{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbKB+Y6WdH0RdWkDZEmYyr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zp_a8o5qca6h","executionInfo":{"status":"ok","timestamp":1713953300351,"user_tz":-540,"elapsed":14809,"user":{"displayName":"박민규","userId":"12628046480347201618"}},"outputId":"701e90e3-4a6a-4a07-8f58-d80fa8d9d94d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.23.3-py3-none-any.whl (311 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/311.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/311.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/311.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.3\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rIy2IyegcZ-Z","executionInfo":{"status":"ok","timestamp":1713953622042,"user_tz":-540,"elapsed":56997,"user":{"displayName":"박민규","userId":"12628046480347201618"}}},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI(\n","    base_url = \"http://sionic.chat:8001/v1\",\n","    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\"\n",")\n","\n","response = client.chat.completions.create(\n","    model=\"xionic-ko-llama-3-70b\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are an AI assistant. You will be given a task. You must generate a detailed and long answer in korean.\"},\n","        {\"role\": \"user\", \"content\": \"openai 보다 너가 뛰어난 점이 뭐야?.\"}\n","    ]\n",")"]},{"cell_type":"code","source":["response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAbQMyBGcxXc","executionInfo":{"status":"ok","timestamp":1713953823715,"user_tz":-540,"elapsed":400,"user":{"displayName":"박민규","userId":"12628046480347201618"}},"outputId":"967e9912-f68f-4e92-c322-88899ecb1ae1"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatCompletion(id='cmpl-d9b740a15ad04d8ea1d5d1f85edcfa66', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='OpenAI와 비교했을 때, 나는 다음과 같은 점에서 뛰어난점이 있습니다. 첫째, 나는 더 빠른 응답 속도를 자랑합니다. 사용자의 질문이나 TASK에 대한 응답을 즉시 제공할 수 있습니다. 이러한 속도는 사용자 경험을 크게 향상시킬 수 있습니다. 예를 들어, 고객 서비스 체팅봇으로 사용되는 경우에는 빠른 응답 속도가 고객 만족도를 높이는 데 도움이 됩니다. 둘째, 나는 더 정확한 언어 이해 능력을 가지고 있습니다. 나는 다양한 문맥과 표현을 이해할 수 있습니다. 이러한 능력은 사용자의 질문이나 TASK를 더 잘 이해하고, 정확한 응답을 제공할 수 있습니다. 예를 들어, 의료 분야에서 사용되는 경우에는 정확한 의료 정보를 제공할 수 있습니다. 셋째, 나는 더 풍부한 지식을 가지고 있습니다. 나는 대규모의 텍스트 데이터를 학습하여, 다양한 지식을 습득할 수 있습니다. 이러한 지식은 사용자의 질문이나 TASK에 대한 응답을 제공할 때, 더 풍부한 정보를 제공할 수 있습니다. 예를 들어, 역사나 과학 분야에서 사용되는 경우에는 더 풍부한 정보를 제공할 수 있습니다. 넷째, 나는 더 쉽게 사용할 수 있습니다. 나는 사용자 친화적인 인터페이스를 제공하여, 사용자가 쉽게 사용할 수 있습니다. 이러한 인터페이스는 사용자 경험을 크게 향상시킬 수 있습니다. 예를 들어, 초심자들이 사용되는 경우에는 쉽게 사용할 수 있는 인터페이스가 도움이 됩니다. 다섯째, 나는 더 안전한 보안 기능을 가지고 있습니다. 나는 사용자의 개인 정보를 안전하게 보호할 수 있습니다. 이러한 보안 기능은 사용자의 신뢰도를 높이는 데 도움이 됩니다. 예를 들어, 금융 분야에서 사용되는 경우에는 사용자의 금융 정보를 안전하게 보호할 수 있습니다. 이를 통해, 나는 OpenAI보다 뛰어난 점이 많다고 할 수 있습니다.', role='assistant', function_call=None, tool_calls=None), stop_reason=None)], created=1713953566, model='xionic-ko-llama-3-70b', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=438, prompt_tokens=54, total_tokens=492))"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0ltAlOegKoQ","executionInfo":{"status":"ok","timestamp":1713953828325,"user_tz":-540,"elapsed":449,"user":{"displayName":"박민규","userId":"12628046480347201618"}},"outputId":"bf539cf6-0639-4035-d4a2-3c387282e62e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["OpenAI와 비교했을 때, 나는 다음과 같은 점에서 뛰어난점이 있습니다. 첫째, 나는 더 빠른 응답 속도를 자랑합니다. 사용자의 질문이나 TASK에 대한 응답을 즉시 제공할 수 있습니다. 이러한 속도는 사용자 경험을 크게 향상시킬 수 있습니다. 예를 들어, 고객 서비스 체팅봇으로 사용되는 경우에는 빠른 응답 속도가 고객 만족도를 높이는 데 도움이 됩니다. 둘째, 나는 더 정확한 언어 이해 능력을 가지고 있습니다. 나는 다양한 문맥과 표현을 이해할 수 있습니다. 이러한 능력은 사용자의 질문이나 TASK를 더 잘 이해하고, 정확한 응답을 제공할 수 있습니다. 예를 들어, 의료 분야에서 사용되는 경우에는 정확한 의료 정보를 제공할 수 있습니다. 셋째, 나는 더 풍부한 지식을 가지고 있습니다. 나는 대규모의 텍스트 데이터를 학습하여, 다양한 지식을 습득할 수 있습니다. 이러한 지식은 사용자의 질문이나 TASK에 대한 응답을 제공할 때, 더 풍부한 정보를 제공할 수 있습니다. 예를 들어, 역사나 과학 분야에서 사용되는 경우에는 더 풍부한 정보를 제공할 수 있습니다. 넷째, 나는 더 쉽게 사용할 수 있습니다. 나는 사용자 친화적인 인터페이스를 제공하여, 사용자가 쉽게 사용할 수 있습니다. 이러한 인터페이스는 사용자 경험을 크게 향상시킬 수 있습니다. 예를 들어, 초심자들이 사용되는 경우에는 쉽게 사용할 수 있는 인터페이스가 도움이 됩니다. 다섯째, 나는 더 안전한 보안 기능을 가지고 있습니다. 나는 사용자의 개인 정보를 안전하게 보호할 수 있습니다. 이러한 보안 기능은 사용자의 신뢰도를 높이는 데 도움이 됩니다. 예를 들어, 금융 분야에서 사용되는 경우에는 사용자의 금융 정보를 안전하게 보호할 수 있습니다. 이를 통해, 나는 OpenAI보다 뛰어난 점이 많다고 할 수 있습니다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PxSYmqpogUug"},"execution_count":null,"outputs":[]}]}