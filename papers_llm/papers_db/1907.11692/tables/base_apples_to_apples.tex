\begin{table*}[t]
\begin{center}
\begin{tabular}{lcccc}
\toprule
\bf Model & \bf SQuAD 1.1/2.0 & \bf MNLI-m & \bf SST-2 & \bf RACE \\ 
\midrule
\multicolumn{5}{l}{\emph{Our reimplementation (with NSP loss):}} \\
\textsc{segment-pair} & 90.4/78.7 & 84.0 & 92.9 & 64.2 \\
\textsc{sentence-pair} & 88.7/76.2 & 82.9 & 92.1 & 63.0 \\
\midrule
\multicolumn{5}{l}{\emph{Our reimplementation (without NSP loss):}} \\
\textsc{full-sentences} & 90.4/79.1 & 84.7 & 92.5 & 64.8 \\
\textsc{doc-sentences} & 90.6/79.7 & 84.7 & 92.7 & 65.6 \\
\midrule
\bertbase{} & 88.5/76.3 & 84.3 & 92.8 & 64.3 \\
\xlnetbase{} (K = 7) & --/81.3 & 85.8 & 92.7 & 66.1 \\
\xlnetbase{} (K = 6) & --/81.0 & 85.6 & 93.4 & 66.7 \\
\bottomrule



\end{tabular}
\end{center}
\caption{
Development set results for base models pretrained over \textsc{BookCorpus} and \textsc{Wikipedia}.
All models are trained for 1M steps with a batch size of 256 sequences.
We report F1 for SQuAD and accuracy for MNLI-m, SST-2 and RACE.
Reported results are medians over five random initializations (seeds).
Results for \bertbase{} and \xlnetbase{} are from \newcite{yang2019xlnet}.
}
\label{tab:base_apples_to_apples}
\end{table*}