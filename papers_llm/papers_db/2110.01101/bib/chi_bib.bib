%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Chi Zhang at 2021-07-17 01:18:35 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{effective_online_hyperparameter,
	author = {Zhan, Hongyuan and Gomes, Gabriel and Li, Xiaoye S. and Madduri, Kamesh and Wu, Kesheng},
	booktitle = {2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
	date-added = {2021-07-17 01:18:16 -0700},
	date-modified = {2021-07-17 01:18:35 -0700},
	doi = {10.1109/ITSC.2018.8569972},
	pages = {164-169},
	title = {Efficient Online Hyperparameter Learning for Traffic Flow Prediction},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/ITSC.2018.8569972}}

@article{rlpyt,
	archiveprefix = {arXiv},
	author = {Adam Stooke and Pieter Abbeel},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1909-01500.bib},
	date-added = {2021-07-16 21:49:51 -0700},
	date-modified = {2021-07-16 21:49:54 -0700},
	eprint = {1909.01500},
	journal = {CoRR},
	timestamp = {Mon, 16 Sep 2019 17:27:14 +0200},
	title = {rlpyt: {A} Research Code Base for Deep Reinforcement Learning in PyTorch},
	url = {http://arxiv.org/abs/1909.01500},
	volume = {abs/1909.01500},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1909.01500}}

@article{pfrl,
	author = {Yasuhiro Fujita and Prabhat Nagarajan and Toshiki Kataoka and Takahiro Ishikawa},
	date-added = {2021-07-16 21:49:06 -0700},
	date-modified = {2021-07-16 21:49:11 -0700},
	journal = {Journal of Machine Learning Research},
	number = {77},
	pages = {1-14},
	title = {ChainerRL: A Deep Reinforcement Learning Library},
	url = {http://jmlr.org/papers/v22/20-376.html},
	volume = {22},
	year = {2021},
	Bdsk-Url-1 = {http://jmlr.org/papers/v22/20-376.html}}

@misc{tianshou,
	author = {Jiayi Weng et al},
	date-added = {2021-07-16 21:48:32 -0700},
	date-modified = {2021-07-16 21:51:47 -0700},
	howpublished = {\url{https://github.com/thu-ml/tianshou}},
	journal = {GitHub repository},
	publisher = {GitHub},
	title = {Tianshou},
	year = {2020}}

@inproceedings{pthread,
	author = {G. Narlikar and G. Blelloch},
	date-added = {2021-07-16 10:48:57 -0700},
	date-modified = {2021-07-16 10:49:00 -0700},
	title = {Pthreads for Dynamic Parallelism},
	year = {1998}}

@article{tpu,
	archiveprefix = {arXiv},
	author = {Norman P. Jouppi and Cliff Young and Nishant Patil and David A. Patterson and Gaurav Agrawal and Raminder Bajwa and Sarah Bates and Suresh Bhatia and Nan Boden and Al Borchers and Rick Boyle and Pierre{-}luc Cantin and Clifford Chao and Chris Clark and Jeremy Coriell and Mike Daley and Matt Dau and Jeffrey Dean and Ben Gelb and Tara Vazir Ghaemmaghami and Rajendra Gottipati and William Gulland and Robert Hagmann and Richard C. Ho and Doug Hogberg and John Hu and Robert Hundt and Dan Hurt and Julian Ibarz and Aaron Jaffey and Alek Jaworski and Alexander Kaplan and Harshit Khaitan and Andy Koch and Naveen Kumar and Steve Lacy and James Laudon and James Law and Diemthu Le and Chris Leary and Zhuyuan Liu and Kyle Lucke and Alan Lundin and Gordon MacKean and Adriana Maggiore and Maire Mahony and Kieran Miller and Rahul Nagarajan and Ravi Narayanaswami and Ray Ni and Kathy Nix and Thomas Norrie and Mark Omernick and Narayana Penukonda and Andy Phelps and Jonathan Ross and Amir Salek and Emad Samadiani and Chris Severn and Gregory Sizikov and Matthew Snelham and Jed Souter and Dan Steinberg and Andy Swing and Mercedes Tan and Gregory Thorson and Bo Tian and Horia Toma and Erick Tuttle and Vijay Vasudevan and Richard Walter and Walter Wang and Eric Wilcox and Doe Hyun Yoon},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/JouppiYPPABBBBB17.bib},
	date-added = {2021-07-14 20:24:00 -0700},
	date-modified = {2021-07-14 20:24:04 -0700},
	eprint = {1704.04760},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:48:05 +0200},
	title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
	url = {http://arxiv.org/abs/1704.04760},
	volume = {abs/1704.04760},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1704.04760}}

@incollection{pytorch,
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	booktitle = {Advances in Neural Information Processing Systems 32},
	date-added = {2021-07-14 20:20:29 -0700},
	date-modified = {2021-07-14 20:20:32 -0700},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8024--8035},
	publisher = {Curran Associates, Inc.},
	title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	year = {2019},
	Bdsk-Url-1 = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}}

@article{alphago_zero,
	abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100--0 against the previously published, champion-defeating AlphaGo.},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	da = {2017/10/01},
	date-added = {2021-07-14 20:09:00 -0700},
	date-modified = {2021-07-14 20:09:08 -0700},
	doi = {10.1038/nature24270},
	id = {Silver2017},
	isbn = {1476-4687},
	journal = {Nature},
	number = {7676},
	pages = {354--359},
	title = {Mastering the game of Go without human knowledge},
	ty = {JOUR},
	url = {https://doi.org/10.1038/nature24270},
	volume = {550},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature24270}}

@article{AsyncPSGD,
	archiveprefix = {arXiv},
	author = {Karl B{\"{a}}ckstr{\"{o}}m and Marina Papatriantafilou and Philippas Tsigas},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1911-03444.bib},
	date-added = {2021-07-14 18:48:56 -0700},
	date-modified = {2021-07-14 18:49:05 -0700},
	eprint = {1911.03444},
	journal = {CoRR},
	timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
	title = {MindTheStep-AsyncPSGD: Adaptive Asynchronous Parallel Stochastic Gradient Descent},
	url = {http://arxiv.org/abs/1911.03444},
	volume = {abs/1911.03444},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1911.03444}}

@inproceedings{ppo_fpga,
	author = {Meng, Yuan and Kuppannagari, Sanmukh and Prasanna, Viktor},
	booktitle = {2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
	date-added = {2021-07-14 18:09:08 -0700},
	date-modified = {2021-07-14 18:09:13 -0700},
	doi = {10.1109/FCCM48280.2020.00012},
	pages = {19-27},
	title = {Accelerating Proximal Policy Optimization on CPU-FPGA Heterogeneous Platforms},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1109/FCCM48280.2020.00012}}

@inproceedings{trpo_fpga,
	author = {Shao, Shengjia and Luk, Wayne},
	booktitle = {2017 27th International Conference on Field Programmable Logic and Applications (FPL)},
	date-added = {2021-07-14 18:08:35 -0700},
	date-modified = {2021-07-14 18:08:39 -0700},
	doi = {10.23919/FPL.2017.8056789},
	pages = {1-6},
	title = {Customised pearlmutter propagation: A hardware architecture for trust region policy optimisation},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.23919/FPL.2017.8056789}}

@article{map_reduce,
	abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
	address = {New York, NY, USA},
	author = {Dean, Jeffrey and Ghemawat, Sanjay},
	date-added = {2021-07-14 18:03:43 -0700},
	date-modified = {2021-07-14 18:03:48 -0700},
	doi = {10.1145/1327452.1327492},
	issn = {0001-0782},
	issue_date = {January 2008},
	journal = {Commun. ACM},
	month = jan,
	number = {1},
	numpages = {7},
	pages = {107--113},
	publisher = {Association for Computing Machinery},
	title = {MapReduce: Simplified Data Processing on Large Clusters},
	url = {https://doi.org/10.1145/1327452.1327492},
	volume = {51},
	year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1145/1327452.1327492}}

@inproceedings{parallel_rl,
	author = {Kretchmar, R Matthew},
	booktitle = {The 6th World Conference on Systemics, Cybernetics, and Informatics},
	date-added = {2021-07-14 17:57:22 -0700},
	date-modified = {2021-07-14 17:57:26 -0700},
	organization = {Citeseer},
	title = {Parallel reinforcement learning},
	year = {2002}}

@article{paac,
	archiveprefix = {arXiv},
	author = {Alfredo V. Clemente and Humberto Nicol{\'{a}}s Castej{\'{o}}n Mart{\'{\i}}nez and Arjun Chandra},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/ClementeMC17.bib},
	date-added = {2021-07-14 17:50:36 -0700},
	date-modified = {2021-07-14 17:50:39 -0700},
	eprint = {1705.04862},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:48 +0200},
	title = {Efficient Parallel Methods for Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1705.04862},
	volume = {abs/1705.04862},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1705.04862}}

@article{ray_rllib,
	archiveprefix = {arXiv},
	author = {Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Joseph Gonzalez and Ken Goldberg and Ion Stoica},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1712-09381.bib},
	date-added = {2021-07-14 17:21:19 -0700},
	date-modified = {2021-07-14 17:21:24 -0700},
	eprint = {1712.09381},
	journal = {CoRR},
	timestamp = {Thu, 30 Apr 2020 14:45:00 +0200},
	title = {Ray RLLib: {A} Composable and Scalable Reinforcement Learning Library},
	url = {http://arxiv.org/abs/1712.09381},
	volume = {abs/1712.09381},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1712.09381}}

@inproceedings{map_reduce_parallel_rl,
	abstract = {We investigate the parallelization of reinforcement learning algorithms using MapReduce, a popular parallel computing framework. We present parallel versions of several dynamic programming algorithms, including policy evaluation, policy iteration, and off-policy updates. Furthermore, we design parallel reinforcement learning algorithms to deal with large scale problems using linear function approximation, including model-based projection, least squares policy iteration, temporal difference learning and recent gradient temporal difference learning algorithms. We give time and space complexity analysis of the proposed algorithms. This study demonstrates how parallelization opens new avenues for solving large scale reinforcement learning problems.},
	address = {Berlin, Heidelberg},
	author = {Li, Yuxi and Schuurmans, Dale},
	booktitle = {Recent Advances in Reinforcement Learning},
	date-added = {2021-07-14 17:16:48 -0700},
	date-modified = {2021-07-14 17:16:54 -0700},
	editor = {Sanner, Scott and Hutter, Marcus},
	isbn = {978-3-642-29946-9},
	pages = {309--320},
	publisher = {Springer Berlin Heidelberg},
	title = {MapReduce for Parallel Reinforcement Learning},
	year = {2012}}

@techreport{python,
	address = {Amsterdam},
	author = {G. van Rossum},
	date-added = {2021-07-14 14:16:59 -0700},
	date-modified = {2021-07-14 14:17:02 -0700},
	institution = {Centrum voor Wiskunde en Informatica (CWI)},
	month = {May},
	number = {CS-R9526},
	title = {Python tutorial},
	year = {1995}}

@inproceedings{parameter_server,
	abstract = {We propose a parameter server framework for distributed machine learning problems. Both data and workloads are distributed over worker nodes, while the server nodes maintain globally shared parameters, represented as dense or sparse vectors and matrices. The framework manages asynchronous data communication between nodes, and supports flexible consistency models, elastic scalability, and continuous fault tolerance.To demonstrate the scalability of the proposed framework, we show experimental results on petabytes of real data with billions of examples and parameters on problems ranging from Sparse Logistic Regression to Latent Dirichlet Allocation and Distributed Sketching.},
	address = {USA},
	author = {Li, Mu and Andersen, David G. and Park, Jun Woo and Smola, Alexander J. and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J. and Su, Bor-Yiing},
	booktitle = {Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation},
	date-added = {2021-06-15 19:41:43 -0700},
	date-modified = {2021-06-15 19:41:50 -0700},
	isbn = {9781931971164},
	location = {Broomfield, CO},
	numpages = {16},
	pages = {583--598},
	publisher = {USENIX Association},
	series = {OSDI'14},
	title = {Scaling Distributed Machine Learning with the Parameter Server},
	year = {2014}}

@article{impala,
	archiveprefix = {arXiv},
	author = {Lasse Espeholt and Hubert Soyer and R{\'{e}}mi Munos and Karen Simonyan and Volodymyr Mnih and Tom Ward and Yotam Doron and Vlad Firoiu and Tim Harley and Iain Dunning and Shane Legg and Koray Kavukcuoglu},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1802-01561.bib},
	date-added = {2021-06-15 09:58:59 -0700},
	date-modified = {2021-06-15 09:59:03 -0700},
	eprint = {1802.01561},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
	title = {{IMPALA:} Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
	url = {http://arxiv.org/abs/1802.01561},
	volume = {abs/1802.01561},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1802.01561}}

@article{ApeX,
	archiveprefix = {arXiv},
	author = {Dan Horgan and John Quan and David Budden and Gabriel Barth{-}Maron and Matteo Hessel and Hado van Hasselt and David Silver},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1803-00933.bib},
	date-added = {2021-06-15 09:58:31 -0700},
	date-modified = {2021-06-15 09:58:36 -0700},
	eprint = {1803.00933},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
	title = {Distributed Prioritized Experience Replay},
	url = {http://arxiv.org/abs/1803.00933},
	volume = {abs/1803.00933},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1803.00933}}

@article{a3c,
	archiveprefix = {arXiv},
	author = {Volodymyr Mnih and Adri{\`{a}} Puigdom{\`{e}}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
	date-added = {2021-06-15 09:57:50 -0700},
	date-modified = {2021-06-15 09:57:53 -0700},
	eprint = {1602.01783},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
	title = {Asynchronous Methods for Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1602.01783},
	volume = {abs/1602.01783},
	year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1602.01783}}

@article{gorila,
	archiveprefix = {arXiv},
	author = {Arun Nair and Praveen Srinivasan and Sam Blackwell and Cagdas Alcicek and Rory Fearon and Alessandro De Maria and Vedavyas Panneershelvam and Mustafa Suleyman and Charles Beattie and Stig Petersen and Shane Legg and Volodymyr Mnih and Koray Kavukcuoglu and David Silver},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/NairSBAFMPSBPLM15.bib},
	date-added = {2021-06-15 09:49:09 -0700},
	date-modified = {2021-06-15 09:49:49 -0700},
	eprint = {1507.04296},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
	title = {Massively Parallel Methods for Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1507.04296},
	volume = {abs/1507.04296},
	year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1507.04296}}

@inproceedings{Fox2019TowardPU,
	author = {R. Fox},
	title = {Toward Provably Unbiased Temporal-Difference Value Estimation},
	year = {2019}}

@article{critic_rr,
	author = {Ziyu Wang and A. Novikov and Konrad Zolna and Jost Tobias Springenberg and Scott Reed and B. Shahriari and N. Siegel and Josh Merel and Caglar Gulcehre and Nicolas Heess and N. D. Freitas},
	journal = {ArXiv},
	title = {Critic Regularized Regression},
	volume = {abs/2006.15134},
	year = {2020}}

@article{adroit_env,
	author = {A. Rajeswaran and V. Kumar and Abhishek Gupta and John Schulman and E. Todorov and S. Levine},
	journal = {ArXiv},
	title = {Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations},
	volume = {abs/1709.10087},
	year = {2018}}

@article{intro_vae,
	archiveprefix = {arXiv},
	author = {Diederik P. Kingma and Max Welling},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1906-02691.bib},
	eprint = {1906.02691},
	journal = {CoRR},
	timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
	title = {An Introduction to Variational Autoencoders},
	url = {http://arxiv.org/abs/1906.02691},
	volume = {abs/1906.02691},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1906.02691}}

@article{imitation_learning_f_divergence_min,
	author = {Liyiming Ke and M. Barnes and W. Sun and Gilwoo Lee and S. Choudhury and S. Srinivasa},
	date-added = {2020-11-14 22:45:06 -0800},
	date-modified = {2020-11-14 22:45:15 -0800},
	journal = {ArXiv},
	title = {Imitation Learning as f-Divergence Minimization},
	volume = {abs/1905.12888},
	year = {2019}}

@inproceedings{beta_vae,
	author = {I. Higgins and Lo{\"\i}c Matthey and A. Pal and C. Burgess and Xavier Glorot and M. Botvinick and S. Mohamed and Alexander Lerchner},
	booktitle = {ICLR},
	date-added = {2020-11-14 17:58:40 -0800},
	date-modified = {2020-11-14 17:58:46 -0800},
	title = {beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework},
	year = {2017}}

@inproceedings{wgan_gp,
	author = {Ishaan Gulrajani and F. Ahmed and Mart{\'\i}n Arjovsky and Vincent Dumoulin and Aaron C. Courville},
	booktitle = {NIPS},
	date-added = {2020-11-10 14:09:06 -0800},
	date-modified = {2020-11-10 14:09:09 -0800},
	title = {Improved Training of Wasserstein GANs},
	year = {2017}}

@article{mbop,
	author = {Arthur Argenson and Gabriel Dulac-Arnold},
	date-added = {2020-10-01 15:15:17 -0700},
	date-modified = {2020-10-01 15:15:21 -0700},
	journal = {ArXiv},
	title = {Model-Based Offline Planning},
	volume = {abs/2008.05556},
	year = {2020}}

@article{vae_intro,
	author = {Diederik P. Kingma and M. Welling},
	date-added = {2020-10-01 09:14:24 -0700},
	date-modified = {2020-10-01 09:14:28 -0700},
	journal = {Found. Trends Mach. Learn.},
	pages = {307-392},
	title = {An Introduction to Variational Autoencoders},
	volume = {12},
	year = {2019}}

@article{td3,
	author = {Scott Fujimoto and H. V. Hoof and David Meger},
	date-added = {2020-09-29 15:59:10 -0700},
	date-modified = {2020-09-29 15:59:13 -0700},
	journal = {ArXiv},
	title = {Addressing Function Approximation Error in Actor-Critic Methods},
	volume = {abs/1802.09477},
	year = {2018}}

@inproceedings{approximate_kl,
	author = {J. R. {Hershey} and P. A. {Olsen}},
	booktitle = {2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07},
	date-added = {2020-09-27 22:31:42 -0700},
	date-modified = {2020-09-27 22:31:48 -0700},
	pages = {IV-317-IV-320},
	title = {Approximating the Kullback Leibler Divergence Between Gaussian Mixture Models},
	volume = {4},
	year = {2007}}

@inproceedings{batch_rl_hyperparameter_gradient,
	author = {Byung-Jun Lee and Jongmin Lee and Peter Vrancx and DongHo Kim and Kee-Eung Kim},
	date-added = {2020-09-25 09:26:21 -0700},
	date-modified = {2020-09-25 09:26:30 -0700},
	title = {Batch Reinforcement Learning with Hyperparameter Gradients},
	year = {2020}}

@article{behavior_prior,
	author = {Noah Siegel and Jost Tobias Springenberg and Felix Berkenkamp and Abbas Abdolmaleki and Michael Neunert and T. Lampe and Roland Hafner and Martin A. Riedmiller},
	date-added = {2020-09-24 22:14:31 -0700},
	date-modified = {2020-09-24 22:14:36 -0700},
	journal = {ArXiv},
	title = {Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
	volume = {abs/2002.08396},
	year = {2020}}

@article{recommendation_rl,
	author = {Sungwoon Choi and Heonseok Ha and Uiwon Hwang and Chanju Kim and Jung-Woo Ha and S. Yoon},
	date-added = {2020-09-24 15:44:17 -0700},
	date-modified = {2020-09-24 15:44:21 -0700},
	journal = {ArXiv},
	title = {Reinforcement Learning based Recommender System using Biclustering Technique},
	volume = {abs/1801.05532},
	year = {2018}}

@article{f_gan,
	author = {Sebastian Nowozin and B. Cseke and Ryota Tomioka},
	date-added = {2020-09-22 17:25:47 -0700},
	date-modified = {2020-09-22 17:25:52 -0700},
	journal = {ArXiv},
	title = {f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization},
	volume = {abs/1606.00709},
	year = {2016}}

@inproceedings{mmd,
	author = {Arthur Gretton and Karsten M. Borgwardt and Malte J. Rasch and Bernhard Scholkopf and Alexander J. Smola},
	booktitle = {AAAI},
	cdate = {1167609600000},
	date-added = {2020-09-22 15:53:20 -0700},
	date-modified = {2020-09-22 15:56:32 -0700},
	pages = {1637-1641},
	title = {A Kernel Approach to Comparing Distributions},
	url = {http://www.aaai.org/Library/AAAI/2007/aaai07-262.php},
	year = {2007},
	Bdsk-Url-1 = {http://www.aaai.org/Library/AAAI/2007/aaai07-262.php}}

@article{f_divergence,
	abstract = {A class of numerical measures of informativity of observation channels or statistical experiments is defined by the aid off-divergences introduced by the author as measures of difference of two probability distributions. For observation channels with given prior probabilities, thef-informativity measures are generalizations of Shannon's mutual information and include Gallager's functionE0(ϱQ) appearing in the derivation of error exponent for noisy channels, as well. For observation channels without prior probabilities, the suggested informativity measures have the geometric interpretation of a radius.},
	author = {Csisz{\'a}r, I.},
	da = {1972/03/01},
	date-added = {2020-09-22 14:48:48 -0700},
	date-modified = {2020-09-22 14:48:54 -0700},
	doi = {10.1007/BF02018661},
	id = {Csisz{\'a}r1972},
	isbn = {1588-2829},
	journal = {Periodica Mathematica Hungarica},
	number = {1},
	pages = {191--213},
	title = {A class of measures of informativity of observation channels},
	ty = {JOUR},
	url = {https://doi.org/10.1007/BF02018661},
	volume = {2},
	year = {1972},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF02018661}}

@article{adam,
	author = {Diederik P. Kingma and Jimmy Ba},
	date-added = {2020-09-21 21:33:21 -0700},
	date-modified = {2020-09-21 21:33:24 -0700},
	journal = {CoRR},
	title = {Adam: A Method for Stochastic Optimization},
	volume = {abs/1412.6980},
	year = {2015}}

@article{relu,
	author = {Abien Fred Agarap},
	date-added = {2020-09-21 21:27:22 -0700},
	date-modified = {2020-09-21 21:27:24 -0700},
	journal = {ArXiv},
	title = {Deep Learning using Rectified Linear Units (ReLU)},
	volume = {abs/1803.08375},
	year = {2018}}

@incollection{double_q_learning,
	author = {Hado V. Hasselt},
	booktitle = {Advances in Neural Information Processing Systems 23},
	date-added = {2020-09-21 20:32:23 -0700},
	date-modified = {2020-09-21 20:32:29 -0700},
	editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
	pages = {2613--2621},
	publisher = {Curran Associates, Inc.},
	title = {Double Q-learning},
	url = {http://papers.nips.cc/paper/3964-double-q-learning.pdf},
	year = {2010},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/3964-double-q-learning.pdf}}

@article{cql,
	author = {Aviral Kumar and Aurick Zhou and G. Tucker and Sergey Levine},
	date-added = {2020-09-21 10:43:07 -0700},
	date-modified = {2020-09-21 10:43:11 -0700},
	journal = {ArXiv},
	title = {Conservative Q-Learning for Offline Reinforcement Learning},
	volume = {abs/2006.04779},
	year = {2020}}

@misc{conditional_nf,
	archiveprefix = {arXiv},
	author = {Christina Winkler and Daniel Worrall and Emiel Hoogeboom and Max Welling},
	date-added = {2020-09-07 11:05:27 -0700},
	date-modified = {2020-09-07 11:05:35 -0700},
	eprint = {1912.00042},
	primaryclass = {cs.LG},
	title = {Learning Likelihoods with Conditional Normalizing Flows},
	year = {2019}}

@article{gan,
	author = {Ian J. Goodfellow and Jean Pouget-Abadie and M. Mirza and B. Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
	date-added = {2020-09-07 10:50:49 -0700},
	date-modified = {2020-09-07 10:50:52 -0700},
	journal = {ArXiv},
	title = {Generative Adversarial Networks},
	volume = {abs/1406.2661},
	year = {2014}}

@article{real_nvp,
	author = {Laurent Dinh and Jascha Sohl-Dickstein and S. Bengio},
	date-added = {2020-09-06 22:54:38 -0700},
	date-modified = {2020-09-06 22:54:42 -0700},
	journal = {ArXiv},
	title = {Density estimation using Real NVP},
	volume = {abs/1605.08803},
	year = {2017}}

@article{normalizing_flow_intro,
	author = {I. Kobyzev and S. Prince and M. Brubaker},
	date-added = {2020-09-06 22:49:36 -0700},
	date-modified = {2020-09-06 22:49:46 -0700},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	title = {Normalizing Flows: An Introduction and Review of Current Methods.},
	year = {2020}}

@article{d4rl,
	author = {Justin Fu and Aviral Kumar and Ofir Nachum and G. Tucker and Sergey Levine},
	date-added = {2020-09-06 14:35:35 -0700},
	date-modified = {2020-09-06 14:35:39 -0700},
	journal = {ArXiv},
	title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
	volume = {abs/2004.07219},
	year = {2020}}

@inproceedings{citylearn,
	address = {New York, NY, USA},
	author = {V\'{a}zquez-Canteli, Jos\'{e} R. and K\"{a}mpf, J\'{e}r\^{o}me and Henze, Gregor and Nagy, Zoltan},
	booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	date-added = {2020-07-30 23:07:41 -0700},
	date-modified = {2020-07-30 23:07:45 -0700},
	doi = {10.1145/3360322.3360998},
	isbn = {9781450370059},
	keywords = {Smart Grid, Building Energy Control, Smart Buildings},
	location = {New York, NY, USA},
	numpages = {2},
	pages = {356--357},
	publisher = {Association for Computing Machinery},
	series = {BuildSys '19},
	title = {CityLearn v1.0: An OpenAI Gym Environment for Demand Response with Deep Reinforcement Learning},
	url = {https://doi.org/10.1145/3360322.3360998},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3360322.3360998}}

@misc{eDrawings,
	author = {Dassault Systemes SolidWorks Corporation},
	date-added = {2020-07-30 17:13:17 -0700},
	date-modified = {2020-07-30 17:16:24 -0700},
	howpublished = {https://www.edrawingsviewer.com},
	title = {Review 2D \& 3D Designs with eDrawings},
	year = {2019}}

@inproceedings{offpolicy_evaluation_is,
	author = {Doina Precup and Richard S. Sutton and Satinder P. Singh},
	booktitle = {ICML},
	date-added = {2020-07-29 15:14:41 -0700},
	date-modified = {2020-07-29 15:14:54 -0700},
	title = {Eligibility Traces for Off-Policy Policy Evaluation},
	year = {2000}}

@article{virtual_to_real_transfer_robots,
	author = {Michael L. Iuzzolino and Michael E. Walker and Daniel Szafir},
	date-added = {2020-07-26 19:53:23 -0700},
	date-modified = {2020-07-26 19:53:32 -0700},
	journal = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	pages = {576-582},
	title = {Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails},
	year = {2018}}

@article{smart_hvac_iot,
	author = {Jordi Serra and David Pubill and Angelos Antonopoulos and Christos V. Verikoukis},
	date-added = {2020-07-25 23:29:46 -0700},
	date-modified = {2020-07-25 23:29:54 -0700},
	journal = {The Scientific World Journal},
	title = {Smart HVAC Control in IoT: Energy Consumption Minimization with User Comfort Constraints},
	volume = {2014},
	year = {2014}}

@article{offlineRL_tutorial,
	author = {Sergey Levine and Aviral Kumar and George Tucker and Justin Fu},
	date-added = {2020-07-25 23:27:14 -0700},
	date-modified = {2020-07-25 23:27:31 -0700},
	journal = {ArXiv},
	title = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
	volume = {abs/2005.01643},
	year = {2020}}

@inproceedings{control_air_free_data_center_drl,
	address = {New York, NY, USA},
	author = {Van Le, Duc and Liu, Yingbo and Wang, Rongrong and Tan, Rui and Wong, Yew-Wah and Wen, Yonggang},
	booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	date-added = {2020-07-25 22:56:19 -0700},
	date-modified = {2020-07-25 22:56:28 -0700},
	doi = {10.1145/3360322.3360845},
	isbn = {9781450370059},
	keywords = {deep reinforcement learning, Data centers, air free cooling},
	location = {New York, NY, USA},
	numpages = {10},
	pages = {306--315},
	publisher = {Association for Computing Machinery},
	series = {BuildSys '19},
	title = {Control of Air Free-Cooled Data Centers in Tropics via Deep Reinforcement Learning},
	url = {https://doi.org/10.1145/3360322.3360845},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3360322.3360845}}

@inproceedings{octopus,
	address = {New York, NY, USA},
	author = {Ding, Xianzhong and Du, Wan and Cerpa, Alberto},
	booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	date-added = {2020-07-25 22:55:19 -0700},
	date-modified = {2020-07-25 22:55:23 -0700},
	doi = {10.1145/3360322.3360857},
	isbn = {9781450370059},
	keywords = {energy efficiency, deep reinforcement learning, HVAC control},
	location = {New York, NY, USA},
	numpages = {10},
	pages = {326--335},
	publisher = {Association for Computing Machinery},
	series = {BuildSys '19},
	title = {OCTOPUS: Deep Reinforcement Learning for Holistic Smart Building Control},
	url = {https://doi.org/10.1145/3360322.3360857},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3360322.3360857}}

@inproceedings{gnu-rl,
	address = {New York, NY, USA},
	author = {Chen, Bingqing and Cai, Zicheng and Berg\'{e}s, Mario},
	booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	date-added = {2020-07-25 22:54:35 -0700},
	date-modified = {2020-07-25 22:54:41 -0700},
	doi = {10.1145/3360322.3360849},
	isbn = {9781450370059},
	keywords = {Deep Reinforcement Learning, HVAC Control},
	location = {New York, NY, USA},
	numpages = {10},
	pages = {316--325},
	publisher = {Association for Computing Machinery},
	series = {BuildSys '19},
	title = {Gnu-RL: A Precocial Reinforcement Learning Solution for Building HVAC Control Using a Differentiable MPC Policy},
	url = {https://doi.org/10.1145/3360322.3360849},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3360322.3360849}}

@article{building_dynamics_model,
	author = {B. {Arguello-Serrano} and M. {Velez-Reyes}},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1109/87.736752},
	issn = {1063-6536},
	journal = {IEEE Transactions on Control Systems Technology},
	keywords = {HVAC;nonlinear control systems;state estimation;stability;Lyapunov methods;nonlinear control;online thermal load estimation;time-varying thermal loads;disturbance rejection component;Lyapunov stability theory;state estimator;variable-air-volume HVAC system;Temperature control;Air conditioning;Thermal loading;Space heating;Nonlinear control systems;Control systems;Time varying systems;Regulators;Lyapunov method;State estimation},
	month = {Jan},
	number = {1},
	pages = {56-63},
	title = {Nonlinear control of a heating, ventilating, and air conditioning system with thermal load estimation},
	volume = {7},
	year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAlLi4vLi4vLi4vRG93bmxvYWRzL2FpYWFfamdjZDE2XzU5LmJpYk8RAV4AAAAAAV4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xJhaWFhX2pnY2QxNl81OS5iaWIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAMAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAC0vOlVzZXJzOmNoaXpoYW5nOkRvd25sb2FkczphaWFhX2pnY2QxNl81OS5iaWIAAA4AJgASAGEAaQBhAGEAXwBqAGcAYwBkADEANgBfADUAOQAuAGIAaQBiAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAK1VzZXJzL2NoaXpoYW5nL0Rvd25sb2Fkcy9haWFhX2pnY2QxNl81OS5iaWIAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAEwAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABrg==},
	Bdsk-Url-1 = {https://doi.org/10.1109/87.736752}}

@article{sgd,
	added-at = {2008-10-07T16:03:39.000+0200},
	author = {Robbins, H. and Monro, S.},
	biburl = {https://www.bibsonomy.org/bibtex/2cc1b9aa8927ac4952e93f34094a3eaaf/brefeld},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	interhash = {93d54534a08c30eda9e34d1def03ffa3},
	intrahash = {cc1b9aa8927ac4952e93f34094a3eaaf},
	journal = {Annals of Mathematical Statistics},
	keywords = {imported},
	pages = {400-407},
	timestamp = {2008-10-07T16:03:40.000+0200},
	title = {A stochastic approximation method},
	volume = 22,
	year = 1951}

@article{survey_mcts,
	author = {C. B. {Browne} and E. {Powley} and D. {Whitehouse} and S. M. {Lucas} and P. I. {Cowling} and P. {Rohlfshagen} and S. {Tavener} and D. {Perez} and S. {Samothrakis} and S. {Colton}},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1109/TCIAIG.2012.2186810},
	issn = {1943-068X},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	keywords = {game theory;Monte Carlo methods;tree searching;Monte carlo tree search methods;random sampling generality;computer Go;MCTS research;key game;nongame domains;Games;Monte Carlo methods;Artificial intelligence;Game theory;Computers;Markov processes;Decision theory;Artificial intelligence (AI);bandit-based methods;computer Go;game search;Monte Carlo tree search (MCTS);upper confidence bounds (UCB);upper confidence bounds for trees (UCT)},
	month = {March},
	number = {1},
	pages = {1-43},
	title = {A Survey of Monte Carlo Tree Search Methods},
	volume = {4},
	year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1109/TCIAIG.2012.2186810}}

@inproceedings{pomdp,
	author = {Michael L. Littman},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	title = {A tutorial on partially observable Markov decision processes},
	year = {2009}}

@inproceedings{appro_mpc_nn,
	author = {S. {Chen} and K. {Saulnier} and N. {Atanasov} and D. D. {Lee} and V. {Kumar} and G. J. {Pappas} and M. {Morari}},
	booktitle = {2018 Annual American Control Conference (ACC)},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.23919/ACC.2018.8431275},
	keywords = {gradient methods;learning (artificial intelligence);linear quadratic control;neurocontrollers;predictive control;constrained neural networks;approximate explicit model predictive control law;optimal MPC control law;constrained linear quadratic regulator systems;reinforcement learning techniques;rectified linear units;modified reinforcement learning policy gradient algorithm;system model;feasible control inputs;maximal control invariant set;neural network training;polytope regions;piecewise affine;Neural networks;Optimal control;Computer architecture;Optimization;Predictive control;Learning (artificial intelligence);Computational modeling},
	month = {June},
	pages = {1520-1527},
	title = {Approximating Explicit Model Predictive Control Using Constrained Neural Networks},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.23919/ACC.2018.8431275}}

@article{ann_mpc_review,
	author = {Afram, Abdul and Janabi-Sharifi, Farrokh and S. Fung, Alan and Raahemifar, Kaamran},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1016/j.enbuild.2017.02.012},
	journal = {Energy and Buildings},
	month = {02},
	title = {Artificial Neural Network (ANN) based Model Predictive Control (MPC) and Optimization of HVAC Systems: A State of the Art Review and Case Study of a Residential HVAC System},
	volume = {141},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.enbuild.2017.02.012}}

@inproceedings{attention_relation_extraction,
	author = {Peng Zhou and Wei Shi and Jun Tian and Zhenyu Qi and Bingchen Li and Hongwei Hao and Bo Xu},
	booktitle = {ACL},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	title = {Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification},
	year = {2016}}

@inproceedings{chi_buildsys19,
	address = {New York, NY, USA},
	author = {Zhang, Chi and Kuppannagari, Sanmukh R. and Kannan, Rajgopal and Prasanna, Viktor K.},
	booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1145/3360322.3360861},
	isbn = {9781450370059},
	keywords = {neural network dynamics, hvac control, model predictive control, data center cooling, smart buildings, model-based reinforcement learning},
	location = {New York, NY, USA},
	numpages = {10},
	pages = {287--296},
	publisher = {Association for Computing Machinery},
	series = {BuildSys '19},
	title = {Building HVAC Scheduling Using Reinforcement Learning via Neural Network Based Model Approximation},
	url = {https://doi.org/10.1145/3360322.3360861},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3360322.3360861}}

@misc{building_energy_data_book,
	author = {U.S. Department of Energy},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	howpublished = {https://ieer.org/resource/energy-issues/2011-buildings-energy-data-book/},
	title = {Buildings Energy Data Book},
	year = {2011}}

@webpage{control_system_equations,
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	title = {Control Systems/State-Space Equations},
	url = {https://en.wikibooks.org/wiki/Control\_Systems/State-Space\_Equations},
	year = {2019},
	Bdsk-Url-1 = {https://en.wikibooks.org/wiki/Control%5C_Systems/State-Space%5C_Equations}}

@incollection{data_center_cooling_mpc,
	author = {Lazic, Nevena and Boutilier, Craig and Lu, Tyler and Wong, Eehern and Roy, Binz and Ryu, MK and Imwalle, Greg},
	booktitle = {Advances in Neural Information Processing Systems 31},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {3814--3823},
	publisher = {Curran Associates, Inc.},
	title = {Data center cooling using model-predictive control},
	url = {http://papers.nips.cc/paper/7638-data-center-cooling-using-model-predictive-control.pdf},
	year = {2018},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/7638-data-center-cooling-using-model-predictive-control.pdf}}

@inproceedings{drl_hvac,
	author = {T. {Wei} and {Yanzhi Wang} and Q. {Zhu}},
	booktitle = {2017 54th ACM/EDAC/IEEE Design Automation Conference (DAC)},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1145/3061639.3062224},
	keywords = {building management systems;buildings (structures);cost reduction;energy consumption;HVAC;learning (artificial intelligence);deep reinforcement learning;building HVAC control;data-driven approach;DRL algorithm;EnergyPlus tool;intelligent scheduling;air conditioning;United States;total energy consumption;HVAC control;energy cost reduction;Buildings;Mathematical model;Training;Learning (artificial intelligence);Meteorology;Aerospace electronics;Neural networks},
	month = {June},
	pages = {1-6},
	title = {Deep reinforcement learning for building HVAC control},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1145/3061639.3062224}}

@misc{thermal_comfort_rl,
	author = {Guanyu Gao and Jie Li and Yonggang Wen},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	eprint = {arXiv:1901.04693},
	title = {Energy-Efficient Thermal Comfort Control in Smart Buildings via Deep Reinforcement Learning},
	year = {2019}}

@article{energyplus,
	author = {Drury B. Crawley and Curtis O. Pedersen and Linda K. Lawrie and Frederick C. Winkelmann},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	journal = {ASHRAE Journal},
	pages = {49--56},
	title = {EnergyPlus: Energy Simulation Program},
	volume = {42},
	year = {2000}}

@book{gaussian_process,
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	isbn = {026218253X},
	publisher = {The MIT Press},
	title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
	year = {2005}}

@inproceedings{mpc,
	author = {C. {Ekaputri} and A. {Syaichu-Rohman}},
	booktitle = {2012 IEEE Control and System Graduate Research Colloquium},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1109/ICSGRC.2012.6287146},
	keywords = {actuators;mathematics computing;microcontrollers;multivariable control systems;nonlinear control systems;pendulums;predictive control;quadratic programming;implementation model predictive control algorithm;MPC algorithm;inverted pendulum;real-time optimization problem;multivariable control problem;actuator constraints;complex algorithm;floating point algorithm-3;system modelling;system design;MATLAB;AVR ATmega32 microcontroller;quadratic programming;time external force;Algorithm design and analysis;Mathematical model;Control systems;Computational modeling;Equations;Time factors;Optimization;Model Predictive Control (MPC);algorithm-3;inverted pendulum;AVR ATmega32},
	month = {July},
	pages = {116-122},
	title = {Implementation model predictive control (MPC) algorithm-3 for inverted pendulum},
	year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICSGRC.2012.6287146}}

@misc{hvac_intro,
	author = {Reid Hart},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	howpublished = {https://www.energycodes.gov/sites/default/files/becu/\\HVAC\_Systems\_Presentation\_Slides.pdf},
	month = {Aug},
	title = {Introduction to Commercial Building HVAC Systems and Energy Code Requirements},
	year = {2016}}

@inproceedings{lqr,
	author = {S. {Ahmad} and M. O. {Tokhi}},
	booktitle = {2011 4th International Conference on Mechatronics (ICOM)},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1109/ICOM.2011.5937119},
	keywords = {differential equations;handicapped aids;linear quadratic control;nonlinear control systems;pendulums;stability;state-space methods;wheelchairs;linear quadratic regulator approach;two wheeled wheelchair stabilization;state space model;double inverted pendulum;linearized mathematical equation;linearized differential equation;Wheelchairs;Mathematical model;Wheels;Equations;Regulators;Differential equations;Aerospace electronics;state space model;double inverted pendulum;fuzzy logic control;wheelchair;nonlinear system},
	month = {May},
	pages = {1-6},
	title = {Linear Quadratic Regulator (LQR) approach for lifting and stabilizing of two-wheeled wheelchair},
	year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICOM.2011.5937119}}

@article{nn_model_based_rl,
	archiveprefix = {arXiv},
	author = {Anusha Nagabandi and Gregory Kahn and Ronald S. Fearing and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/bib/journals/corr/abs-1708-02596},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	eprint = {1708.02596},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:41 +0200},
	title = {Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning},
	url = {http://arxiv.org/abs/1708.02596},
	volume = {abs/1708.02596},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1708.02596}}

@article{dagger,
	archiveprefix = {arXiv},
	author = {St{\'{e}}phane Ross and Geoffrey J. Gordon and J. Andrew Bagnell},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/bib/journals/corr/abs-1011-0686},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	eprint = {1011.0686},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:45:56 +0200},
	title = {No-Regret Reductions for Imitation Learning and Structured Prediction},
	url = {http://arxiv.org/abs/1011.0686},
	volume = {abs/1011.0686},
	year = {2010},
	Bdsk-Url-1 = {http://arxiv.org/abs/1011.0686}}

@article{novel_modeling,
	author = {Kang, Chang-Soon and Park, Jong-Il and Park, Mignon and Baek, Jaeho},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.3390/en7063599},
	journal = {Energies},
	month = {06},
	pages = {3599-3617},
	title = {Novel Modeling and Control Strategies for a HVAC System Including Carbon Dioxide Control},
	volume = {7},
	year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.3390/en7063599}}

@article{optimal_control_building_hvac_sequential_quadratic_programming,
	abstract = {This paper presents a general and systematic methodology, termed complete simulation-based sequential quadratic programming (CSB-SQP), for determining the optimal control of building HVAC&R systems. This approach allows the coupling of a detailed simulation program with an efficient optimization method, namely the sequential quadratic programming (SQP) algorithm. This approach allows the use of accurate component models of the system as against empirical models as currently used, while providing efficient optimal solutions to be determined. We develop the mathematical basis of the methodology and apply it to a simple cooling plant system to illustrate the accuracy, efficiency and robustness of this method. The issue of implementing such an optimization under real-time control is also discussed.},
	author = {Jian Sun and Reddy, {T Agami}},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1016/j.buildenv.2004.08.011},
	issn = {0360-1323},
	journal = {Building and Environment},
	keywords = {Control, Cooling plants, HVAC\&R, Optimization, Simulation, SQP},
	language = {English (US)},
	month = {5},
	number = {5},
	pages = {657--669},
	publisher = {Elsevier BV},
	title = {Optimal control of building HVAC\&R systems using complete simulation-based sequential quadratic programming (CSB-SQP)},
	volume = {40},
	year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.buildenv.2004.08.011}}

@article{trajectory_optimization,
	author = {BETTS, JOHN T. and HUFFMAN, WILLIAM P.},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.2514/3.11428},
	eprint = {https://doi.org/10.2514/3.11428},
	journal = {Journal of Guidance, Control, and Dynamics},
	number = {1},
	pages = {59-68},
	title = {Path-constrained trajectory optimization using sparse sequential quadratic programming},
	url = {https://doi.org/10.2514/3.11428},
	volume = {16},
	year = {1993},
	Bdsk-Url-1 = {https://doi.org/10.2514/3.11428}}

@inproceedings{hvac_pid,
	author = {{Ya-Gang Wang} and {Zhi-Gang Shi} and {Wen-Jian Cai}},
	booktitle = {Proceedings of the 2001 American Control Conference. (Cat. No.01CH37148)},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1109/ACC.2001.946075},
	issn = {0743-1619},
	keywords = {HVAC;three-term control;feedback;identification;HVAC systems;PID autotuner;PID controller;continuous relay feedback;autotuning;relay feedback;frequency response;Open loop systems;Three-term control;Control systems;Relays;Pressure control;Electrical equipment industry;Feedback;Process control;Frequency estimation;Tuning},
	month = {June},
	pages = {2192-2196 vol.3},
	title = {PID autotuner and its application in HVAC systems},
	volume = {3},
	year = {2001},
	Bdsk-Url-1 = {https://doi.org/10.1109/ACC.2001.946075}}

@inproceedings{reward_shaping,
	acmid = {657613},
	address = {San Francisco, CA, USA},
	author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
	booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	isbn = {1-55860-612-2},
	numpages = {10},
	pages = {278--287},
	publisher = {Morgan Kaufmann Publishers Inc.},
	series = {ICML '99},
	title = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
	url = {http://dl.acm.org/citation.cfm?id=645528.657613},
	year = {1999},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=645528.657613}}

@inproceedings{practical_drl_radiant_heating,
	acmid = {3276775},
	address = {New York, NY, USA},
	author = {Zhang, Zhiang and Lam, Khee Poh},
	booktitle = {Proceedings of the 5th Conference on Systems for Built Environments},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1145/3276774.3276775},
	isbn = {978-1-4503-5951-1},
	keywords = {HVAC control, deep reinforcement learning, energy efficiency},
	location = {Shenzen, China},
	numpages = {10},
	pages = {148--157},
	publisher = {ACM},
	series = {BuildSys '18},
	title = {Practical Implementation and Evaluation of Deep Reinforcement Learning Control for a Radiant Heating System},
	url = {http://doi.acm.org/10.1145/3276774.3276775},
	year = {2018},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/3276774.3276775},
	Bdsk-Url-2 = {https://doi.org/10.1145/3276774.3276775}}

@article{hyperparameter_random_search,
	acmid = {2188395},
	author = {Bergstra, James and Bengio, Yoshua},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	issn = {1532-4435},
	issue_date = {3/1/2012},
	journal = {J. Mach. Learn. Res.},
	keywords = {deep learning, global optimization, model selection, neural networks, response surface modeling},
	month = feb,
	numpages = {25},
	pages = {281--305},
	publisher = {JMLR.org},
	title = {Random Search for Hyper-parameter Optimization},
	url = {http://dl.acm.org/citation.cfm?id=2188385.2188395},
	volume = {13},
	year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2188385.2188395}}

@article{rl_gym_env,
	archiveprefix = {arXiv},
	author = {Takao Moriyama and Giovanni De Magistris and Michiaki Tatsubori and Tu{-}Hoa Pham and Asim Munawar and Ryuki Tachibana},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/bib/journals/corr/abs-1808-10427},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	eprint = {1808.10427},
	journal = {CoRR},
	timestamp = {Mon, 03 Sep 2018 13:36:40 +0200},
	title = {Reinforcement Learning Testbed for Power-Consumption Optimization},
	url = {http://arxiv.org/abs/1808.10427},
	volume = {abs/1808.10427},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1808.10427}}

@article{supervisory_rule_based,
	author = {Shengwei Wang and Zhenjun Ma},
	date-added = {2020-07-25 14:24:01 -0700},
	date-modified = {2020-07-25 14:24:01 -0700},
	doi = {10.1080/10789669.2008.10390991},
	eprint = {https://www.tandfonline.com/doi/pdf/10.1080/10789669.2008.10390991},
	journal = {HVAC\&R Research},
	number = {1},
	pages = {3-32},
	publisher = {Taylor & Francis},
	title = {Supervisory and Optimal Control of Building HVAC Systems: A Review},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10789669.2008.10390991},
	volume = {14},
	year = {2008},
	Bdsk-Url-1 = {https://www.tandfonline.com/doi/abs/10.1080/10789669.2008.10390991},
	Bdsk-Url-2 = {https://doi.org/10.1080/10789669.2008.10390991}}

@inproceedings{npg,
	address = {Cambridge, MA, USA},
	author = {Kakade, Sham},
	booktitle = {Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	location = {Vancouver, British Columbia, Canada},
	numpages = {8},
	pages = {1531--1538},
	publisher = {MIT Press},
	series = {NIPS'01},
	title = {A Natural Policy Gradient},
	year = {2001}}

@article{random_sampling_shooting,
	author = {Rao, Anil},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {Advances in the Astronautical Sciences},
	month = {01},
	title = {A Survey of Numerical Methods for Optimal Control},
	volume = {135},
	year = {2010}}

@article{cross_entropy_method,
	author = {Pieter-Tjerk de Boer and Dirk P. Kroese and Shie Mannor and Reuven Y. Rubinstein},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {ANNALS OF OPERATIONS RESEARCH},
	title = {A tutorial on the cross-entropy method},
	volume = {134},
	year = {2004}}

@article{slbo,
	archiveprefix = {arXiv},
	author = {Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1807-03858.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1807.03858},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:22 +0200},
	title = {Algorithmic Framework for Model-based Reinforcement Learning with Theoretical Guarantees},
	url = {http://arxiv.org/abs/1807.03858},
	volume = {abs/1807.03858},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1807.03858}}

@misc{alphastarblog,
	author = {Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojtek and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	howpublished = {\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
	title = {{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}},
	year = {2019}}

@article{vae,
	author = {Diederik P. Kingma and Max Welling},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {CoRR},
	title = {Auto-Encoding Variational Bayes},
	volume = {abs/1312.6114},
	year = {2014}}

@inproceedings{batch_rl_smart_home,
	author = {Berlink, Heider and Costa, Anna Helena Reali},
	booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	isbn = {9781577357384},
	location = {Buenos Aires, Argentina},
	numpages = {7},
	pages = {2561--2567},
	publisher = {AAAI Press},
	series = {IJCAI'15},
	title = {Batch Reinforcement Learning for Smart Home Energy Management},
	year = {2015}}

@misc{wu2019behavior,
	archiveprefix = {arXiv},
	author = {Yifan Wu and George Tucker and Ofir Nachum},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1911.11361},
	primaryclass = {cs.LG},
	title = {Behavior Regularized Offline Reinforcement Learning},
	year = {2019}}

@article{ddpg,
	author = {Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Manfred Otto Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {CoRR},
	title = {Continuous control with deep reinforcement learning},
	volume = {abs/1509.02971},
	year = {2016}}

@url{dl_def,
	author = {Marshall Hargrave},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	month = {April},
	title = {Deep Learning},
	url = {https://www.investopedia.com/terms/d/deep-learning.asp},
	year = {2019},
	Bdsk-Url-1 = {https://www.investopedia.com/terms/d/deep-learning.asp}}

@book{deep_learning,
	author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	note = {\url{http://www.deeplearningbook.org}},
	publisher = {MIT Press},
	title = {Deep Learning},
	year = {2016}}

@article{pets,
	archiveprefix = {arXiv},
	author = {Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1805-12114.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1805.12114},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:23 +0200},
	title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
	url = {http://arxiv.org/abs/1805.12114},
	volume = {abs/1805.12114},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1805.12114}}

@article{dyna,
	address = {New York, NY, USA},
	author = {Sutton, Richard S.},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	doi = {10.1145/122344.122377},
	issn = {0163-5719},
	issue_date = {Aug. 1991},
	journal = {SIGART Bull.},
	month = jul,
	number = {4},
	numpages = {4},
	pages = {160--163},
	publisher = {Association for Computing Machinery},
	title = {Dyna, an Integrated Architecture for Learning, Planning, and Reacting},
	url = {https://doi.org/10.1145/122344.122377},
	volume = {2},
	year = {1991},
	Bdsk-Url-1 = {https://doi.org/10.1145/122344.122377}}

@book{dp_optimal_control,
	author = {Bertsekas, Dimitri P.},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	edition = {2nd},
	isbn = {1886529086},
	publisher = {Athena Scientific},
	title = {Dynamic Programming and Optimal Control, Two Volume Set},
	year = {2001}}

@article{er_real_time_rl_control,
	author = {S. {Adam} and L. {Busoniu} and R. {Babuska}},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	number = {2},
	pages = {201-212},
	title = {Experience Replay for Real-Time Reinforcement Learning Control},
	volume = {42},
	year = {2012}}

@article{poplin,
	archiveprefix = {arXiv},
	author = {Tingwu Wang and Jimmy Ba},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1906-08649.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1906.08649},
	journal = {CoRR},
	timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
	title = {Exploring Model-based Planning with Policy Networks},
	url = {http://arxiv.org/abs/1906.08649},
	volume = {abs/1906.08649},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1906.08649}}

@inproceedings{guided_policy_search,
	abstract = {Direct policy search can effectively scale to high-dimensional systems, but complex policies with hundreds of parameters often present a challenge for such methods, requiring numerous samples and often falling into poor local optima. We present a guided policy search algorithm that uses trajectory optimization to direct policy learning and avoid poor local optima. We show how differential dynamic programming can be used to generate suitable guiding samples, and describe a regularized importance sampled policy optimization that incorporates these samples into the policy search. We evaluate the method by learning neural network controllers for planar swimming, hopping, and walking, as well as simulated 3D humanoid running.},
	address = {Atlanta, Georgia, USA},
	author = {Sergey Levine and Vladlen Koltun},
	booktitle = {Proceedings of the 30th International Conference on Machine Learning},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	editor = {Sanjoy Dasgupta and David McAllester},
	month = {17--19 Jun},
	number = {3},
	pages = {1--9},
	pdf = {http://proceedings.mlr.press/v28/levine13.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Guided Policy Search},
	url = {http://proceedings.mlr.press/v28/levine13.html},
	volume = {28},
	year = {2013},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v28/levine13.html}}

@inproceedings{improving_pilco,
	author = {Rowan McAllister and Carl Edward Rasmussen},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	title = {Improving PILCO with Bayesian Neural Network Dynamics Models},
	year = {2016}}

@inproceedings{ilqr,
	author = {Li, Weiwei and Todorov, Emanuel},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {Proceedings of the 1st International Conference on Informatics in Control, Automation and Robotics, (ICINCO 2004)},
	month = {01},
	pages = {222-229},
	title = {Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems.},
	volume = {1},
	year = {2004}}

@book{mdp,
	address = {USA},
	author = {Puterman, Martin L.},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	edition = {1st},
	isbn = {0471619779},
	publisher = {John Wiley \& Sons, Inc.},
	title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
	year = {1994}}

@article{alphago,
	author = {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {Nature},
	pages = {484--503},
	title = {Mastering the game of Go with deep neural networks and tree search},
	url = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
	volume = {529},
	year = {2016},
	Bdsk-Url-1 = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html}}

@article{mppi,
	archiveprefix = {arXiv},
	author = {Grady Williams and Andrew Aldrich and Evangelos A. Theodorou},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/WilliamsAT15.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1509.01149},
	journal = {CoRR},
	timestamp = {Thu, 18 Jul 2019 16:08:56 +0200},
	title = {Model Predictive Path Integral Control using Covariance Variable Importance Sampling},
	url = {http://arxiv.org/abs/1509.01149},
	volume = {abs/1509.01149},
	year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1509.01149}}

@article{mbrl_atari,
	archiveprefix = {arXiv},
	author = {Lukasz Kaiser and Mohammad Babaeizadeh and Piotr Milos and Blazej Osinski and Roy H. Campbell and Konrad Czechowski and Dumitru Erhan and Chelsea Finn and Piotr Kozakowski and Sergey Levine and Ryan Sepassi and George Tucker and Henryk Michalewski},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1903-00374.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1903.00374},
	journal = {CoRR},
	timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
	title = {Model-Based Reinforcement Learning for Atari},
	url = {http://arxiv.org/abs/1903.00374},
	volume = {abs/1903.00374},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1903.00374}}

@article{model_based_value_expansion,
	archiveprefix = {arXiv},
	author = {Vladimir Feinberg and Alvin Wan and Ion Stoica and Michael I. Jordan and Joseph E. Gonzalez and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1803-00101.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1803.00101},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:50 +0200},
	title = {Model-Based Value Estimation for Efficient Model-Free Reinforcement Learning},
	url = {http://arxiv.org/abs/1803.00101},
	volume = {abs/1803.00101},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1803.00101}}

@article{me_trpo,
	archiveprefix = {arXiv},
	author = {Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1802-10592.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1802.10592},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:17 +0200},
	title = {Model-Ensemble Trust-Region Policy Optimization},
	url = {http://arxiv.org/abs/1802.10592},
	volume = {abs/1802.10592},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1802.10592}}

@misc{mopo,
	archiveprefix = {arXiv},
	author = {Tianhe Yu and Garrett Thomas and Lantao Yu and Stefano Ermon and James Zou and Sergey Levine and Chelsea Finn and Tengyu Ma},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {2005.13239},
	primaryclass = {cs.LG},
	title = {MOPO: Model-based Offline Policy Optimization},
	year = {2020}}

@misc{morel,
	archiveprefix = {arXiv},
	author = {Rahul Kidambi and Aravind Rajeswaran and Praneeth Netrapalli and Thorsten Joachims},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {2005.05951},
	primaryclass = {cs.LG},
	title = {MOReL : Model-Based Offline Reinforcement Learning},
	year = {2020}}

@inproceedings{mujoco,
	author = {E. {Todorov} and T. {Erez} and Y. {Tassa}},
	booktitle = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	pages = {5026-5033},
	title = {MuJoCo: A physics engine for model-based control},
	year = {2012}}

@article{mb_mf,
	archiveprefix = {arXiv},
	author = {Anusha Nagabandi and Gregory Kahn and Ronald S. Fearing and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1708-02596.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1708.02596},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:41 +0200},
	title = {Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning},
	url = {http://arxiv.org/abs/1708.02596},
	volume = {abs/1708.02596},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1708.02596}}

@article{normalizing_flow_intro_review,
	author = {Ivan Kobyzev and Simon Prince and Marcus A. Brubaker},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	title = {Normalizing Flows: An Introduction and Review of Current Methods.},
	year = {2020}}

@article{bcq,
	archiveprefix = {arXiv},
	author = {Scott Fujimoto and David Meger and Doina Precup},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1812-02900.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1812.02900},
	journal = {CoRR},
	timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
	title = {Off-Policy Deep Reinforcement Learning without Exploration},
	url = {http://arxiv.org/abs/1812.02900},
	volume = {abs/1812.02900},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1812.02900}}

@misc{openai_gym,
	author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {arXiv:1606.01540},
	title = {OpenAI Gym},
	year = {2016}}

@inproceedings{pilco,
	address = {Madison, WI, USA},
	author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
	booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	isbn = {9781450306195},
	location = {Bellevue, Washington, USA},
	numpages = {8},
	pages = {465--472},
	publisher = {Omnipress},
	series = {ICML'11},
	title = {PILCO: A Model-Based and Data-Efficient Approach to Policy Search},
	year = {2011}}

@article{dqn,
	archiveprefix = {arXiv},
	author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1312.5602},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
	title = {Playing Atari with Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1312.5602},
	volume = {abs/1312.5602},
	year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1312.5602}}

@misc{prioritized_experience_replay,
	abstract = {Experience replay lets online reinforcement learning agents remember and
reuse experiences from the past. In prior work, experience transitions were
uniformly sampled from a replay memory. However, this approach simply replays
transitions at the same frequency that they were originally experienced,
regardless of their significance. In this paper we develop a framework for
prioritizing experience, so as to replay important transitions more frequently,
and therefore learn more efficiently. We use prioritized experience replay in
Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved
human-level performance across many Atari games. DQN with prioritized
experience replay achieves a new state-of-the-art, outperforming DQN with
uniform replay on 41 out of 49 games.},
	added-at = {2019-11-17T22:17:21.000+0100},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	biburl = {https://www.bibsonomy.org/bibtex/2be47ebfc4c5eb8f06b374fe632a3e236/jan.hofmann1},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	description = {[1511.05952] Prioritized Experience Replay},
	interhash = {db6e4402b0807938aae61afc45b70f73},
	intrahash = {be47ebfc4c5eb8f06b374fe632a3e236},
	keywords = {final reinforcement_learning thema:double_dqn},
	note = {cite arxiv:1511.05952Comment: Published at ICLR 2016},
	timestamp = {2019-12-09T10:13:58.000+0100},
	title = {Prioritized Experience Replay},
	url = {http://arxiv.org/abs/1511.05952},
	year = 2015,
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.05952}}

@article{ppo,
	archiveprefix = {arXiv},
	author = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1707.06347},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
	title = {Proximal Policy Optimization Algorithms},
	url = {http://arxiv.org/abs/1707.06347},
	volume = {abs/1707.06347},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1707.06347}}

@article{q_learning,
	abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
	author = {Watkins, Christopher J. C. H. and Dayan, Peter},
	da = {1992/05/01},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	doi = {10.1007/BF00992698},
	id = {Watkins1992},
	isbn = {1573-0565},
	journal = {Machine Learning},
	number = {3},
	pages = {279--292},
	title = {Q-learning},
	ty = {JOUR},
	url = {https://doi.org/10.1007/BF00992698},
	volume = {8},
	year = {1992},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF00992698}}

@article{rl_survey,
	author = {Leslie Pack Kaelbling and Michael L. Littman and Andrew W. Moore},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/cs-AI-9605103.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	journal = {CoRR},
	timestamp = {Fri, 10 Jan 2020 12:58:17 +0100},
	title = {Reinforcement Learning: {A} Survey},
	url = {https://arxiv.org/abs/cs/9605103},
	volume = {cs.AI/9605103},
	year = {1996},
	Bdsk-Url-1 = {https://arxiv.org/abs/cs/9605103}}

@book{rl_intro,
	address = {Cambridge, MA, USA},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	isbn = {0262039249},
	publisher = {A Bradford Book},
	title = {Reinforcement Learning: An Introduction},
	year = {2018}}

@phdthesis{rl_robots_nn,
	address = {USA},
	author = {Lin, Long-Ji},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	publisher = {Carnegie Mellon University},
	title = {Reinforcement Learning for Robots Using Neural Networks},
	year = {1992}}

@misc{re_mbpo,
	author = {Xiaoyu Jiang and Qiuxuan Chen and Shiyi Han and Mingxuan Li and Jingyan Dong and Ruochen Zhang},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	howpublished = {https://openreview.net/pdf?id=SkgPIpcGar},
	title = {Replication of ``When to Trust Your Model: Model-Based Policy Optimization''}}

@article{steve,
	archiveprefix = {arXiv},
	author = {Jacob Buckman and Danijar Hafner and George Tucker and Eugene Brevdo and Honglak Lee},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1807-01675.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1807.01675},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:49:01 +0200},
	title = {Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion},
	url = {http://arxiv.org/abs/1807.01675},
	volume = {abs/1807.01675},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1807.01675}}

@article{sac_algo_apps,
	archiveprefix = {arXiv},
	author = {Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1812-05905.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1812.05905},
	journal = {CoRR},
	timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
	title = {Soft Actor-Critic Algorithms and Applications},
	url = {http://arxiv.org/abs/1812.05905},
	volume = {abs/1812.05905},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1812.05905}}

@article{sac,
	archiveprefix = {arXiv},
	author = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1801-01290.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1801.01290},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
	title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
	url = {http://arxiv.org/abs/1801.01290},
	volume = {abs/1801.01290},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1801.01290}}

@article{mbrl_latent_repr,
	archiveprefix = {arXiv},
	author = {Marvin Zhang and Sharad Vikram and Laura Smith and Pieter Abbeel and Matthew J. Johnson and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1808-09105.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1808.09105},
	journal = {CoRR},
	timestamp = {Wed, 31 Oct 2018 07:41:35 +0100},
	title = {{SOLAR:} Deep Structured Latent Representations for Model-Based Reinforcement Learning},
	url = {http://arxiv.org/abs/1808.09105},
	volume = {abs/1808.09105},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1808.09105}}

@article{bear,
	archiveprefix = {arXiv},
	author = {Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1906-00949.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1906.00949},
	journal = {CoRR},
	timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
	title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
	url = {http://arxiv.org/abs/1906.00949},
	volume = {abs/1906.00949},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1906.00949}}

@inproceedings{monte_carlo_sampling,
	author = {Nick Metropolis},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	title = {THE BEGINNING of the MONTE CARLO METHOD}}

@article{conjugate_gradient,
	address = {Berlin, Heidelberg},
	author = {Ginsburg, Theo},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	doi = {10.1007/BF01385890},
	issn = {0029-599X},
	issue_date = {December 1963},
	journal = {Numer. Math.},
	month = dec,
	number = {1},
	numpages = {10},
	pages = {191--200},
	publisher = {Springer-Verlag},
	title = {The Conjugate Gradient Method},
	url = {https://doi.org/10.1007/BF01385890},
	volume = {5},
	year = {1963},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF01385890}}

@article{trpo,
	archiveprefix = {arXiv},
	author = {John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/SchulmanLMJA15.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1502.05477},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:48:08 +0200},
	title = {Trust Region Policy Optimization},
	url = {http://arxiv.org/abs/1502.05477},
	volume = {abs/1502.05477},
	year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1502.05477}}

@book{understanding_ml,
	address = {USA},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	isbn = {1107057132},
	publisher = {Cambridge University Press},
	title = {Understanding Machine Learning: From Theory to Algorithms},
	year = {2014}}

@article{mbpo,
	archiveprefix = {arXiv},
	author = {Michael Janner and Justin Fu and Marvin Zhang and Sergey Levine},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1906-08253.bib},
	date-added = {2020-07-25 14:23:43 -0700},
	date-modified = {2020-07-25 14:23:43 -0700},
	eprint = {1906.08253},
	journal = {CoRR},
	timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
	title = {When to Trust Your Model: Model-Based Policy Optimization},
	url = {http://arxiv.org/abs/1906.08253},
	volume = {abs/1906.08253},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1906.08253}}
