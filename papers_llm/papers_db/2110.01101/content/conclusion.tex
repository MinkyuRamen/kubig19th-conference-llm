\section{Conclusions and Future Work}
In this work, we propose a framework for generating scalable RL implementations on processor with accelerator platforms. We propose to use parallel actors and learners to increase the throughput of the data collection and the data consumption. To support asynchronous actors and learners, we propose a Prioritized Replay Buffer based on $K$-ary sum tree data structure. We propose \textit{lazy writing} locking mechanism to minimize the synchronization effort. Our experiments demonstrate that our proposed framework is superior to baseline approaches. Given hardware resources, our framework can automatically generate the number of actor threads and learner threads such that the desired ratio between data collection and data consumption is met. Future work includes implementation of the learners on various accelerator types including GPU clusters and FPGAs.
