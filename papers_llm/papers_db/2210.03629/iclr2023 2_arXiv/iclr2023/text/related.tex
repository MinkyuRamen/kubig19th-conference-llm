\section{Related Work}

\myparagraph{Language model for reasoning}
Perhaps the most well-known work of using LLMs for reasoning is Chain-of-Thought (CoT)~\citep{wei2022chain}, which reveals the ability of LLMs to formulate their own ``thinking procedure'' for problem solving. Several follow-up works have since been performed, including least-to-most prompting for solving complicated tasks~\citep{zhou2022least}, zero-shot-CoT~\citep{kojima2022large}, and reasoning with self-consistency~\citep{wang2022self-consistency}. Recently, \citep{madaan2022text} systematically studied the formulation and structure of CoT, and observed that the presence of symbols, patterns and texts is crucial to the effectiveness of CoT.
Other work has also been extended to more sophisticated reasoning architecture beyond simple prompting. For example Selection-Inference~\citep{creswell2022selection} divides the reasoning process into two steps of ``selection'' and ``inference''. STaR~\citep{zelikman2022star} bootstraps the reasoning process by finetuning the model on correct rationales generated by the model itself. Faithful reasoning~\citep{creswell2022faithful} decomposes multi-step reasoning into three steps, each performed by a dedicated LM respectively. Similar approaches like Scratchpad~\citep{nye2021show}, which finetunes a LM on intermediate computation steps, also demonstrate improvement on multi-step computation problems.
In contrast to these methods, \model{} performs more than just isolated, fixed reasoning, and integrates model actions and their corresponding observations into a coherent stream of inputs for the model to reason more accurately and tackle tasks beyond reasoning (e.g.\,interactive decision making).

\myparagraph{Language model for decision making}
The strong capability of LLMs has enabled them to perform tasks beyond language generation, and it is becoming more popular to take advantage of LLMs as a policy model for decision making, especially in interactive environments. WebGPT \citep{nakano2021webgpt} 
uses an LM to interact with web browsers, navigate through web pages, and infer answers to complicated questions from ELI5 \citep{fan-etal-2019-eli5}. In comparison to \model, WebGPT does not explicitly model the thinking and reasoning procedure, instead rely on expensive human feedback for reinforcement learning.
In conversation modeling, chatbots like BlenderBot~\citep{shuster2022blenderbot3} and Sparrow~\citep{amelia2022improving} {and task-oriented dialogue systems like SimpleTOD~\citep{hosseini2020simple}} also train LMs to make decision about API calls. Unlike \model, they do not explicitly consider the reasoning procedure either, and also relies on expensive datasets and human feedback collections for policy learning. In contrast, \model{} learns a policy in a much cheaper way, since the decision making process only requires language description of the reasoning procedure.\footnote{Human feedback can also be incorporated in a complementary manner but we leave it for future work.}

LLMS have also been increasingly employed in interactive and embodied environments for planning and decision making. Perhaps most relevant to \model{} in this respect are SayCan~\citep{ahn2022do} and Inner Monologue~\citep{huang2022inner}, which use LLMs for robotic action planning and decision making. In SayCan, LLMs were prompted to directly predict possible actions a robot can take, which is then reranked by an affordance model grounded on the visual environments for final prediction. Inner Monologue made further improvements by adding the eponymous ``inner monologue", which is implemented as injected feedback from the environment. To our knowledge, Inner Monologue is the first work that demonstrates such a closed-loop system, which \model{} builds on. However, we argue that Inner Monologue does not truly comprise of inner thoughts --- this is elaborated in Section~\ref{decision_making_tasks}.
We also note that leveraging language as semantically-rich inputs in the process of interactive decision making has been shown to be successful under other settings~\citep{abramson2020imitating,siddaharth2021lila,huang2022language,li2022pretrained}. It is becoming more evident that with the help of LLMs, language as a fundamental cognitive mechanism will play a critical role in interaction and decision making. What is more, progress in LLMs has also inspired the development of versatile and generalist agents like \cite{reed2022gato}.




