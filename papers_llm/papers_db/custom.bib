@book{Aho:72,
 address = {Englewood Cliffs, NJ},
 author = {Alfred V. Aho and Jeffrey D. Ullman},
 publisher = {Prentice-Hall},
 title = {{The Theory of Parsing, Translation and Compiling}},
 volume = {1},
 year = {1972}
}

@article{ruan2023tptu,
 author = {Ruan, Jingqing and Chen, Yihong and Zhang, Bin and Xu, Zhiwei and Bao, Tianpeng and Du, Guoqing and Shi, Shiwei and Mao, Hangyu and Zeng, Xingyu and Zhao, Rui},
 journal = {ArXiv preprint},
 title = {{TPTU: Task planning and tool usage of large language model-based AI agents}},
 url = {https://arxiv.org/abs/2308.03427},
 volume = {abs/2308.03427},
 year = {2023}
}

@article{mialon2023augmented,
 author = {Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
 journal = {ArXiv preprint},
 title = {{Augmented Language Models: A Survey}},
 url = {https://arxiv.org/abs/2302.07842},
 volume = {abs/2302.07842},
 year = {2023}
}

@article{hsieh2023tool,
 author = {Hsieh, Cheng-Yu and Chen, Si-An and Li, Chun-Liang and Fujii, Yasuhisa and Ratner, Alexander and Lee, Chen-Yu and Krishna, Ranjay and Pfister, Tomas},
 journal = {ArXiv preprint},
 title = {Tool documentation enables zero-shot tool-usage with large language models},
 url = {https://arxiv.org/abs/2308.00675},
 volume = {abs/2308.00675},
 year = {2023}
}

@article{huang2023metatool,
 author = {Huang, Yue and Shi, Jiawen and Li, Yuan and Fan, Chenrui and Wu, Siyuan and Zhang, Qihui and Liu, Yixin and Zhou, Pan and Wan, Yao and Gong, Neil Zhenqiang and others},
 journal = {ArXiv preprint},
 title = {{MetaTool} benchmark for large language models: Deciding whether to use tools and which to use},
 url = {https://arxiv.org/abs/2310.03128},
 volume = {abs/2310.03128},
 year = {2023}
}

@article{chen2023fireact,
 author = {Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
 journal = {ArXiv preprint},
 title = {{FireAct}: Toward language agent fine-tuning},
 url = {https://arxiv.org/abs/2310.05915},
 volume = {abs/2310.05915},
 year = {2023}
}

@article{mialon2023gaia,
 author = {Mialon, Gr{\'e}goire and Fourrier, Cl{\'e}mentine and Swift, Craig and Wolf, Thomas and LeCun, Yann and Scialom, Thomas},
 journal = {ArXiv preprint},
 title = {{GAIA}: a benchmark for general {AI} assistants},
 url = {https://arxiv.org/abs/2311.12983},
 volume = {abs/2311.12983},
 year = {2023}
}

@article{wang2023mint,
 author = {Wang, Xingyao and Wang, Zihan and Liu, Jiateng and Chen, Yangyi and Yuan, Lifan and Peng, Hao and Ji, Heng},
 journal = {ArXiv preprint},
 title = {{MINT}: Evaluating {LLMs} in multi-turn interaction with tools and language feedback},
 url = {https://arxiv.org/abs/2309.10691},
 volume = {abs/2309.10691},
 year = {2023}
}

@inproceedings{mishra2021cross,
 address = {Dublin, Ireland},
 author = {Mishra, Swaroop  and
Khashabi, Daniel  and
Baral, Chitta  and
Hajishirzi, Hannaneh},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 doi = {10.18653/v1/2022.acl-long.244},
 pages = {3470--3487},
 publisher = {Association for Computational Linguistics},
 title = {{Cross-Task Generalization via Natural Language Crowdsourcing Instructions}},
 url = {https://aclanthology.org/2022.acl-long.244},
 year = {2022}
}

@inproceedings{wei2021finetuned,
 author = {Jason Wei and
Maarten Bosma and
Vincent Y. Zhao and
Kelvin Guu and
Adams Wei Yu and
Brian Lester and
Nan Du and
Andrew M. Dai and
Quoc V. Le},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/WeiBZGYLDDL22.bib},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 publisher = {OpenReview.net},
 timestamp = {Sat, 20 Aug 2022 01:00:00 +0200},
 title = {{Finetuned Language Models are Zero-Shot Learners}},
 url = {https://openreview.net/forum?id=gEZrGCozdqR},
 year = {2022}
}

@inproceedings{brown2020language,
 author = {Tom B. Brown and
Benjamin Mann and
Nick Ryder and
Melanie Subbiah and
Jared Kaplan and
Prafulla Dhariwal and
Arvind Neelakantan and
Pranav Shyam and
Girish Sastry and
Amanda Askell and
Sandhini Agarwal and
Ariel Herbert{-}Voss and
Gretchen Krueger and
Tom Henighan and
Rewon Child and
Aditya Ramesh and
Daniel M. Ziegler and
Jeffrey Wu and
Clemens Winter and
Christopher Hesse and
Mark Chen and
Eric Sigler and
Mateusz Litwin and
Scott Gray and
Benjamin Chess and
Jack Clark and
Christopher Berner and
Sam McCandlish and
Alec Radford and
Ilya Sutskever and
Dario Amodei},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/BrownMRSKDNSSAA20.bib},
 booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual},
 editor = {Hugo Larochelle and
Marc'Aurelio Ranzato and
Raia Hadsell and
Maria{-}Florina Balcan and
Hsuan{-}Tien Lin},
 timestamp = {Tue, 19 Jan 2021 00:00:00 +0100},
 title = {{Language Models are Few-Shot Learners}},
 url = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
 year = {2020}
}

@article{radford2019language,
 author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
 journal = {OpenAI blog},
 number = {8},
 pages = {9},
 title = {Language models are unsupervised multitask learners},
 volume = {1},
 year = {2019}
}

@article{liu2023controlllm,
 author = {Liu, Zhaoyang and Lai, Zeqiang and Gao, Zhangwei and Cui, Erfei and Li, Zhiheng and Zhu, Xizhou and Lu, Lewei and Chen, Qifeng and Qiao, Yu and Dai, Jifeng and others},
 journal = {ArXiv preprint},
 title = {Controlllm: Augment language models with tools by searching on graphs},
 url = {https://arxiv.org/abs/2310.17796},
 volume = {abs/2310.17796},
 year = {2023}
}

@misc{qin2023toolllm,
 archiveprefix = {arXiv},
 author = {Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
 eprint = {2307.16789},
 primaryclass = {cs.AI},
 title = {{ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}},
 year = {2023}
}

@misc{tang2023toolalpaca,
 archiveprefix = {arXiv},
 author = {Qiaoyu Tang and Ziliang Deng and Hongyu Lin and Xianpei Han and Qiao Liang and Le Sun},
 eprint = {2306.05301},
 primaryclass = {cs.CL},
 title = {{ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases}},
 year = {2023}
}

@misc{ye2024tooleyes,
 archiveprefix = {arXiv},
 author = {Junjie Ye and Guanyu Li and Songyang Gao and Caishuang Huang and Yilong Wu and Sixian Li and Xiaoran Fan and Shihan Dou and Qi Zhang and Tao Gui and Xuanjing Huang},
 eprint = {2401.00741},
 primaryclass = {cs.CL},
 title = {{ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios}},
 year = {2024}
}

@misc{xu2023tool,
 archiveprefix = {arXiv},
 author = {Qiantong Xu and Fenglu Hong and Bo Li and Changran Hu and Zhengyu Chen and Jian Zhang},
 eprint = {2305.16504},
 primaryclass = {cs.CL},
 title = {{On the Tool Manipulation Capability of Open-source Large Language Models}},
 year = {2023}
}

@misc{li2023apibank,
 archiveprefix = {arXiv},
 author = {Minghao Li and Feifan Song and Bowen Yu and Haiyang Yu and Zhoujun Li and Fei Huang and Yongbin Li},
 eprint = {2304.08244},
 primaryclass = {cs.CL},
 title = {{API-Bank: A Benchmark for Tool-Augmented LLMs}},
 year = {2023}
}

@misc{rozière2023code,
 archiveprefix = {arXiv},
 author = {Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
 eprint = {2308.12950},
 primaryclass = {cs.CL},
 title = {{Code Llama: Open Foundation Models for Code}},
 year = {2023}
}

@inproceedings{yao2023react,
 author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
 journal = {ArXiv preprint},
 title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
 url = {https://arxiv.org/abs/2210.03629},
 volume = {abs/2210.03629},
 year = {2022}
}

@article{lu2023chameleon,
 author = {Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
 journal = {ArXiv preprint},
 title = {{Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models}},
 url = {https://arxiv.org/abs/2304.09842},
 volume = {abs/2304.09842},
 year = {2023}
}

@misc{nakano2022webgpt,
 archiveprefix = {arXiv},
 author = {Reiichiro Nakano and Jacob Hilton and Suchir Balaji and Jeff Wu and Long Ouyang and Christina Kim and Christopher Hesse and Shantanu Jain and Vineet Kosaraju and William Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and Benjamin Chess and John Schulman},
 eprint = {2112.09332},
 primaryclass = {cs.CL},
 title = {{WebGPT: Browser-assisted question-answering with human feedback}},
 year = {2022}
}

@misc{chen2021evaluating,
 archiveprefix = {arXiv},
 author = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
 eprint = {2107.03374},
 primaryclass = {cs.LG},
 title = {{Evaluating Large Language Models Trained on Code}},
 year = {2021}
}

@misc{ling2023deductive,
 archiveprefix = {arXiv},
 author = {Zhan Ling and Yunhao Fang and Xuanlin Li and Zhiao Huang and Mingu Lee and Roland Memisevic and Hao Su},
 eprint = {2306.03872},
 primaryclass = {cs.CL},
 title = {{Deductive Verification of Chain-of-Thought Reasoning}},
 year = {2023}
}

@misc{weng2023large,
 archiveprefix = {arXiv},
 author = {Yixuan Weng and Minjun Zhu and Fei Xia and Bin Li and Shizhu He and Shengping Liu and Bin Sun and Kang Liu and Jun Zhao},
 eprint = {2212.09561},
 primaryclass = {cs.AI},
 title = {{Large Language Models are Better Reasoners with Self-Verification}},
 year = {2023}
}

@misc{touvron2023llama,
 archiveprefix = {arXiv},
 author = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
 eprint = {2302.13971},
 primaryclass = {cs.CL},
 title = {{LLaMA: Open and Efficient Foundation Language Models}},
 year = {2023}
}

@misc{kamalloo2023evaluating,
 archiveprefix = {arXiv},
 author = {Ehsan Kamalloo and Nouha Dziri and Charles L. A. Clarke and Davood Rafiei},
 eprint = {2305.06984},
 primaryclass = {cs.CL},
 title = {{Evaluating Open-Domain Question Answering in the Era of Large Language Models}},
 year = {2023}
}

@misc{openai2023gpt4,
 archiveprefix = {arXiv},
 author = {OpenAI},
 eprint = {2303.08774},
 primaryclass = {cs.CL},
 title = {{GPT-4 Technical Report}},
 year = {2023}
}

@misc{geminiteam2023gemini,
 archiveprefix = {arXiv},
 author = {{Gemini Team}},
 eprint = {2312.11805},
 primaryclass = {cs.CL},
 title ={ {Gemini: A Family of Highly Capable Multimodal Models}},
 year = {2023}
}

@misc{gpt4tools,
 archiveprefix = {arXiv},
 author = {Rui Yang and Lin Song and Yanwei Li and Sijie Zhao and Yixiao Ge and Xiu Li and Ying Shan},
 eprint = {2305.18752},
 primaryclass = {cs.CV},
 title = {{GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction}},
 year = {2023}
}

@article{patil2023gorilla,
 author = {Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
 journal = {ArXiv preprint},
 title = {{Gorilla: Large Language Model Connected with Massive APIs}},
 url = {https://arxiv.org/abs/2305.15334},
 volume = {abs/2305.15334},
 year = {2023}
}

@article{chen2023teval,
 author = {Chen, Zehui and Du, Weihua and Zhang, Wenwei and Liu, Kuikun and Liu, Jiangning and Zheng, Miao and Zhuo, Jingming and Zhang, Songyang and Lin, Dahua and Chen, Kai and others},
 journal = {ArXiv preprint},
 title = {{T-Eval: Evaluating the Tool Utilization Capability Step by Step}},
 url = {https://arxiv.org/abs/2312.14033},
 volume = {abs/2312.14033},
 year = {2023}
}

@inproceedings{langley00,
 author = {Pat Langley},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/Langley00.bib},
 booktitle = {Proceedings of the Seventeenth International Conference on Machine
Learning {(ICML} 2000), Stanford University, Stanford, CA, USA, June
29 - July 2, 2000},
 editor = {Pat Langley},
 pages = {1207--1216},
 publisher = {Morgan Kaufmann},
 timestamp = {Tue, 26 Nov 2002 00:00:00 +0100},
 title = {Crafting Papers on Machine Learning},
 year = {2000}
}

@techreport{mitchell80,
 address = {New Brunswick, MA},
 author = {T. M. Mitchell},
 institution = {Computer Science Department, Rutgers University},
 title = {{The Need for Biases in Learning Generalizations}},
 year = {1980}
}

@phdthesis{kearns89,
 author = {M. J. Kearns},
 school = {Department of Computer Science, Harvard University},
 title ={ {Computational Complexity of Machine Learning}},
 year = {1989}
}

@book{MachineLearningI,
 address = {Palo Alto, CA},
 editor = {R. S. Michalski and J. G. Carbonell and T.
M. Mitchell},
 publisher = {Tioga},
 title = {{Machine Learning: An Artificial Intelligence
Approach, Vol. I}},
 year = {1983}
}

@book{DudaHart2nd,
 author = {R. O. Duda and P. E. Hart and D. G. Stork},
 edition = {2nd},
 publisher = {John Wiley and Sons},
 title = {Pattern Classification},
 year = {2000}
}

@misc{anonymous,
 author = {Author, N. N.},
 title = {Suppressed for Anonymity},
 year = {2021}
}

@incollection{Newell81,
 address = {Hillsdale, NJ},
 author = {A. Newell and P. S. Rosenbloom},
 booktitle = {Cognitive Skills and Their Acquisition},
 chapter = {1},
 editor = {J. R. Anderson},
 pages = {1--51},
 publisher = {Lawrence Erlbaum Associates, Inc.},
 title = {Mechanisms of Skill Acquisition and the Law of
Practice},
 year = {1981}
}

@article{Samuel59,
 author = {A. L. Samuel},
 journal = {IBM Journal of Research and Development},
 number = {3},
 pages = {211--229},
 title = {Some Studies in Machine Learning Using the Game of
Checkers},
 volume = {3},
 year = {1959}
}

@book{APA:83,
 address = {Washington, DC},
 author = {{American Psychological Association}},
 publisher = {American Psychological Association},
 title = {Publications Manual},
 year = {1983}
}

@article{Chandra:81,
 author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
 doi = {10.1145/322234.322243},
 journal = {Journal of the Association for Computing Machinery},
 number = {1},
 pages = {114--133},
 title = {Alternation},
 volume = {28},
 year = {1981}
}

@inproceedings{andrew2007scalable,
 author = {Andrew, Galen and Gao, Jianfeng},
 booktitle = {Proc. of ICML},
 pages = {33--40},
 title = {Scalable training of {L1}-regularized log-linear models},
 year = {2007}
}

@book{Gusfield:97,
 address = {Cambridge, UK},
 author = {Dan Gusfield},
 publisher = {Cambridge University Press},
 title = {Algorithms on Strings, Trees and Sequences},
 year = {1997}
}

@article{rasooli-tetrault-2015,
 author = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
 journal = {ArXiv preprint},
 title = {Yara Parser: {A} Fast and Accurate Dependency Parser},
 url = {https://arxiv.org/abs/1503.06733},
 volume = {abs/1503.06733},
 year = {2015}
}

@article{Ando2005,
 acmid = {1194905},
 author = {Ando, Rie Kubota and Zhang, Tong},
 issn = {1532-4435},
 issue_date = {12/1/2005},
 journal = {Journal of Machine Learning Research},
 numpages = {37},
 pages = {1817--1853},
 publisher = {JMLR.org},
 title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
 volume = {6},
 year = {2005}
}

@article{qin2023tool,
 author = {Qin, Yujia and Hu, Shengding and Lin, Yankai and Chen, Weize and Ding, Ning and Cui, Ganqu and Zeng, Zheni and Huang, Yufei and Xiao, Chaojun and Han, Chi and others},
 journal = {ArXiv preprint},
 title = {Tool learning with foundation models},
 url = {https://arxiv.org/abs/2304.08354},
 volume = {abs/2304.08354},
 year = {2023}
}

@article{ye2023large,
 author = {Ye, Yining and Cong, Xin and Qin, Yujia and Lin, Yankai and Liu, Zhiyuan and Sun, Maosong},
 journal = {ArXiv preprint},
 title = {{Large Language Model as Autonomous Decision Maker}},
 url = {https://arxiv.org/abs/2308.12519},
 volume = {abs/2308.12519},
 year = {2023}
}

@article{liu2023llm+,
 author = {Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
 journal = {ArXiv preprint},
 title = {{LLM+P: Empowering Large Language Models with Optimal Planning Proficiency}},
 url = {https://arxiv.org/abs/2304.11477},
 volume = {abs/2304.11477},
 year = {2023}
}

@article{yang2023mm,
 author = {Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Azarnasab, Ehsan and Ahmed, Faisal and Liu, Zicheng and Liu, Ce and Zeng, Michael and Wang, Lijuan},
 journal = {ArXiv preprint},
 title = {{MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action}},
 url = {https://arxiv.org/abs/2303.11381},
 volume = {abs/2303.11381},
 year = {2023}
}

@article{song2022llm,
 author = {Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
 journal = {ArXiv preprint},
 title = {{LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models}},
 url = {https://arxiv.org/abs/2212.04088},
 volume = {abs/2212.04088},
 year = {2022}
}

@article{hao2023reasoning,
 author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
 journal = {ArXiv preprint},
 title = {{Reasoning with language model is planning with world model}},
 url = {https://arxiv.org/abs/2305.14992},
 volume = {abs/2305.14992},
 year = {2023}
}

@article{wang2023describe,
 author = {Wang, Zihao and Cai, Shaofei and Liu, Anji and Ma, Xiaojian and Liang, Yitao},
 journal = {ArXiv preprint},
 title = {{Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents}},
 url = {https://arxiv.org/abs/2302.01560},
 volume = {abs/2302.01560},
 year = {2023}
}

@article{gur2023real,
 author = {Gur, Izzeddin and Furuta, Hiroki and Huang, Austin and Safdari, Mustafa and Matsuo, Yutaka and Eck, Douglas and Faust, Aleksandra},
 journal = {ArXiv preprint},
 title = {A real-world webagent with planning, long context understanding, and program synthesis},
 url = {https://arxiv.org/abs/2307.12856},
 volume = {abs/2307.12856},
 year = {2023}
}

@article{qiao2023making,
 author = {Qiao, Shuofei and Gui, Honghao and Chen, Huajun and Zhang, Ningyu},
 journal = {ArXiv preprint},
 title = {{Making Language Models Better Tool Learners with Execution Feedback}},
 url = {https://arxiv.org/abs/2305.13068},
 volume = {abs/2305.13068},
 year = {2023}
}

@article{gao2023assistgpt,
 author = {Gao, Difei and Ji, Lei and Zhou, Luowei and Lin, Kevin Qinghong and Chen, Joya and Fan, Zihan and Shou, Mike Zheng},
 journal = {ArXiv preprint},
 title = {{AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn}},
 url = {https://arxiv.org/abs/2306.08640},
 volume = {abs/2306.08640},
 year = {2023}
}

@article{yang2023gpt4tools,
 author = {Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying},
 journal = {ArXiv preprint},
 title = {{GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction}},
 url = {https://arxiv.org/abs/2305.18752},
 volume = {abs/2305.18752},
 year = {2023}
}

@article{zhuang2023toolqa,
 author = {Zhuang, Yuchen and Yu, Yue and Wang, Kuan and Sun, Haotian and Zhang, Chao},
 journal = {ArXiv preprint},
 title = {{ToolQA: A Dataset for LLM Question Answering with External Tools}},
 url = {https://arxiv.org/abs/2306.13304},
 volume = {abs/2306.13304},
 year = {2023}
}

@article{deng2023mind2web,
 author = {Deng, Xiang and Gu, Yu and Zheng, Boyuan and Chen, Shijie and Stevens, Samuel and Wang, Boshi and Sun, Huan and Su, Yu},
 journal = {ArXiv preprint},
 title = {{Mind2Web: Towards a Generalist Agent for the Web}},
 url = {https://arxiv.org/abs/2306.06070},
 volume = {abs/2306.06070},
 year = {2023}
}

@article{touvron2023llama2,
 author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
 journal = {ArXiv preprint},
 title = {{Llama 2: Open foundation and fine-tuned chat models}},
 url = {https://arxiv.org/abs/2307.09288},
 volume = {abs/2307.09288},
 year = {2023}
}

@article{zhou2023webarena,
 author = {Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others},
 journal = {ArXiv preprint},
 title = {{WebArena: A Realistic Web Environment for Building Autonomous Agents}},
 url = {https://arxiv.org/abs/2307.13854},
 volume = {abs/2307.13854},
 year = {2023}
}

@misc{openaichatgptblog,
 author = {OpenAI},
 title = {Open{AI}: Introducing {ChatGPT}},
 url = {https://openai.com/blog/chatgpt},
 year = {2022}
}

@article{qin2023webcpm,
 author = {Qin, Yujia and Cai, Zihan and Jin, Dian and Yan, Lan and Liang, Shihao and Zhu, Kunlun and Lin, Yankai and Han, Xu and Ding, Ning and Wang, Huadong and others},
 journal = {ArXiv preprint},
 title = {{WebCPM: Interactive Web Search for Chinese Long-form Question Answering}},
 url = {https://arxiv.org/abs/2305.06849},
 volume = {abs/2305.06849},
 year = {2023}
}

@article{cobbe2021training,
 author = {Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
 journal = {ArXiv preprint},
 title = {Training verifiers to solve math word problems},
 url = {https://arxiv.org/abs/2110.14168},
 volume = {abs/2110.14168},
 year = {2021}
}

@article{nakano2021webgpt,
 author = {Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
 journal = {ArXiv preprint},
 title = {{WebGPT: Browser-assisted question-answering with human feedback}},
 url = {https://arxiv.org/abs/2112.09332},
 volume = {abs/2112.09332},
 year = {2021}
}

@article{schick2023toolformer,
 author = {Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
 journal = {ArXiv preprint},
 title = {{Toolformer: Language Models Can Teach Themselves to Use Tools}},
 url = {https://arxiv.org/abs/2302.04761},
 volume = {abs/2302.04761},
 year = {2023}
}

@inproceedings{NEURIPS2022_82ad13ec_webshop,
 author = {Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
 booktitle = {{In Proceedings of the Advances in Neural Information Processing Systems (NeurIPS 2022)}},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {20744--20757},
 publisher = {Curran Associates, Inc.},
 title = {{WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents}},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{cai2024large,
 author = {Tianle Cai and Xuezhi Wang and Tengyu Ma and Xinyun Chen and Denny Zhou},
 booktitle = {{Proc. of The Twelfth International Conference on Learning Representations (ICLR 2024)}},
 title = {{Large Language Models as Tool Makers}},
 url = {https://openreview.net/forum?id=qV83K9d5WB},
 year = {2024}
}

@inproceedings{qin-etal-2023-webcpm,
 abstract = {Long-form question answering (LFQA) aims at answering complex, open-ended questions with detailed, paragraph-length responses. The de facto paradigm of LFQA necessitates two procedures: information retrieval, which searches for relevant supporting facts, and information synthesis, which integrates these facts into a coherent answer. In this paper, we introduce WebCPM, the first Chinese LFQA dataset. One unique feature of WebCPM is that its information retrieval is based on interactive web search, which engages with a search engine in real time. Following WebGPT, we develop a web search interface. We recruit annotators to search for relevant information using our interface and then answer questions. Meanwhile, the web search behaviors of our annotators would be recorded. In total, we collect 5,500 high-quality question-answer pairs, together with 15,372 supporting facts and 125,954 web search actions. We fine-tune pre-trained language models to imitate human behaviors for web search and to generate answers based on the collected facts. Our LFQA pipeline, built on these fine-tuned models, generates answers that are no worse than human-written ones in 32.5{\%} and 47.5{\%} of the cases on our dataset and DuReader, respectively. The interface, dataset, and codes are publicly available at \url{https://github.com/thunlp/WebCPM}.},
 address = {Toronto, Canada},
 author = {Qin, Yujia  and
Cai, Zihan  and
Jin, Dian  and
Yan, Lan  and
Liang, Shihao  and
Zhu, Kunlun  and
Lin, Yankai  and
Han, Xu  and
Ding, Ning  and
Wang, Huadong  and
Xie, Ruobing  and
Qi, Fanchao  and
Liu, Zhiyuan  and
Sun, Maosong  and
Zhou, Jie},
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
 doi = {10.18653/v1/2023.acl-long.499},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 pages = {8968--8988},
 publisher = {Association for Computational Linguistics},
 title = {{W}eb{CPM}: Interactive Web Search for {C}hinese Long-form Question Answering},
 url = {https://aclanthology.org/2023.acl-long.499},
 year = {2023}
}

@misc{alpaca,
 author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
 howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
 journal = {GitHub repository},
 publisher = {GitHub},
 title = {{Stanford Alpaca: An Instruction-following LLaMA model}},
 year = {2023}
}

@misc{vicuna2023,
 author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
 title = {{Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality}},
 url = {https://lmsys.org/blog/2023-03-30-vicuna/},
 year = {2023}
}

@inproceedings{hu2021lora,
 author = {Edward J. Hu and
Yelong Shen and
Phillip Wallis and
Zeyuan Allen{-}Zhu and
Yuanzhi Li and
Shean Wang and
Lu Wang and
Weizhu Chen},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/HuSWALWWC22.bib},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 publisher = {OpenReview.net},
 timestamp = {Sat, 20 Aug 2022 01:00:00 +0200},
 title ={ {LoRA: Low-Rank Adaptation of Large Language Models}},
 url = {https://openreview.net/forum?id=nZeVKeeFYf9},
 year = {2022}
}

@article{ding2022delta,
 author = {Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
 journal = {ArXiv preprint},
 title = {{Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models}},
 url = {https://arxiv.org/abs/2203.06904},
 volume = {abs/2203.06904},
 year = {2022}
}

@article{ding2023enhancing,
 author = {Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
 journal = {ArXiv preprint},
 title = {{Enhancing Chat Language Models by Scaling High-quality Instructional Conversations}},
 url = {https://arxiv.org/abs/2305.14233},
 volume = {abs/2305.14233},
 year = {2023}
}

@article{wang2022self,
 author = {Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
 journal = {ArXiv preprint},
 title = {{Self-Instruct: Aligning Language Model with Self Generated Instructions}},
 url = {https://arxiv.org/abs/2212.10560},
 volume = {abs/2212.10560},
 year = {2022}
}

@article{li2023api,
 author = {Li, Minghao and Song, Feifan and Yu, Bowen and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
 journal = {ArXiv preprint},
 title = {{API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs}},
 url = {https://arxiv.org/abs/2304.08244},
 volume = {abs/2304.08244},
 year = {2023}
}

@article{song2023restgpt,
 author = {Song, Yifan and Xiong, Weimin and Zhu, Dawei and Li, Cheng and Wang, Ke and Tian, Ye and Li, Sujian},
 journal = {ArXiv preprint},
 title = {{RestGPT: Connecting Large Language Models with Real-World Applications via RESTful APIs}},
 url = {https://arxiv.org/abs/2306.06624},
 volume = {abs/2306.06624},
 year = {2023}
}

@article{wang2023improving,
 author = {Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
 journal = {ArXiv preprint},
 title = {{Improving Text Embeddings with Large Language Models}},
 url = {https://arxiv.org/abs/2401.00368},
 volume = {abs/2401.00368},
 year = {2024}
}

@article{wang2022text,
 author = {Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
 journal = {ArXiv preprint},
 title = {{Text Embeddings by Weakly-Supervised Contrastive Pre-training}},
 url = {https://arxiv.org/abs/2212.03533},
 volume = {abs/2212.03533},
 year = {2022}
}

@misc{yuan2024easytool,
 archiveprefix = {arXiv},
 author = {Siyu Yuan and Kaitao Song and Jiangjie Chen and Xu Tan and Yongliang Shen and Ren Kan and Dongsheng Li and Deqing Yang},
 eprint = {2401.06201},
 primaryclass = {cs.CL},
 title = {{EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction}},
 year = {2024}
}

@inproceedings{MacQueen1967SomeMF,
 author = {J. MacQueen},
 title = {{Some methods for classification and analysis of multivariate observations}},
 url = {https://api.semanticscholar.org/CorpusID:6278891},
 year = {1967}
}

@inbook{Turing2009,
 abstract = {I propose to consider the question, ``Can machines think?''♣ This should begin with definitions of the meaning of the terms ``machine'' and ``think''. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words ``machine'' and ``think'' are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, ``Can machines think?'' is to be sought in a statistical survey such as a Gallup poll.},
 address = {Dordrecht},
 author = {Turing, Alan M.},
 booktitle = {Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer},
 doi = {10.1007/978-1-4020-6710-5_3},
 editor = {Epstein, Robert
and Roberts, Gary
and Beber, Grace},
 isbn = {978-1-4020-6710-5},
 pages = {23--65},
 publisher = {Springer Netherlands},
 title = {{Computing Machinery and Intelligence}},
 url = {https://doi.org/10.1007/978-1-4020-6710-5_3},
 year = {2009}
}

@article{bubeck2023sparks,
 author = {Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
 journal = {ArXiv preprint},
 title = {{Sparks of Artificial General Intelligence: Early experiments with GPT-4}},
 url = {https://arxiv.org/abs/2303.12712},
 volume = {abs/2303.12712},
 year = {2023}
}

@misc{wei2023chainofthought,
 archiveprefix = {arXiv},
 author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
 eprint = {2201.11903},
 primaryclass = {cs.CL},
 title = {{Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}},
 year = {2023}
}

@article{yao2022react,
 author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
 journal = {ArXiv preprint},
 title = {{ReAct: Synergizing Reasoning and Acting in Language Models}},
 url = {https://arxiv.org/abs/2210.03629},
 volume = {abs/2210.03629},
 year = {2022}
}

@inproceedings{gupta2023visual,
 author = {Gupta, Tanmay and Kembhavi, Aniruddha},
 booktitle = {{In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023)}},
 pages = {14953--14962},
 title = {Visual programming: Compositional visual reasoning without training},
 year = {2023}
}

@article{jin2023genegpt,
 abstract = {{While large language models (LLMs) have been successfully applied to various tasks, they still face challenges with hallucinations. Augmenting LLMs with domain-specific tools such as database utilities can facilitate easier and more precise access to specialized knowledge. In this article, we present GeneGPT, a novel method for teaching LLMs to use the Web APIs of the National Center for Biotechnology Information (NCBI) for answering genomics questions. Specifically, we prompt Codex to solve the GeneTuring tests with NCBI Web APIs by in-context learning and an augmented decoding algorithm that can detect and execute API calls.Experimental results show that GeneGPT achieves state-of-the-art performance on eight tasks in the GeneTuring benchmark with an average score of 0.83, largely surpassing retrieval-augmented LLMs such as the new Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as well as GPT-3 (0.16) and ChatGPT (0.12). Our further analyses suggest that: First, API demonstrations have good cross-task generalizability and are more useful than documentations for in-context learning; second, GeneGPT can generalize to longer chains of API calls and answer multi-hop questions in GeneHop, a novel dataset introduced in this work; finally, different types of errors are enriched in different tasks, providing valuable insights for future improvements.The GeneGPT code and data are publicly available at https://github.com/ncbi/GeneGPT.}},
 author = {Jin, Qiao and Yang, Yifan and Chen, Qingyu and Lu, Zhiyong},
 doi = {10.1093/bioinformatics/btae075},
 eprint = {https://academic.oup.com/bioinformatics/article-pdf/40/2/btae075/56803364/btae075.pdf},
 issn = {1367-4811},
 journal = {Bioinformatics},
 number = {2},
 pages = {btae075},
 title = {{GeneGPT: augmenting large language models with domain tools for improved access to biomedical information}},
 url = {https://doi.org/10.1093/bioinformatics/btae075},
 volume = {40},
 year = {2024}
}

@article{yang2023chatgpt,
 author = {Yang, Linyao and Chen, Hongyang and Li, Zhao and Ding, Xiao and Wu, Xindong},
 journal = {ArXiv preprint},
 title = {{ChatGPT is not Enough: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling}},
 url = {https://arxiv.org/abs/2306.11489},
 volume = {abs/2306.11489},
 year = {2023}
}

@techreport{vemprala2023chatgpt,
 author = {Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
 institution = {Microsoft},
 number = {MSR-TR-2023-8},
 title = {{ChatGPT for Robotics: Design Principles and Model Abilities}},
 year = {2023}
}

@misc{shen2023hugginggpt,
 archiveprefix = {arXiv},
 author = {Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},
 eprint = {2303.17580},
 primaryclass = {cs.CL},
 title = {{HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace}},
 year = {2023}
}

@article{wu2023visual,
 author = {Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
 journal = {ArXiv preprint},
 title = {{Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models}},
 url = {https://arxiv.org/abs/2303.04671},
 volume = {abs/2303.04671},
 year = {2023}
}

@article{hao2023toolkengpt,
 author = {Hao, Shibo and Liu, Tianyang and Wang, Zhen and Hu, Zhiting},
 journal = {ArXiv preprint},
 title = {{ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings}},
 url = {https://arxiv.org/abs/2305.11554},
 volume = {abs/2305.11554},
 year = {2023}
}

@article{qian2023creator,
 author = {Qian, Cheng and Han, Chi and Fung, Yi R and Qin, Yujia and Liu, Zhiyuan and Ji, Heng},
 journal = {ArXiv preprint},
 title = {{CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation}},
 url = {https://arxiv.org/abs/2305.14318},
 volume = {abs/2305.14318},
 year = {2023}
}

@article{xu2023baize,
 author = {Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
 journal = {ArXiv preprint},
 title = {{Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data}},
 url = {https://arxiv.org/abs/2304.01196},
 volume = {abs/2304.01196},
 year = {2023}
}

@misc{xu2023wizardlm,
 archiveprefix = {arXiv},
 author = {Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
 eprint = {2304.12244},
 primaryclass = {cs.CL},
 title = {{WizardLM: Empowering Large Language Models to Follow Complex Instructions}},
 year = {2023}
}

@article{penedo2023refinedweb,
 author = {Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
 journal = {ArXiv preprint},
 title = {{The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only}},
 url = {https://arxiv.org/abs/2306.01116},
 volume = {abs/2306.01116},
 year = {2023}
}

@inproceedings{mishra2022cross,
 address = {Dublin, Ireland},
 author = {Mishra, Swaroop  and
Khashabi, Daniel  and
Baral, Chitta  and
Hajishirzi, Hannaneh},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 doi = {10.18653/v1/2022.acl-long.244},
 pages = {3470--3487},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
 url = {https://aclanthology.org/2022.acl-long.244},
 year = {2022}
}

@article{robertson2009probabilistic,
 author = {Robertson, Stephen and Zaragoza, Hugo and others},
 journal = {Foundations and Trends{\textregistered} in Information Retrieval},
 number = {4},
 pages = {333--389},
 publisher = {Now Publishers, Inc.},
 title = {The probabilistic relevance framework: BM25 and beyond},
 volume = {3},
 year = {2009}
}

@inproceedings{devlin2018bert,
 address = {Minneapolis, Minnesota},
 author = {Devlin, Jacob  and
Chang, Ming-Wei  and
Lee, Kenton  and
Toutanova, Kristina},
 booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
 doi = {10.18653/v1/N19-1423},
 pages = {4171--4186},
 publisher = {Association for Computational Linguistics},
 title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
 url = {https://aclanthology.org/N19-1423},
 year = {2019}
}

@article{chen2023extending,
 author = {Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
 journal = {ArXiv preprint},
 title = {{Extending Context Window of Large Language Models via Positional Interpolation}},
 url = {https://arxiv.org/abs/2306.15595},
 volume = {abs/2306.15595},
 year = {2023}
}

@inproceedings{reimers2019sentence,
 address = {Hong Kong, China},
 author = {Reimers, Nils  and
Gurevych, Iryna},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 doi = {10.18653/v1/D19-1410},
 pages = {3982--3992},
 publisher = {Association for Computational Linguistics},
 title = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
 url = {https://aclanthology.org/D19-1410},
 year = {2019}
}

@inproceedings{bach2022promptsource,
 address = {Dublin, Ireland},
 author = {Bach, Stephen  and
Sanh, Victor  and
Yong, Zheng Xin  and
Webson, Albert  and
Raffel, Colin  and
Nayak, Nihal V.  and
Sharma, Abheesht  and
Kim, Taewoon  and
Bari, M Saiful  and
Fevry, Thibault  and
Alyafeai, Zaid  and
Dey, Manan  and
Santilli, Andrea  and
Sun, Zhiqing  and
Ben-david, Srulik  and
Xu, Canwen  and
Chhablani, Gunjan  and
Wang, Han  and
Fries, Jason  and
Al-shaibani, Maged  and
Sharma, Shanya  and
Thakker, Urmish  and
Almubarak, Khalid  and
Tang, Xiangru  and
Radev, Dragomir  and
Jiang, Mike Tian-jian  and
Rush, Alexander},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
 doi = {10.18653/v1/2022.acl-demo.9},
 pages = {93--104},
 publisher = {Association for Computational Linguistics},
 title = {{P}rompt{S}ource: An Integrated Development Environment and Repository for Natural Language Prompts},
 url = {https://aclanthology.org/2022.acl-demo.9},
 year = {2022}
}

@article{yao2023tree,
 author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
 journal = {ArXiv preprint},
 title = {Tree of thoughts: Deliberate problem solving with large language models},
 url = {https://arxiv.org/abs/2305.10601},
 volume = {abs/2305.10601},
 year = {2023}
}

@misc{shinn2023reflexion,
 archiveprefix = {arXiv},
 author = {Noah Shinn and Federico Cassano and Beck Labash and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
 eprint = {2303.11366},
 primaryclass = {cs.AI},
 title = {Reflexion: Language Agents with Verbal Reinforcement Learning},
 year = {2023}
}

@article{huang2022inner,
 author = {Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
 journal = {ArXiv preprint},
 title ={ {Inner monologue: Embodied reasoning through planning with language models}},
 url = {https://arxiv.org/abs/2207.05608},
 volume = {abs/2207.05608},
 year = {2022}
}

@inproceedings{huang2022language,
 author = {Wenlong Huang and
Pieter Abbeel and
Deepak Pathak and
Igor Mordatch},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/HuangAPM22.bib},
 booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
2022, Baltimore, Maryland, {USA}},
 editor = {Kamalika Chaudhuri and
Stefanie Jegelka and
Le Song and
Csaba Szepesv{\'{a}}ri and
Gang Niu and
Sivan Sabato},
 pages = {9118--9147},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Tue, 12 Jul 2022 01:00:00 +0200},
 title = {Language Models as Zero-Shot Planners: Extracting Actionable Knowledge
for Embodied Agents},
 url = {https://proceedings.mlr.press/v162/huang22a.html},
 volume = {162},
 year = {2022}
}

@article{ahn2022can,
 author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
 journal = {ArXiv preprint},
 title = {{Do As I Can, Not As I Say: Grounding Language in Robotic Affordances}},
 url = {https://arxiv.org/abs/2204.01691},
 volume = {abs/2204.01691},
 year = {2022}
}

@article{mcinnes2018umap-software,
 author = {McInnes, Leland and Healy, John and Saul, Nathaniel and Grossberger, Lukas},
 journal = {The Journal of Open Source Software},
 number = {29},
 pages = {861},
 title = {{UMAP: Uniform Manifold Approximation and Projection}},
 volume = {3},
 year = {2018}
}

@inproceedings{reimers-2019-sentence-bert,
 address = {Hong Kong, China},
 author = {Reimers, Nils  and
Gurevych, Iryna},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 doi = {10.18653/v1/D19-1410},
 pages = {3982--3992},
 publisher = {Association for Computational Linguistics},
 title = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
 url = {https://aclanthology.org/D19-1410},
 year = {2019}
}

@misc{alpaca_eval,
 author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
 howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}},
 journal = {GitHub repository},
 publisher = {GitHub},
 title = {{AlpacaEval: An Automatic Evaluator of Instruction-following Models}},
 year = {2023}
}

@inproceedings{karpukhin-etal-2020-dense,
 address = {Online},
 author = {Karpukhin, Vladimir  and
Oguz, Barlas  and
Min, Sewon  and
Lewis, Patrick  and
Wu, Ledell  and
Edunov, Sergey  and
Chen, Danqi  and
Yih, Wen-tau},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 doi = {10.18653/v1/2020.emnlp-main.550},
 pages = {6769--6781},
 publisher = {Association for Computational Linguistics},
 title = {{Dense Passage Retrieval for Open-Domain Question Answering}},
 url = {https://aclanthology.org/2020.emnlp-main.550},
 year = {2020}
}

@article{jarvelin2002cumulated,
 author = {J{\"a}rvelin, Kalervo and Kek{\"a}l{\"a}inen, Jaana},
 journal = {ACM Transactions on Information Systems (TOIS)},
 number = {4},
 pages = {422--446},
 publisher = {ACM New York, NY, USA},
 title = {Cumulated gain-based evaluation of IR techniques},
 volume = {20},
 year = {2002}
}
