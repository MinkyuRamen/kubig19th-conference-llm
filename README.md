# kubig19th-conference-llm
## ëª©í‘œ (ìˆ˜ì •ê°€ëŠ¥)
1. Llama-3-8bë¡œ (ì•„ì¹´ì´ë¸Œ, Semantic Scholoar)ë¥¼ function callë¡œ ë„£ì–´ì„œ data generation í›„ huggingfaceì— ì €ì¥ (original data)
2. ì €ì¥ëœ original dataë¥¼ streamìœ¼ë¡œ ë¶ˆëŸ¬ì™€ ì •ì˜ëœ tool (wikipedia search, google search, wolfram alpha, calendar ë“±)ì„ ì´ìš©í•˜ì—¬ data augmented (augmented data)
3. [training] augmented dataë¥¼ ì´ìš©í•˜ì—¬ LoRA fine-tuning (ToolLLaMA)
4. [inference] ToolLLaMAì—ë‹¤ê°€ (ì•„ì¹´ì´ë¸Œ, Semantic Scholoar)ë¥¼ function callí•˜ì—¬ output ìƒì„±
## ì§„í–‰ì‚¬í•­
### 16ê¸° ë°•ë¯¼ê·œ
(ì„¸ë¶€ëª©í‘œ) target paperë¥¼ ê³µë¶€í•˜ê¸° ì „ ë´ì•¼í•  premiminaries & target paper ì´í›„ì— ë‚˜ì˜¨  future works ë“¤ì— ëŒ€í•œ ì •ë³´ ìƒì„±(ft llama) + ì‹œê°í™” ì§„í–‰
  - semantic scholar apiì™€ sentence transformerë¥¼ ì´ìš©í•˜ì—¬ data preprocessing âœ…
  - semantic scholar apië¥¼ ì´ìš©í•˜ì—¬ preminiaries visualization âœ… >> ì¡°ê¸ˆ ë” ê³ ê¸‰ì§€ê²Œ ì‹œê°í™” ğŸƒ
  - semantic scholar & archive apië¥¼ toolë¡œ ì‚¬ìš© >> langchainìœ¼ë¡œ ìƒì„± ğŸƒ
  - semantic scholar & archive api ì‚¬ìš©í•˜ì—¬ llamaë¡œ orginal dataset generate ğŸƒ


### 16ê¸° ì´ì˜ë…¸
- ToolFormer êµ¬í˜„

  ğŸƒ `EleutherAI/gpt-j-6B` GPUì— Model Load ì´í›„ ToolFormer `data_generator.py` ì‹¤í–‰ì‹œ, `retrieval_data_{self.num_device}.json` íŒŒì¼ stack í•˜ëŠ” ê³¼ì •ì—ì„œ GRAM OOM error ë¬¸ì œ ë°œìƒ 
  --> json íŒŒì¼ ì €ì¥ ì½”ë“œ ìˆ˜ì •

  ğŸƒ ì°¨í›„ `deepspeed` í†µí•œ FT ì§„í–‰ (`deepspeed` ì‚¬ìš©ë²• ê³µë¶€)

- ToolFormer ê°œì„ 
  - ë°°ê²½ : `conceptofmind` huggingface ëª¨ë¸ì˜ Mathematical Reasoning ëŠ¥ë ¥ ë¶€ì¡±
  - ê°œì„ ë°©ì•ˆ : `from prompts import retrieval_prompt` : prompt ìˆ˜ì •
    - e.g. CoT, step-by-step ìœ¼ë¡œ ìª¼ê°œëŠ” prompt search í•´ì„œ ë„£ì–´ë³´ê¸° ,tool documentation ë„£ì–´ì£¼ê³  zero-shot ìœ¼ë¡œ ì‹œë„
    - Sequential Tool Calling ì´ ê°€ëŠ¥í•´ì•¼ í•˜ëŠ”ë°, ì´ê±¸ ê¸°ì¡´ Toolformer ì½”ë“œì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰í• ì§€ ê³ ë¯¼ (LangChain?)
    
