{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41ebee11108544c0af238f2662aa47a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b1b5e8336454c9494ec54d858416fac",
              "IPY_MODEL_a00d7df419724f88a1f96faca386f291",
              "IPY_MODEL_bfcf09f16db34a47921a4e46caa3ec67"
            ],
            "layout": "IPY_MODEL_ba7137a99e7d4254ba3e45eacc86267e"
          }
        },
        "2b1b5e8336454c9494ec54d858416fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26091e5251a74eba9d2c934ee39a59fc",
            "placeholder": "​",
            "style": "IPY_MODEL_4469a113dc88436fa249a02288ed8a5f",
            "value": "modules.json: 100%"
          }
        },
        "a00d7df419724f88a1f96faca386f291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680be8a1eafc423d8f3b531017d42b36",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_152c754dfd9b48f7b66d43c638f78952",
            "value": 349
          }
        },
        "bfcf09f16db34a47921a4e46caa3ec67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e8afe34c2a48af8fa6a1d59584d728",
            "placeholder": "​",
            "style": "IPY_MODEL_6cbbd66949374f69bc43a1ff5ed3599f",
            "value": " 349/349 [00:00&lt;00:00, 3.65kB/s]"
          }
        },
        "ba7137a99e7d4254ba3e45eacc86267e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26091e5251a74eba9d2c934ee39a59fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4469a113dc88436fa249a02288ed8a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "680be8a1eafc423d8f3b531017d42b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152c754dfd9b48f7b66d43c638f78952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26e8afe34c2a48af8fa6a1d59584d728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cbbd66949374f69bc43a1ff5ed3599f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55f43f86e41c4482aeb1e797ef7e1b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3734dd45fbe44eabcd6d0f2157bf5af",
              "IPY_MODEL_55b42de838c640228c98d63506cc300d",
              "IPY_MODEL_43a7a9c6a39c475b93638c3e323134fe"
            ],
            "layout": "IPY_MODEL_d955a74fed2140f283c7664f9976e7ef"
          }
        },
        "a3734dd45fbe44eabcd6d0f2157bf5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a318c736784f0f81aa46136f6500c3",
            "placeholder": "​",
            "style": "IPY_MODEL_3e404298fc8748cfbad867ee63a1433c",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "55b42de838c640228c98d63506cc300d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f550008d3784d1484186645343868e7",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_258f0bb6978946faa083c4538b60fed3",
            "value": 116
          }
        },
        "43a7a9c6a39c475b93638c3e323134fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7765b70e93fa4ebe9ca709f0d7b5db18",
            "placeholder": "​",
            "style": "IPY_MODEL_a13bcdade06a465bbaed72fec83bc1d1",
            "value": " 116/116 [00:00&lt;00:00, 3.52kB/s]"
          }
        },
        "d955a74fed2140f283c7664f9976e7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a318c736784f0f81aa46136f6500c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e404298fc8748cfbad867ee63a1433c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f550008d3784d1484186645343868e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258f0bb6978946faa083c4538b60fed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7765b70e93fa4ebe9ca709f0d7b5db18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13bcdade06a465bbaed72fec83bc1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9e7e28619e54a6d933f09ad46450e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0d8fb3273444549b7c090a6753a1661",
              "IPY_MODEL_1047883bf4ff4fa49025ceb8f69401d6",
              "IPY_MODEL_a4c929e9b5af41d6a9c6f439f8cea600"
            ],
            "layout": "IPY_MODEL_6a93a5e2fc6843fbbe9e82a9ade466c5"
          }
        },
        "c0d8fb3273444549b7c090a6753a1661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a33954bfd983404d9ea5072b770147cb",
            "placeholder": "​",
            "style": "IPY_MODEL_53bf5359070240af90726220fec83f8d",
            "value": "README.md: 100%"
          }
        },
        "1047883bf4ff4fa49025ceb8f69401d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82fc501865884b549613387d178bf6bf",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ab26e6957d647b69957110d68c62b95",
            "value": 10659
          }
        },
        "a4c929e9b5af41d6a9c6f439f8cea600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a0d840bffd403ebe454e22a2588b80",
            "placeholder": "​",
            "style": "IPY_MODEL_b062e08d2ea94b4288251fd076990702",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 244kB/s]"
          }
        },
        "6a93a5e2fc6843fbbe9e82a9ade466c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33954bfd983404d9ea5072b770147cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53bf5359070240af90726220fec83f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82fc501865884b549613387d178bf6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab26e6957d647b69957110d68c62b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9a0d840bffd403ebe454e22a2588b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b062e08d2ea94b4288251fd076990702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd52f16820ca45a1b8b3fb9dd406a3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37e69b6e80d642cc8538e42b8a8ad806",
              "IPY_MODEL_5f30e9fa58ad4716a97383beb0dc31e3",
              "IPY_MODEL_e20d73f05a9e4c4881a0fc177bd65b6e"
            ],
            "layout": "IPY_MODEL_da62c90a84fa418288ba01e770783c02"
          }
        },
        "37e69b6e80d642cc8538e42b8a8ad806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5df6ca3a43f422a9cff7f2b3274f719",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0940b0f46d41e9aa8144e7491c719e",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "5f30e9fa58ad4716a97383beb0dc31e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a81446e257240538691f4c02158cc24",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5a67456f8734e7e9dd9bdf4a4791759",
            "value": 53
          }
        },
        "e20d73f05a9e4c4881a0fc177bd65b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ccffff343344248ac357db3384a3b7",
            "placeholder": "​",
            "style": "IPY_MODEL_7c8ad0a2a5d84b5e89c4eb926d15e758",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.36kB/s]"
          }
        },
        "da62c90a84fa418288ba01e770783c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5df6ca3a43f422a9cff7f2b3274f719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0940b0f46d41e9aa8144e7491c719e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a81446e257240538691f4c02158cc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a67456f8734e7e9dd9bdf4a4791759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0ccffff343344248ac357db3384a3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8ad0a2a5d84b5e89c4eb926d15e758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1f046d5b7d49df9e854e3732486f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86b8d4386e674c47b1ec627c6cd3110e",
              "IPY_MODEL_b1d8b11890334ef79a620373f24e8639",
              "IPY_MODEL_c061ad3713a4403b95a04e9d8785bb91"
            ],
            "layout": "IPY_MODEL_68a666a298c34fdb8dc8c45fe578b3c3"
          }
        },
        "86b8d4386e674c47b1ec627c6cd3110e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba68aa516d748fcb69517e0a2401114",
            "placeholder": "​",
            "style": "IPY_MODEL_57cbf268c54641748bc68a544f9cbf1b",
            "value": "config.json: 100%"
          }
        },
        "b1d8b11890334ef79a620373f24e8639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9afdf588434d928e3acdf3e40efca9",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d8f46ac093642538e2b7e3ebcd879f1",
            "value": 612
          }
        },
        "c061ad3713a4403b95a04e9d8785bb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a371f2ed1941b2b0d6743e861720ea",
            "placeholder": "​",
            "style": "IPY_MODEL_681a378f6de6407b969b58d0480654a3",
            "value": " 612/612 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "68a666a298c34fdb8dc8c45fe578b3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba68aa516d748fcb69517e0a2401114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57cbf268c54641748bc68a544f9cbf1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9afdf588434d928e3acdf3e40efca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8f46ac093642538e2b7e3ebcd879f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9a371f2ed1941b2b0d6743e861720ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681a378f6de6407b969b58d0480654a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca3affb3a004acb98db106346b4ca7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adce33b39712416789e0c805b05fa241",
              "IPY_MODEL_69a2dcdebfd44c94b26af61e6aad75d1",
              "IPY_MODEL_2d81d2a356ab4adabe1c2c416e5afa8e"
            ],
            "layout": "IPY_MODEL_de3cfd9cf6584fadb2620ea76a3b2201"
          }
        },
        "adce33b39712416789e0c805b05fa241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980fba15c04f421688f0520e8c34a181",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5c8441dd1644318d5661a650994a43",
            "value": "model.safetensors: 100%"
          }
        },
        "69a2dcdebfd44c94b26af61e6aad75d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01b86cade7c641239439795b6e6cbd11",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abd7889b757d4287ac73c2dabd874c15",
            "value": 90868376
          }
        },
        "2d81d2a356ab4adabe1c2c416e5afa8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f2455a12df4176a9408a37bf75bae2",
            "placeholder": "​",
            "style": "IPY_MODEL_9be6a2c2068746bd880ad0e6a414fb89",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 158MB/s]"
          }
        },
        "de3cfd9cf6584fadb2620ea76a3b2201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980fba15c04f421688f0520e8c34a181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5c8441dd1644318d5661a650994a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01b86cade7c641239439795b6e6cbd11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd7889b757d4287ac73c2dabd874c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9f2455a12df4176a9408a37bf75bae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be6a2c2068746bd880ad0e6a414fb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f5c3afbe70540a194b54396a7869d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e857a6754614e22b16c8a53b786fa2c",
              "IPY_MODEL_21f23599abe140b38f6e786c91faf39c",
              "IPY_MODEL_46c563f2cc8440e78be85e82f396cdea"
            ],
            "layout": "IPY_MODEL_fd8ea4faee6c413494a7feb33b061119"
          }
        },
        "6e857a6754614e22b16c8a53b786fa2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94faa061cae74315a7582b41a7fd3ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_89b6c3b16a684ae98546094207ace3a3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "21f23599abe140b38f6e786c91faf39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e735f4ff759b4786aa9a6dfce0f0d11f",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62c3fc47f8c54d89a1a388824f644354",
            "value": 350
          }
        },
        "46c563f2cc8440e78be85e82f396cdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e92cbda29d94dab9c6b04a4b5800a7e",
            "placeholder": "​",
            "style": "IPY_MODEL_e33acdb6979e452fbd54dc2f9ba74d27",
            "value": " 350/350 [00:00&lt;00:00, 6.42kB/s]"
          }
        },
        "fd8ea4faee6c413494a7feb33b061119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94faa061cae74315a7582b41a7fd3ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b6c3b16a684ae98546094207ace3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e735f4ff759b4786aa9a6dfce0f0d11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c3fc47f8c54d89a1a388824f644354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e92cbda29d94dab9c6b04a4b5800a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33acdb6979e452fbd54dc2f9ba74d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7962a4fa684d138ad91e2fb93a094d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fae7ea8717d450197897e250f228545",
              "IPY_MODEL_96c4d5bcd39f412da41324628ede6cf1",
              "IPY_MODEL_0e7f73d1011a4aea9fa1e8192d4dddba"
            ],
            "layout": "IPY_MODEL_0201c5cc6da440d1b1c4b0ca7674e06d"
          }
        },
        "0fae7ea8717d450197897e250f228545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ff3fdc9caa4becacbfbb2799e53b84",
            "placeholder": "​",
            "style": "IPY_MODEL_96e85e86cb8a491bb35cd368af6900a6",
            "value": "vocab.txt: 100%"
          }
        },
        "96c4d5bcd39f412da41324628ede6cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb1fa27d8b3144d5b4356d00a4ed7f04",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b74ad1ecfa1b4317ace83dc092303e77",
            "value": 231508
          }
        },
        "0e7f73d1011a4aea9fa1e8192d4dddba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b7656a2e1143639a2d02e148b01cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_34effe578c0147ccb4ee886e5a5c7746",
            "value": " 232k/232k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "0201c5cc6da440d1b1c4b0ca7674e06d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ff3fdc9caa4becacbfbb2799e53b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e85e86cb8a491bb35cd368af6900a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb1fa27d8b3144d5b4356d00a4ed7f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74ad1ecfa1b4317ace83dc092303e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21b7656a2e1143639a2d02e148b01cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34effe578c0147ccb4ee886e5a5c7746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f08f416f1ce54273837feaf7c6a8ee23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cde1eb79aab4094b90459e31d4210aa",
              "IPY_MODEL_5fcf2625fed54f3b90cd47d643c3aa6f",
              "IPY_MODEL_e9fa30239dac4e3a8252090e7d2567f3"
            ],
            "layout": "IPY_MODEL_346fdd1a754d4a55b4ada3c693c33a71"
          }
        },
        "9cde1eb79aab4094b90459e31d4210aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7012d361d014770a4101b2efbf7c380",
            "placeholder": "​",
            "style": "IPY_MODEL_33669d2effb54d68b49605f6a58cfc35",
            "value": "tokenizer.json: 100%"
          }
        },
        "5fcf2625fed54f3b90cd47d643c3aa6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f578757d968c44b3a4ed6e301bdb16c9",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71d3c1fd672d49179a063c80cc37b7ae",
            "value": 466247
          }
        },
        "e9fa30239dac4e3a8252090e7d2567f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e5c48a65cda48aca2afd9653b71a77c",
            "placeholder": "​",
            "style": "IPY_MODEL_3cc2918974c34a72940622033925792e",
            "value": " 466k/466k [00:00&lt;00:00, 9.16MB/s]"
          }
        },
        "346fdd1a754d4a55b4ada3c693c33a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7012d361d014770a4101b2efbf7c380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33669d2effb54d68b49605f6a58cfc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f578757d968c44b3a4ed6e301bdb16c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d3c1fd672d49179a063c80cc37b7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e5c48a65cda48aca2afd9653b71a77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc2918974c34a72940622033925792e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83fc1b7d5c1842b397147938c5b84345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f60190afb848cc8b16efcbdd7ef202",
              "IPY_MODEL_552bbaf866184ee0af5f35e320da212d",
              "IPY_MODEL_7d486684c51248ae8c116289ec22417c"
            ],
            "layout": "IPY_MODEL_79f9de2d4b774c8694ecef6895cca949"
          }
        },
        "e5f60190afb848cc8b16efcbdd7ef202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c40b7771064740b7f61ac946ada7ee",
            "placeholder": "​",
            "style": "IPY_MODEL_1b1792e1f34048abba0d63c13f5c6c84",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "552bbaf866184ee0af5f35e320da212d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95747cc292e946eb8c486b2d0639c179",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b06f53396bd8470bad1cb89ae5274145",
            "value": 112
          }
        },
        "7d486684c51248ae8c116289ec22417c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9337d9540f7f4e78bb50baa86934f158",
            "placeholder": "​",
            "style": "IPY_MODEL_7cc16b5367c64ea8ac646c9dfc2b2d71",
            "value": " 112/112 [00:00&lt;00:00, 3.71kB/s]"
          }
        },
        "79f9de2d4b774c8694ecef6895cca949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c40b7771064740b7f61ac946ada7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1792e1f34048abba0d63c13f5c6c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95747cc292e946eb8c486b2d0639c179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06f53396bd8470bad1cb89ae5274145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9337d9540f7f4e78bb50baa86934f158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc16b5367c64ea8ac646c9dfc2b2d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba3487c400f443d3b44e6061f84d1efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9adc7d6b6df6441fa5ec15e508da9928",
              "IPY_MODEL_4d21ff19d69b41d6a391752aa28889a1",
              "IPY_MODEL_8d11aec2c2104f1f8d9ec79196a0e253"
            ],
            "layout": "IPY_MODEL_f3eab52fee884a6b9ffefc7b6658229b"
          }
        },
        "9adc7d6b6df6441fa5ec15e508da9928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_072fd7f512e34f799682f4e663628475",
            "placeholder": "​",
            "style": "IPY_MODEL_5487460d371c42568826141abfa2fb34",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "4d21ff19d69b41d6a391752aa28889a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7c7591e5bb4b83a06ed428199462c4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dfbec3a364c4be996fe4babeac4721a",
            "value": 190
          }
        },
        "8d11aec2c2104f1f8d9ec79196a0e253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a488e4c22f4dba99917a26f97b3b34",
            "placeholder": "​",
            "style": "IPY_MODEL_c0486bcdba7a46efa980535373333185",
            "value": " 190/190 [00:00&lt;00:00, 2.88kB/s]"
          }
        },
        "f3eab52fee884a6b9ffefc7b6658229b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072fd7f512e34f799682f4e663628475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5487460d371c42568826141abfa2fb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba7c7591e5bb4b83a06ed428199462c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dfbec3a364c4be996fe4babeac4721a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74a488e4c22f4dba99917a26f97b3b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0486bcdba7a46efa980535373333185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4bsv8crJSpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2076ae05-2b87-4046-811a-223ad735ccd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m565.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade -q langchain-openai tiktoken langchain-chroma langchain GitPython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community"
      ],
      "metadata": {
        "id": "1JmmTnDeK30U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb1fa06-8cb1-458f-ee33-df10b350b86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n"
      ],
      "metadata": {
        "id": "uXVgbScCJ1wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from git import Repo\n",
        "from langchain_community.document_loaders.generic import GenericLoader # 디렉토리에서 파일 로드\n",
        "from langchain_community.document_loaders.parsers import LanguageParser\n",
        "from langchain_text_splitters import Language"
      ],
      "metadata": {
        "id": "-UKj8GyGKU2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "!mkdir test_repo\n",
        "os.chdir(\"test_repo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh-TTkDSLFZ3",
        "outputId": "4acb8f26-437e-43b0-c961-184ad5bbc20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = os.getcwd()\n",
        "repo = Repo.clone_from(\"https://github.com/conceptofmind/toolformer\", to_path = repo_path)"
      ],
      "metadata": {
        "id": "Bz7yfe5oLaXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subdirs = [os.path.join(repo_path, d) for d in os.listdir(repo_path) if os.path.isdir(os.path.join(repo_path, d))]\n",
        "subdirs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFhjvRs2eBQD",
        "outputId": "edb794b4-1e4a-4409-b6a1-e5a395a15470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/test_repo/test_repo/test_repo/test_repo/data_handling',\n",
              " '/content/test_repo/test_repo/test_repo/test_repo/customToolformer',\n",
              " '/content/test_repo/test_repo/test_repo/test_repo/data_generation',\n",
              " '/content/test_repo/test_repo/test_repo/test_repo/configs',\n",
              " '/content/test_repo/test_repo/test_repo/test_repo/.git',\n",
              " '/content/test_repo/test_repo/test_repo/test_repo/flash_attention']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Code\n",
        "loader = GenericLoader.from_filesystem(\n",
        "    repo_path ,\n",
        "    glob = \"**/*\",\n",
        "    suffixes= [\".py\"],\n",
        "    exclude = [\"**/non-utf8-encoding.py\"],\n",
        "    parser = LanguageParser(language = Language.PYTHON, parser_threshold = 200),\n",
        ")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "0hadJR_vLx8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# document 들을 더 작은 chunk 로 분해\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language = Language.PYTHON,\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap = 200,\n",
        ")\n",
        "texts = python_splitter.split_documents(documents)\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BchvibgnNaqG",
        "outputId": "2796464a-0963-474b-8fd7-e8aac77fa655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "db  = Chroma.from_documents(texts, OpenAIEmbeddings(openai_api_key=api_key, disallowed_special = ()))\n",
        "retriever = db.as_retriever(\n",
        "    search_type = \"mmr\",\n",
        "    search_kwargs = {\"k\" : 10}\n",
        ")"
      ],
      "metadata": {
        "id": "Ti8prRucOsPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0c925b-1ce4-4df3-aa7b-bbaa499d43fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature = 0.0, openai_api_key=api_key)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "qa = create_retrieval_chain(retrieval_chain, document_chain)"
      ],
      "metadata": {
        "id": "x-pCfAtrPOZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\"Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘.\",\n",
        "            \"Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어?\"]\n",
        "for question in questions:\n",
        "    result = qa.invoke({\"input\": question})\n",
        "    print(f\"-> **Question**: {question} \\n\")\n",
        "    print(f\"**Answer**: {result['answer']} \\n\\n\")\n"
      ],
      "metadata": {
        "id": "Uq2BNeycZXIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7325c0c3-e529-4d8c-aab2-cf62acb0b754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. \n",
            "\n",
            "**Answer**: Toolformer의 Loss는 주어진 문제에 대한 모델의 출력과 실제 정답 간의 차이를 측정하는 방법입니다. 주로 Cross Entropy Loss 또는 Negative Log Likelihood Loss와 같은 손실 함수를 사용하여 계산됩니다.\n",
            "\n",
            "주어진 코드에서는 Loss를 계산하는 부분이 누락되어 있어 정확한 Loss 함수를 확인할 수 없습니다. 그러나 주로 사용되는 Cross Entropy Loss는 다음과 같이 수식화됩니다:\n",
            "\n",
            "Loss = -1/N * Σ(y * log(p) + (1-y) * log(1-p))\n",
            "\n",
            "여기서,\n",
            "- N은 데이터 포인트의 총 개수\n",
            "- y는 실제 정답 레이블\n",
            "- p는 모델의 예측 확률\n",
            "\n",
            "따라서, 모델이 예측한 확률과 실제 정답 레이블 간의 차이를 최소화하는 방향으로 학습됩니다. Toolformer의 Loss 함수는 모델이 학습하는 목표에 따라 다를 수 있으며, 실제 코드에서 사용된 Loss 함수를 확인하여 더 자세한 정보를 얻을 수 있습니다. \n",
            "\n",
            "\n",
            "-> **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? \n",
            "\n",
            "**Answer**: Toolformer 클래스에서 사용되는 Tool은 다음과 같습니다:\n",
            "1. Transformer: Transformer 클래스\n",
            "2. RotaryEmbedding: RotaryEmbedding 클래스\n",
            "3. ParallelTransformerBlock: ParallelTransformerBlock 클래스\n",
            "4. Toolformer: Toolformer 클래스 (자체 정의)\n",
            "5. RMSNorm: RMSNorm 클래스\n",
            "6. rotate_half 함수\n",
            "7. apply_rotary_pos_emb 함수\n",
            "\n",
            "이러한 Tool들이 Toolformer 클래스 내에서 사용되고 있습니다. \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence_transformers"
      ],
      "metadata": {
        "id": "xDskmWK8grrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da31f2e1-66de-4bcf-815c-8aa349dfd23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "8KwiAwWygpWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562,
          "referenced_widgets": [
            "41ebee11108544c0af238f2662aa47a4",
            "2b1b5e8336454c9494ec54d858416fac",
            "a00d7df419724f88a1f96faca386f291",
            "bfcf09f16db34a47921a4e46caa3ec67",
            "ba7137a99e7d4254ba3e45eacc86267e",
            "26091e5251a74eba9d2c934ee39a59fc",
            "4469a113dc88436fa249a02288ed8a5f",
            "680be8a1eafc423d8f3b531017d42b36",
            "152c754dfd9b48f7b66d43c638f78952",
            "26e8afe34c2a48af8fa6a1d59584d728",
            "6cbbd66949374f69bc43a1ff5ed3599f",
            "55f43f86e41c4482aeb1e797ef7e1b6a",
            "a3734dd45fbe44eabcd6d0f2157bf5af",
            "55b42de838c640228c98d63506cc300d",
            "43a7a9c6a39c475b93638c3e323134fe",
            "d955a74fed2140f283c7664f9976e7ef",
            "05a318c736784f0f81aa46136f6500c3",
            "3e404298fc8748cfbad867ee63a1433c",
            "5f550008d3784d1484186645343868e7",
            "258f0bb6978946faa083c4538b60fed3",
            "7765b70e93fa4ebe9ca709f0d7b5db18",
            "a13bcdade06a465bbaed72fec83bc1d1",
            "b9e7e28619e54a6d933f09ad46450e2e",
            "c0d8fb3273444549b7c090a6753a1661",
            "1047883bf4ff4fa49025ceb8f69401d6",
            "a4c929e9b5af41d6a9c6f439f8cea600",
            "6a93a5e2fc6843fbbe9e82a9ade466c5",
            "a33954bfd983404d9ea5072b770147cb",
            "53bf5359070240af90726220fec83f8d",
            "82fc501865884b549613387d178bf6bf",
            "5ab26e6957d647b69957110d68c62b95",
            "b9a0d840bffd403ebe454e22a2588b80",
            "b062e08d2ea94b4288251fd076990702",
            "cd52f16820ca45a1b8b3fb9dd406a3e9",
            "37e69b6e80d642cc8538e42b8a8ad806",
            "5f30e9fa58ad4716a97383beb0dc31e3",
            "e20d73f05a9e4c4881a0fc177bd65b6e",
            "da62c90a84fa418288ba01e770783c02",
            "c5df6ca3a43f422a9cff7f2b3274f719",
            "aa0940b0f46d41e9aa8144e7491c719e",
            "2a81446e257240538691f4c02158cc24",
            "e5a67456f8734e7e9dd9bdf4a4791759",
            "a0ccffff343344248ac357db3384a3b7",
            "7c8ad0a2a5d84b5e89c4eb926d15e758",
            "9e1f046d5b7d49df9e854e3732486f1a",
            "86b8d4386e674c47b1ec627c6cd3110e",
            "b1d8b11890334ef79a620373f24e8639",
            "c061ad3713a4403b95a04e9d8785bb91",
            "68a666a298c34fdb8dc8c45fe578b3c3",
            "6ba68aa516d748fcb69517e0a2401114",
            "57cbf268c54641748bc68a544f9cbf1b",
            "1c9afdf588434d928e3acdf3e40efca9",
            "4d8f46ac093642538e2b7e3ebcd879f1",
            "d9a371f2ed1941b2b0d6743e861720ea",
            "681a378f6de6407b969b58d0480654a3",
            "9ca3affb3a004acb98db106346b4ca7c",
            "adce33b39712416789e0c805b05fa241",
            "69a2dcdebfd44c94b26af61e6aad75d1",
            "2d81d2a356ab4adabe1c2c416e5afa8e",
            "de3cfd9cf6584fadb2620ea76a3b2201",
            "980fba15c04f421688f0520e8c34a181",
            "2d5c8441dd1644318d5661a650994a43",
            "01b86cade7c641239439795b6e6cbd11",
            "abd7889b757d4287ac73c2dabd874c15",
            "a9f2455a12df4176a9408a37bf75bae2",
            "9be6a2c2068746bd880ad0e6a414fb89",
            "8f5c3afbe70540a194b54396a7869d18",
            "6e857a6754614e22b16c8a53b786fa2c",
            "21f23599abe140b38f6e786c91faf39c",
            "46c563f2cc8440e78be85e82f396cdea",
            "fd8ea4faee6c413494a7feb33b061119",
            "94faa061cae74315a7582b41a7fd3ba0",
            "89b6c3b16a684ae98546094207ace3a3",
            "e735f4ff759b4786aa9a6dfce0f0d11f",
            "62c3fc47f8c54d89a1a388824f644354",
            "3e92cbda29d94dab9c6b04a4b5800a7e",
            "e33acdb6979e452fbd54dc2f9ba74d27",
            "1a7962a4fa684d138ad91e2fb93a094d",
            "0fae7ea8717d450197897e250f228545",
            "96c4d5bcd39f412da41324628ede6cf1",
            "0e7f73d1011a4aea9fa1e8192d4dddba",
            "0201c5cc6da440d1b1c4b0ca7674e06d",
            "d6ff3fdc9caa4becacbfbb2799e53b84",
            "96e85e86cb8a491bb35cd368af6900a6",
            "bb1fa27d8b3144d5b4356d00a4ed7f04",
            "b74ad1ecfa1b4317ace83dc092303e77",
            "21b7656a2e1143639a2d02e148b01cfd",
            "34effe578c0147ccb4ee886e5a5c7746",
            "f08f416f1ce54273837feaf7c6a8ee23",
            "9cde1eb79aab4094b90459e31d4210aa",
            "5fcf2625fed54f3b90cd47d643c3aa6f",
            "e9fa30239dac4e3a8252090e7d2567f3",
            "346fdd1a754d4a55b4ada3c693c33a71",
            "c7012d361d014770a4101b2efbf7c380",
            "33669d2effb54d68b49605f6a58cfc35",
            "f578757d968c44b3a4ed6e301bdb16c9",
            "71d3c1fd672d49179a063c80cc37b7ae",
            "6e5c48a65cda48aca2afd9653b71a77c",
            "3cc2918974c34a72940622033925792e",
            "83fc1b7d5c1842b397147938c5b84345",
            "e5f60190afb848cc8b16efcbdd7ef202",
            "552bbaf866184ee0af5f35e320da212d",
            "7d486684c51248ae8c116289ec22417c",
            "79f9de2d4b774c8694ecef6895cca949",
            "23c40b7771064740b7f61ac946ada7ee",
            "1b1792e1f34048abba0d63c13f5c6c84",
            "95747cc292e946eb8c486b2d0639c179",
            "b06f53396bd8470bad1cb89ae5274145",
            "9337d9540f7f4e78bb50baa86934f158",
            "7cc16b5367c64ea8ac646c9dfc2b2d71",
            "ba3487c400f443d3b44e6061f84d1efd",
            "9adc7d6b6df6441fa5ec15e508da9928",
            "4d21ff19d69b41d6a391752aa28889a1",
            "8d11aec2c2104f1f8d9ec79196a0e253",
            "f3eab52fee884a6b9ffefc7b6658229b",
            "072fd7f512e34f799682f4e663628475",
            "5487460d371c42568826141abfa2fb34",
            "ba7c7591e5bb4b83a06ed428199462c4",
            "5dfbec3a364c4be996fe4babeac4721a",
            "74a488e4c22f4dba99917a26f97b3b34",
            "c0486bcdba7a46efa980535373333185"
          ]
        },
        "outputId": "dd9da4ed-8bc1-4bc0-fdca-cbfae5373b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41ebee11108544c0af238f2662aa47a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55f43f86e41c4482aeb1e797ef7e1b6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9e7e28619e54a6d933f09ad46450e2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd52f16820ca45a1b8b3fb9dd406a3e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e1f046d5b7d49df9e854e3732486f1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ca3affb3a004acb98db106346b4ca7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f5c3afbe70540a194b54396a7869d18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a7962a4fa684d138ad91e2fb93a094d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f08f416f1ce54273837feaf7c6a8ee23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83fc1b7d5c1842b397147938c5b84345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba3487c400f443d3b44e6061f84d1efd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 임베딩 모델 로드\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def answer_quality_score(question: str, answer: str) -> float:\n",
        "    \"\"\"질문과 답변 코드의 유사도를 기반으로 품질 점수를 계산하는 함수\"\"\"\n",
        "    # 질문과 답변을 임베딩\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    answer_embedding = model.encode(answer, convert_to_tensor=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    cos_sim = util.cos_sim(question_embedding, answer_embedding)\n",
        "\n",
        "    # 유사도 점수를 0~1 사이로 정규화\n",
        "    normalized_score = float(cos_sim.item()) / 2 + 0.5\n",
        "\n",
        "    return normalized_score"
      ],
      "metadata": {
        "id": "ZDvVNZ1OlpkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6JtmyPvhhbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드만 가지고 inference 하는 파트\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "subdirs = [os.path.join(repo_path, d) for d in os.listdir(repo_path) if os.path.isdir(os.path.join(repo_path, d))]\n",
        "\n",
        "best_answer = (\"\", 0.0)\n",
        "best_context = \"\"\n",
        "best_subdir = \"\"\n",
        "questions = [\"Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘.\",\n",
        "            \"Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어?\"]\n",
        "\n",
        "for question in questions:\n",
        "  print(f\"\\n---------------------- **Question**: {question} ----------------------\\n\")\n",
        "  for subdir in tqdm(subdirs):\n",
        "      loader = GenericLoader.from_filesystem(\n",
        "          subdir,\n",
        "          glob=\"**/*\",\n",
        "          suffixes=[\".py\"],\n",
        "          exclude=[\"**/non-utf8-encoding.py\"],\n",
        "          parser=LanguageParser(language=Language.PYTHON, parser_threshold=200),\n",
        "      )\n",
        "      documents = loader.load()\n",
        "\n",
        "      python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "          language=Language.PYTHON,\n",
        "          chunk_size=1000,\n",
        "          chunk_overlap=100,\n",
        "      )\n",
        "      texts = python_splitter.split_documents(documents)\n",
        "      if not texts:\n",
        "        pass\n",
        "      else:\n",
        "        db = Chroma.from_documents(texts,\n",
        "                                  OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                                  collection_metadata = {'hnsw:space': 'cosine'})\n",
        "\n",
        "\n",
        "      retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "      prompt = ChatPromptTemplate.from_messages([\n",
        "          (\"placeholder\", \"{chat_history}\"),\n",
        "          (\"user\", \"{input}\"),\n",
        "          (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "      ])\n",
        "\n",
        "      retrieval_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
        "\n",
        "      prompt = ChatPromptTemplate.from_messages([\n",
        "          (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "          (\"placeholder\", \"{chat_history}\"),\n",
        "          (\"user\", \"{input}\"),\n",
        "      ])\n",
        "\n",
        "\n",
        "      document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "      qa = create_retrieval_chain(retrieval_chain, document_chain)\n",
        "\n",
        "      # print results\n",
        "      result = qa.invoke({\"input\": question})\n",
        "      answer = result['answer']\n",
        "      context = result['context']\n",
        "      score = answer_quality_score(question, answer)\n",
        "\n",
        "      # update score, best answer, best subdir\n",
        "      if score > best_answer[1]:\n",
        "          best_answer = (answer, score)\n",
        "          best_subdir = subdir\n",
        "          best_context = context\n",
        "      print(f\"\\n CURRENT SUBDIRECTORY : {subdir}\")\n",
        "      print(f\"**Answer**: {answer} \\n\\n**Score**: {score}\\n\\n\")\n",
        "\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(f\"\\n -> **Question**: {question} \\n\")\n",
        "  print(f\"**Best Answer**: {best_answer[0]} \\n\\n**Score**: {best_answer[1]}\\n\\n\")\n",
        "  print(f\"**Best Subdirectory**: {best_subdir}\")\n",
        "  print(f\"**Best Context**:\\n\")\n",
        "  print(best_context)\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "-Dg-rh5_eV0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da9f524-8123-4e17-fb65-0ebdb2143256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1/6 [00:06<00:33,  6.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/configs\n",
            "**Answer**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 지표입니다. Loss는 모델이 얼마나 잘 작동하는지를 평가하는 중요한 지표 중 하나이며, 최소화되어야 하는 목표입니다.\n",
            "\n",
            "Loss는 주로 Cross-Entropy Loss 함수를 사용하여 계산됩니다. Cross-Entropy Loss 함수는 다음과 같이 정의됩니다:\n",
            "\n",
            "\\[ \\text{Cross-Entropy Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log(p_{i,c}) \\]\n",
            "\n",
            "여기서,\n",
            "- \\( N \\)은 데이터 포인트의 총 수,\n",
            "- \\( C \\)는 클래스의 수,\n",
            "- \\( y_{i,c} \\)는 실제 정답 레이블 (0 또는 1)로, \\( i \\)번째 데이터 포인트가 \\( c \\)번째 클래스에 속하는지 여부를 나타냅니다,\n",
            "- \\( p_{i,c} \\)는 모델의 예측 확률로, \\( i \\)번째 데이터 포인트가 \\( c \\)번째 클래스에 속할 확률을 나타냅니다.\n",
            "\n",
            "이 Loss 함수는 모델의 예측이 실제 정답과 얼마나 일치하는지를 측정하며, 모델이 더 나은 예측을 하도록 학습하도록 도와줍니다.\n",
            "\n",
            "이 답변은 주어진 맥락을 기반으로 추론하여 제공되었습니다. \n",
            "\n",
            "**Score**: 0.692680835723877\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 2/6 [00:10<00:19,  4.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/.git\n",
            "**Answer**: 주어진 문맥에서는 Toolformer의 Loss에 대한 구체적인 정보나 수식이 제공되지 않습니다. 따라서 Loss 함수에 대한 자세한 내용은 이 문서에서는 확인할 수 없습니다. Loss 함수는 모델이 학습 중에 예측과 실제 값 사이의 차이를 측정하는 함수이며, 일반적으로 평균 제곱 오차(Mean Squared Error)나 교차 엔트로피(Cross Entropy)와 같은 함수가 사용됩니다. 이러한 Loss 함수는 모델이 얼마나 잘 학습되고 있는지를 판단하는 중요한 지표입니다. \n",
            "\n",
            "**Score**: 0.7822863459587097\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 3/6 [00:18<00:18,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/customToolformer\n",
            "**Answer**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 지표입니다. Loss를 최소화하는 것이 모델을 훈련시키는 주요 목표 중 하나입니다. Toolformer의 Loss는 다음과 같은 수식을 사용하여 계산될 수 있습니다:\n",
            "\n",
            "Loss = (1/N) * Σ(-y * log(ŷ) - (1-y) * log(1-ŷ))\n",
            "\n",
            "여기서,\n",
            "- N은 데이터 포인트의 총 수입니다.\n",
            "- y는 실제 정답(ground truth)입니다.\n",
            "- ŷ는 모델의 예측값입니다.\n",
            "- log는 자연 로그를 나타냅니다.\n",
            "\n",
            "이 Loss 함수는 주로 이진 분류(binary classification) 문제에 사용되며, Cross-Entropy Loss 또는 Log Loss라고도 불립니다. 이 Loss 함수는 모델이 예측을 잘못할수록 Loss가 증가하게 되어 모델이 올바른 예측을 하도록 학습하게 됩니다.\n",
            "\n",
            "이 답변은 주어진 맥락을 기반으로 추론하여 제공된 것이며, 명시적인 Loss 함수의 정의가 제공된 문서에서 직접 인용된 것은 아닙니다. \n",
            "\n",
            "**Score**: 0.7981629371643066\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 4/6 [00:26<00:13,  6.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/flash_attention\n",
            "**Answer**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 방법입니다. Loss는 모델이 얼마나 잘 작동하는지를 평가하는 중요한 지표 중 하나이며, 최소화되어야 하는 목표입니다.\n",
            "\n",
            "일반적으로 Toolformer의 Loss는 다음과 같은 수식을 사용하여 계산됩니다:\n",
            "Loss = (1/N) * Σ(L(y_pred, y_true))\n",
            "\n",
            "여기서,\n",
            "- N은 데이터 포인트의 총 수\n",
            "- L은 손실 함수\n",
            "- y_pred는 모델의 예측값\n",
            "- y_true는 실제 정답값\n",
            "\n",
            "손실 함수 L은 주어진 작업에 따라 다양하게 정의될 수 있습니다. 예를 들어, 분류 작업의 경우에는 Cross Entropy Loss가 사용될 수 있고, 회귀 작업의 경우에는 Mean Squared Error가 사용될 수 있습니다.\n",
            "\n",
            "이러한 Loss 함수를 최소화하는 것이 모델을 훈련시키는 주요 목표이며, 이를 통해 모델이 더 나은 예측을 할 수 있도록 학습됩니다.\n",
            "\n",
            "(Source: 내 추론을 토대로 작성한 답변입니다.) \n",
            "\n",
            "**Score**: 0.7691965699195862\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 5/6 [00:31<00:06,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/data_handling\n",
            "**Answer**: 주어진 문맥에서는 Toolformer의 Loss에 대한 구체적인 정보나 수식이 제공되지 않습니다. 따라서 Loss 함수에 대한 자세한 내용은 이 문서에서는 확인할 수 없습니다. Loss 함수는 모델이 학습 중에 예측과 실제 값 사이의 차이를 측정하는 함수이며, 일반적으로 평균 제곱 오차(Mean Squared Error)나 교차 엔트로피(Cross Entropy)와 같은 함수가 사용됩니다. 만약 논문이나 해당 연구의 자세한 내용을 확인하고 싶다면, 원본 논문을 참고하시는 것이 좋을 것입니다. \n",
            "\n",
            "**Score**: 0.7727658450603485\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:35<00:00,  5.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/data_generation\n",
            "**Answer**: 주어진 문맥에서는 Toolformer의 Loss에 대한 구체적인 정보나 수식이 제공되지 않습니다. 따라서 Loss 함수에 대한 자세한 내용은 이 문서에서는 확인할 수 없습니다. Loss 함수는 모델이 학습 중에 예측과 실제 값 사이의 차이를 측정하는 함수이며, 일반적으로 평균 제곱 오차(Mean Squared Error)나 교차 엔트로피 손실(Cross-Entropy Loss) 등이 사용될 수 있습니다. 이러한 Loss 함수는 모델이 얼마나 잘 학습되고 있는지를 평가하는 데 사용됩니다. \n",
            "\n",
            "**Score**: 0.7951204776763916\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. \n",
            "\n",
            "**Best Answer**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 지표입니다. Loss를 최소화하는 것이 모델을 훈련시키는 주요 목표 중 하나입니다. Toolformer의 Loss는 다음과 같은 수식을 사용하여 계산될 수 있습니다:\n",
            "\n",
            "Loss = (1/N) * Σ(-y * log(ŷ) - (1-y) * log(1-ŷ))\n",
            "\n",
            "여기서,\n",
            "- N은 데이터 포인트의 총 수입니다.\n",
            "- y는 실제 정답(ground truth)입니다.\n",
            "- ŷ는 모델의 예측값입니다.\n",
            "- log는 자연 로그를 나타냅니다.\n",
            "\n",
            "이 Loss 함수는 주로 이진 분류(binary classification) 문제에 사용되며, Cross-Entropy Loss 또는 Log Loss라고도 불립니다. 이 Loss 함수는 모델이 예측을 잘못할수록 Loss가 증가하게 되어 모델이 올바른 예측을 하도록 학습하게 됩니다.\n",
            "\n",
            "이 답변은 주어진 맥락을 기반으로 추론하여 제공된 것이며, 명시적인 Loss 함수의 정의가 제공된 문서에서 직접 인용된 것은 아닙니다. \n",
            "\n",
            "**Score**: 0.7981629371643066\n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/customToolformer\n",
            "**Best Context**:\n",
            "\n",
            "[Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "---------------------- **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1/6 [00:02<00:10,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/configs\n",
            "**Answer**: Toolformer에서 사용되는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공됩니다. \n",
            "\n",
            "**Score**: 0.8643501400947571\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 2/6 [00:03<00:07,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/.git\n",
            "**Answer**: Toolformer가 사용하는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공됩니다. \n",
            "\n",
            "**Score**: 0.8577778041362762\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 3/6 [00:05<00:05,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/customToolformer\n",
            "**Answer**: Toolformer에서 사용되는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공되었습니다. \n",
            "\n",
            "**Score**: 0.8643501400947571\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 4/6 [00:08<00:04,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/flash_attention\n",
            "**Answer**: Toolformer가 사용하는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공되었습니다. \n",
            "\n",
            "**Score**: 0.8577778041362762\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 5/6 [00:11<00:02,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/data_handling\n",
            "**Answer**: Toolformer에서 사용되는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공됩니다. \n",
            "\n",
            "**Score**: 0.8643501400947571\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:14<00:00,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CURRENT SUBDIRECTORY : /content/test_repo/data_generation\n",
            "**Answer**: Toolformer 모델이 사용하는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. (출처: Toolformer: Language Models Can Teach Themselves to Use Tools) \n",
            "\n",
            "**Score**: 0.8861420154571533\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? \n",
            "\n",
            "**Best Answer**: Toolformer 모델이 사용하는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. (출처: Toolformer: Language Models Can Teach Themselves to Use Tools) \n",
            "\n",
            "**Score**: 0.8861420154571533\n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/data_generation\n",
            "**Best Context**:\n",
            "\n",
            "[Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_context #어디를 참고했는지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzHMMD4OwG1v",
        "outputId": "a4c6da7d-2488-4c36-a87b-85c45e2b444c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}),\n",
              " Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}),\n",
              " Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}),\n",
              " Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}),\n",
              " Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## answer from pdf"
      ],
      "metadata": {
        "id": "g1T8aEH4j5_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypdf"
      ],
      "metadata": {
        "id": "Ik48Ee4wlRsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0762de9f-084e-4d4b-b028-15e40ca8951a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/290.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "pdf = PyPDFLoader(\"/content/2302.04761v1 (4).pdf\")\n",
        "pages = pdf.load_and_split()"
      ],
      "metadata": {
        "id": "YPLwtdrDk-9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def answer_quality_score_multiple(question: str, context_code, context_pdf, weight_qc = 0.2, weight_qp = 0.35, weight_cp = 0.45):\n",
        "    \"\"\"질문과 답변 코드의 유사도를 기반으로 품질 점수를 계산하는 함수\"\"\"\n",
        "    # embedding\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    context_code_embedding = model.encode(context_code, convert_to_tensor=True)\n",
        "    context_pdf_embedding = model.encode(context_pdf, convert_to_tensor=True)\n",
        "\n",
        "    cos_sim_qc = util.cos_sim(question_embedding, context_code_embedding)\n",
        "    cos_sim_qp = util.cos_sim(question_embedding, context_pdf_embedding)\n",
        "    cos_sim_cp = util.cos_sim(context_code_embedding, context_pdf_embedding)\n",
        "\n",
        "    normalized_score = float(cos_sim_qc.item()) * weight_qc + float(cos_sim_qp.item()) * weight_qp + float(cos_sim_cp.item()) * weight_cp\n",
        "\n",
        "    return normalized_score\n",
        "\n",
        "# def random_search(cos_sim_qc, cos_sim_qp, cos_sim_cp, num_iterations=100):\n",
        "#   best_weights = None\n",
        "#   best_score = -float('inf')\n",
        "\n",
        "#   for _ in range(num_iterations):\n",
        "#     weight_qc = random.random()\n",
        "#     weight_qp = random.random()\n",
        "#     weight_cp = 1 - weight_qc - weight_qp\n",
        "\n",
        "#     normalized_score = float(cos_sim_qc.item()) * weight_qc + float(cos_sim_qp.item()) * weight_qp + float(cos_sim_cp.item()) * weight_cp\n",
        "\n",
        "#     if normalized_score > best_score:\n",
        "#       best_weights = (weight_qc, weight_qp, weight_cp)\n",
        "#       best_score = normalized_score\n",
        "\n",
        "#   return best_weights, best_score"
      ],
      "metadata": {
        "id": "_0dRhMlJuPF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "kHqXzFbIypkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_weight_combinations(iter):\n",
        "    combinations = []\n",
        "    for _ in range(iter):\n",
        "        w1 = np.random.rand()\n",
        "        w2 = np.random.rand() * (1 - w1)\n",
        "        w3 = 1 - w1 - w2\n",
        "        combinations.append((w1, w2, w3))\n",
        "    return combinations\n",
        "\n",
        "iter = 10\n",
        "combinations = generate_weight_combinations(iter)\n",
        "for i, combo in enumerate(combinations):\n",
        "    print(f\"Combination {i+1}: {combo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFLV6zhv3TcC",
        "outputId": "00d93f3f-cff0-495b-c1f0-3d4b146cc0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combination 1: (0.6458414485054641, 0.3031001124404972, 0.05105843905403867)\n",
            "Combination 2: (0.5809631519598101, 0.21589852467844373, 0.2031383233617462)\n",
            "Combination 3: (0.377493951373875, 0.006955407191395286, 0.6155506414347297)\n",
            "Combination 4: (0.7344643333908267, 0.1286782882793024, 0.13685737832987088)\n",
            "Combination 5: (0.9601382046237106, 0.01732343690685467, 0.022538358469434753)\n",
            "Combination 6: (0.07239842745791991, 0.32680104617428773, 0.6008005263677924)\n",
            "Combination 7: (0.5990802656544729, 0.1142454171831855, 0.2866743171623416)\n",
            "Combination 8: (0.0400550103501256, 0.225231345951922, 0.7347136436979524)\n",
            "Combination 9: (0.711373743808123, 0.24429538106594947, 0.04433087512592751)\n",
            "Combination 10: (0.8319061800321214, 0.006649174977228679, 0.16144464499064998)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRIAL\n",
        "subdirs = [os.path.join(repo_path, d) for d in os.listdir(repo_path) if os.path.isdir(os.path.join(repo_path, d))]\n",
        "\n",
        "questions = [\"Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘.\",\n",
        "            \"Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어?\"]\n",
        "\n",
        "for question in questions:\n",
        "  best_answer = (\"\", 0.0)\n",
        "  best_subdir = \"\"\n",
        "  best_context_code = \"\"\n",
        "  best_context_pdf = \"\"\n",
        "\n",
        "  qa_code = []\n",
        "  result_code =[]\n",
        "  answer_code =[]\n",
        "  context_code = []\n",
        "  print(f\"\\n---------------------- **Question**: {question} ----------------------\\n\")\n",
        "  for i, subdir in tqdm(enumerate(subdirs)):\n",
        "    # code load setup\n",
        "    loader = GenericLoader.from_filesystem(\n",
        "        repo_path + \"/data_generation\" ,\n",
        "        glob = \"**/*\",\n",
        "        suffixes= [\".py\"],\n",
        "        exclude = [\"**/non-utf8-encoding.py\"],\n",
        "        parser = LanguageParser(language = Language.PYTHON, parser_threshold = 200),\n",
        "    )\n",
        "    python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "        language = Language.PYTHON,\n",
        "        chunk_size = 1000,\n",
        "        chunk_overlap = 100,\n",
        "    )\n",
        "\n",
        "    # code load\n",
        "    documents_code = loader.load()\n",
        "    texts_code = python_splitter.split_documents(documents_code)\n",
        "\n",
        "    db_code = Chroma.from_documents(texts_code,\n",
        "                                OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                                collection_metadata = {'hnsw:space': 'cosine'})\n",
        "\n",
        "    retriever_code = db_code.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "    # prompt\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "    ])\n",
        "    retrieval_chain_code = create_history_aware_retriever(llm, retriever_code, prompt)\n",
        "    # retrieval_chain_pdf = create_history_aware_retriever(llm, retriever_pdf, prompt)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ])\n",
        "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "    # result code\n",
        "    qa_code = create_retrieval_chain(retrieval_chain_code, document_chain)\n",
        "    result_code[i] = qa_code.invoke({\"input\": question})\n",
        "    answer_code[i] = result_code[i]['answer']\n",
        "    context_code[i] = result_code[i]['context']\n",
        "\n",
        "\n",
        "  # pdf load\n",
        "  pdf = PyPDFLoader(\"/content/2302.04761v1 (4).pdf\")\n",
        "  pages = pdf.load_and_split()\n",
        "\n",
        "  db_pdf = Chroma.from_documents(pages,\n",
        "                              OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                              collection_metadata = {'hnsw:space': 'cosine'})\n",
        "\n",
        "  retriever_pdf = db_pdf.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "  # prompt\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      (\"placeholder\", \"{chat_history}\"),\n",
        "      (\"user\", \"{input}\"),\n",
        "      (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "  ])\n",
        "  # retrieval_chain_code = create_history_aware_retriever(llm, retriever_code, prompt)\n",
        "  retrieval_chain_pdf = create_history_aware_retriever(llm, retriever_pdf, prompt)\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "      (\"placeholder\", \"{chat_history}\"),\n",
        "      (\"user\", \"{input}\"),\n",
        "  ])\n",
        "  document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "  # result pdf\n",
        "  qa_pdf = create_retrieval_chain(retrieval_chain_pdf, document_chain)\n",
        "  result_pdf = qa_pdf.invoke({\"input\": question})\n",
        "  answer_pdf = result_pdf['answer']\n",
        "  context_pdf = result_pdf[\"context\"]\n",
        "\n",
        "  for i in range(len(subdirs)):\n",
        "    final_score = answer_quality_score_multiple(question, str(context_code[i]), str(context_pdf[i]), 0.2, 0.3, 0.5)\n",
        "    if final_score > best_answer[1]:\n",
        "      best_answer_code = (answer_code[i], final_score)\n",
        "      best_answer_pdf = (answer_pdf, final_score)\n",
        "      best_subdir = subdir\n",
        "      best_context_pdf = context_pdf\n",
        "      best_context_code = context_code[i]\n",
        "\n",
        "    # print(f\"-> **Question**: {question} \\n\")\n",
        "    # print(f\"**Code 에 대한 대답**: {answer_code} \\n\\n\")\n",
        "    # print(f\"**PDF 에 대한 대답**: {answer_pdf} \\n\\n\")\n",
        "    # print(f\"**Score**: {final_score}\\n\\n\")\n",
        "\n",
        "\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(f\"\\n -> **Question**: {question} \\n\")\n",
        "  print(f\"**Best Score** : {best_answer_code[1]}\")\n",
        "  print(f\"**Best Answer CODE**: {best_answer_code[0]} \\n\\n\")\n",
        "  print(f\"**Best Answer PDF**: {best_answer_pdf[0]} \\n\\n\")\n",
        "  print(f\"**Best Subdirectory**: {best_subdir}\")\n",
        "  print(\"**Best Contex CODE**:\\n\")\n",
        "  print(f\"```python\\n{best_context_code}\\n```\")  # Print context as a formatted code block\n",
        "  print(\"**Best Contex PDF**:\\n\")\n",
        "  print(f\"\\n{best_context_pdf}\\n\")  # Print context as a formatted code block\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "3gOrTCqmn6ZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d644df-af21-411f-bde4-aff4b7c74dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [01:24<00:00, 14.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. \n",
            "\n",
            "**Best Score** : 0.6199304983019829\n",
            "**Best Answer CODE**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 지표입니다. Loss는 모델이 얼마나 잘 작동하는지를 평가하는 중요한 지표 중 하나이며, 최소화되어야 하는 목표입니다.\n",
            "\n",
            "Loss는 주로 모델의 출력과 실제 정답 간의 차이를 계산하는 손실 함수를 통해 계산됩니다. 손실 함수는 모델이 예측한 값과 실제 값 사이의 거리를 측정하고, 이 거리를 최소화하는 방향으로 모델을 학습시키는 역할을 합니다.\n",
            "\n",
            "Toolformer의 Loss는 다양한 요소에 따라 상이할 수 있지만, 일반적으로는 모델이 예측한 값과 실제 값 사이의 차이를 계산하는 함수를 통해 계산됩니다. 이러한 Loss 함수는 주어진 데이터셋과 모델의 목적에 따라 다를 수 있습니다.\n",
            "\n",
            "위의 문맥에서는 Loss에 대한 구체적인 수식이 제공되지 않았기 때문에, 해당 모델의 Loss 함수에 대한 자세한 내용은 문맥에서 확인할 수 없습니다. \n",
            "\n",
            "\n",
            "**Best Answer PDF**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 지표입니다. Loss를 계산하는 방법은 일반적으로 모델의 출력과 실제 정답 간의 거리를 나타내는 손실 함수를 사용하여 수행됩니다. \n",
            "\n",
            "위의 텍스트에서는 Loss에 대한 구체적인 수식은 제시되지 않았습니다. 하지만 Loss를 계산하는 일반적인 방법은 모델의 출력과 실제 정답 간의 차이를 측정하는 손실 함수를 사용하는 것입니다. 손실 함수는 모델이 얼마나 잘 예측했는지를 평가하고, 이를 통해 모델을 훈련시킬 때 사용됩니다.\n",
            "\n",
            "따라서, Toolformer의 Loss를 정확히 계산하려면 해당 모델의 구조와 사용된 손실 함수에 대한 자세한 정보가 필요합니다. 위의 텍스트에서는 Loss에 대한 구체적인 수식이 제시되지 않았기 때문에 해당 정보를 제공할 수 없습니다. \n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/data_generation\n",
            "**Best Contex CODE**:\n",
            "\n",
            "```python\n",
            "[Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "```\n",
            "**Best Contex PDF**:\n",
            "\n",
            "\n",
            "[Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "---------------------- **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:50<00:00,  8.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? \n",
            "\n",
            "**Best Score** : 0.678546816110611\n",
            "**Best Answer CODE**: Toolformer에서 사용되는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공되었습니다. \n",
            "\n",
            "\n",
            "**Best Answer PDF**: Toolformer에서 사용되는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공됩니다. \n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/data_generation\n",
            "**Best Contex CODE**:\n",
            "\n",
            "```python\n",
            "[Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "```\n",
            "**Best Contex PDF**:\n",
            "\n",
            "\n",
            "[Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(result_code[\"context\"][4])"
      ],
      "metadata": {
        "id": "Ob1MFTBy1DjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "471945a3-7cdd-40e9-c819-d1bccf0e15ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"page_content='Model T EMPLAMA D ATESET\\\\nGPT-J 13.7 3.9\\\\nGPT-J + CC 12.9 2.9\\\\nToolformer (disabled) 12.7 5.9\\\\nToolformer 16.3 27.3\\\\nOPT (66B) 14.5 1.3\\\\nGPT-3 (175B) 15.5 0.8\\\\nTable 7: Results for the temporal datasets. Toolformer\\\\noutperforms all baselines, but does not make use of the\\\\ncalendar tool for T EMPLAMA.\\\\nFor both tasks, we use the same evaluation as for\\\\nthe original LAMA dataset.\\\\nResults shown in Table 7 illustrate that Tool-\\\\nformer outperforms all baselines for both TEM-\\\\nPLAMA andDATESET . However, closer inspec-\\\\ntion shows that improvements on TEMPLAMA\\\\ncan not be attributed to the calendar tool, which is\\\\nonly used for 0.2% of all examples, but mostly to\\\\nthe Wikipedia search and question answering tools,\\\\nwhich Toolformer calls the most. This makes sense\\\\ngiven that named entities in TEMPLAMA are often\\\\nso speciﬁc and rare that even knowing the exact\\\\ndate alone would be of little help. The best course\\\\nof action for this dataset – ﬁrst querying the calen-\\\\ndar API to get the current date, and then querying\\\\nthe question answering system with this date – is\\\\nnot only prohibited by our restriction of using at\\\\nmost one API call per example, but also hard to\\\\nlearn for Toolformer given that all API calls in its\\\\ntraining data are sampled independently.\\\\nForDATESET , on the other hand, the consider-\\\\nable improvement of Toolformer compared to other\\\\nmodels can be fully accredited to the calendar tool,\\\\nwhich it makes use of for 54.8% of all examples.\\\\n4.3 Language Modeling\\\\nIn addition to verifying improved performance on\\\\nvarious downstream tasks, we also want to ensure\\\\nthat language modeling performance of Toolformer\\\\ndoes not degrade through our ﬁnetuning with API\\\\ncalls. To this end, we evaluate our models on\\\\ntwo language modeling datasets: WikiText (Mer-\\\\nity et al., 2017) and a subset of 10,000 randomly\\\\nselected documents from CCNet (Wenzek et al.,\\\\n2020) that were not used during training. Perplex-\\\\nities of various models are shown in Table 8. As\\\\none would expect, ﬁnetuning on CCNet leads to\\\\nslightly improved performance on a different CC-\\\\nNet subset, but it slightly deteriorates performance\\\\non WikiText, presumably because the original pre-Model WikiText CCNet\\\\nGPT-J 9.9 10.6\\\\nGPT-J + CC 10.3 10.5\\\\nToolformer (disabled) 10.3 10.5\\\\nTable 8: Perplexities of different models on WikiText\\\\nand our validation subset of CCNet. Adding API calls\\\\ncomes without a cost in terms of perplexity for lan-\\\\nguage modeling without any API calls.\\\\ntraining data for GPT-J is more similar to Wiki-\\\\nText than our randomly selected subset of CCNet.\\\\nMost importantly, however, training on C∗(our\\\\ndataset annotated with API calls) does not lead to\\\\nan increase in perplexity compared to training on\\\\nCwhen API calls are disabled at inference time.8\\\\n4.4 Scaling Laws\\\\nWe investigate how the ability to ask external tools\\\\nfor help affects performance as we vary the size\\\\nof our LM. To this end, we apply our approach\\\\nnot just to GPT-J, but also to four smaller mod-\\\\nels from the GPT-2 family (Radford et al., 2019),\\\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\\\nspectively. We do so using only a subset of three\\\\ntools: the question answering system, the calcula-\\\\ntor, and the Wikipedia search engine. Apart from\\\\nthis, we follow the experimental setup described in\\\\nSection 4.1.\\\\nFigure 4 shows that the ability to leverage the\\\\nprovided tools only emerges at around 775M pa-\\\\nrameters: smaller models achieve similar perfor-\\\\nmance both with and without tools. An exception\\\\nto this is the Wikipedia search engine used mostly\\\\nfor QA benchmarks; we hypothesize that this is\\\\nbecause the API is comparably easy to use. While\\\\nmodels become better at solving tasks without API\\\\ncalls as they grow in size, their ability to make good\\\\nuse of the provided API improves at the same time.\\\\nAs a consequence, there remains a large gap be-\\\\ntween predictions with and without API calls even\\\\nfor our biggest model.\\\\n5 Analysis\\\\nDecoding Strategy We investigate the effect of\\\\nour modiﬁed decoding strategy introduced in Sec-' metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_code[\"answer\"]"
      ],
      "metadata": {
        "id": "1l-HyNrs1Pfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8047d10c-184e-4a3f-9cd0-41ba6644d8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Toolformer에서 사용되는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공되었습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "paYtfSLlbzco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 결과\n",
        "subdirs = [os.path.join(repo_path, d) for d in os.listdir(repo_path) if os.path.isdir(os.path.join(repo_path, d))]\n",
        "subdirs.append(\"/content/test_repo\") # 자기 자신 폴더도 확인되게끔 수정\n",
        "\n",
        "questions = [\"Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘.\",\n",
        "            \"Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어?\"]\n",
        "\n",
        "for question in questions:\n",
        "  best_score = 0.0\n",
        "  best_answer = (\"\")\n",
        "  best_subdir = \"\"\n",
        "  best_context_code = \"\"\n",
        "  best_context_pdf = \"\"\n",
        "\n",
        "  weight_combinations = generate_weight_combinations(200)\n",
        "  print(f\"\\n---------------------- **Question**: {question} ----------------------\\n\")\n",
        "  for subdir in tqdm(subdirs):\n",
        "    # code load setup\n",
        "    loader = GenericLoader.from_filesystem(\n",
        "        subdir,\n",
        "        glob = \"**/*\",\n",
        "        suffixes= [\".py\"],\n",
        "        exclude = [\"**/non-utf8-encoding.py\"],\n",
        "        parser = LanguageParser(language = Language.PYTHON, parser_threshold = 200),\n",
        "    )\n",
        "    python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "        language = Language.PYTHON,\n",
        "        chunk_size = 4000,\n",
        "        chunk_overlap = 100,\n",
        "    )\n",
        "\n",
        "    # code load\n",
        "    documents_code = loader.load()\n",
        "    texts_code = python_splitter.split_documents(documents_code)\n",
        "\n",
        "    # 만약 .py 가 없는 빈 폴더면 error 가 나기 때문에 error handling\n",
        "    try:\n",
        "      db_code = Chroma.from_documents(texts_code,\n",
        "                                  OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                                  collection_metadata = {'hnsw:space': 'cosine'},\n",
        "                                      collection_name = \"code\")\n",
        "      retriever_code = db_code.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
        "\n",
        "      # prompt\n",
        "      prompt = ChatPromptTemplate.from_messages([\n",
        "          (\"placeholder\", \"{chat_history}\"),\n",
        "          (\"user\", \"{input}\"),\n",
        "          (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "      ])\n",
        "      retrieval_chain_code = create_history_aware_retriever(llm, retriever_code, prompt)\n",
        "      # retrieval_chain_pdf = create_history_aware_retriever(llm, retriever_pdf, prompt)\n",
        "\n",
        "      prompt = ChatPromptTemplate.from_messages([\n",
        "          (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "          (\"placeholder\", \"{chat_history}\"),\n",
        "          (\"user\", \"{input}\"),\n",
        "      ])\n",
        "      document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "      # result code\n",
        "      qa_code = create_retrieval_chain(retrieval_chain_code, document_chain)\n",
        "      result_code = qa_code.invoke({\"input\": question})\n",
        "      answer_code = result_code['answer']\n",
        "      context_code = result_code['context']\n",
        "\n",
        "    except ValueError as e:\n",
        "      print(f\"Skipping subdir {subdir} due to error: {e}\")\n",
        "      continue\n",
        "\n",
        "\n",
        "    # pdf load\n",
        "    pdf = PyPDFLoader(\"/content/2302.04761v1 (4).pdf\")\n",
        "    pages = pdf.load_and_split()\n",
        "\n",
        "    db_pdf = Chroma.from_documents(pages,\n",
        "                                OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                                collection_metadata = {'hnsw:space': 'cosine'},\n",
        "                                   collection_name = \"pdf\") # collection_name 을 설정해주지 않으면\n",
        "\n",
        "    retriever_pdf = db_pdf.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
        "\n",
        "    # prompt\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "    ])\n",
        "    # retrieval_chain_code = create_history_aware_retriever(llm, retriever_code, prompt)\n",
        "    retrieval_chain_pdf = create_history_aware_retriever(llm, retriever_pdf, prompt)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ])\n",
        "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "    # result pdf\n",
        "    qa_pdf = create_retrieval_chain(retrieval_chain_pdf, document_chain)\n",
        "    result_pdf = qa_pdf.invoke({\"input\": question})\n",
        "    answer_pdf = result_pdf['answer']\n",
        "    context_pdf = result_pdf[\"context\"]\n",
        "\n",
        "    context_code_str = str(context_code)\n",
        "    context_pdf_str = str(context_pdf)\n",
        "    for i, weights in enumerate(weight_combinations):\n",
        "        final_score = answer_quality_score_multiple(question, context_code_str, context_pdf_str, *weights)\n",
        "        if final_score > best_score:\n",
        "            best_score = final_score # final score update to better score\n",
        "            best_answer_code = (answer_code, final_score)\n",
        "            best_answer_pdf = (answer_pdf, final_score)\n",
        "            best_subdir = subdir\n",
        "            best_context_pdf = context_pdf\n",
        "            best_context_code = context_code\n",
        "            best_weights = weights\n",
        "        if i % 50 == 0:\n",
        "                        print(f\"Iteration {i}: Current best score: {best_score} &&& Best Weights {i} : {best_weights}\")\n",
        "\n",
        "\n",
        "    # print(f\"-> **Question**: {question} \\n\")\n",
        "    # print(f\"**Code 에 대한 대답**: {answer_code} \\n\\n\")\n",
        "    # print(f\"**PDF 에 대한 대답**: {answer_pdf} \\n\\n\")\n",
        "    # print(f\"**Score**: {final_score}\\n\\n\")\n",
        "\n",
        "\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(f\"\\n -> **Question**: {question} \\n\")\n",
        "  print(f\"**Best Score** : {best_answer_code[1]}\")\n",
        "  print(f\"**Best Answer CODE**: {best_answer_code[0]} \\n\\n\")\n",
        "  print(f\"**Best Answer PDF**: {best_answer_pdf[0]} \\n\\n\")\n",
        "  print(f\"**Best Subdirectory**: {best_subdir}\")\n",
        "  print(\"**Best Contex CODE**:\\n\")\n",
        "  print(f\"```python\\n{best_context_code}\\n```\")  # Print context as a formatted code block\n",
        "  print(\"**Best Contex PDF**:\\n\")\n",
        "  print(f\"\\n{best_context_pdf}\\n\")  # Print context as a formatted code block\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sQD9WrK8kH4",
        "outputId": "6acf0d80-1ef2-4fb6-f24a-6abb109cdabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1/7 [00:00<00:00,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping subdir /content/test_repo/configs due to error: Expected IDs to be a non-empty list, got 0 IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 2/7 [00:00<00:00,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping subdir /content/test_repo/.git due to error: Expected IDs to be a non-empty list, got 0 IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 3/7 [00:00<00:00,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping subdir /content/test_repo/customToolformer due to error: Expected IDs to be a non-empty list, got 0 IDs\n",
            "Iteration 0: Current best score: 0.2707290613419365 &&& Best Weights 0 : (0.05833172127228492, 0.468322870745821, 0.47334540798189406)\n",
            "Iteration 50: Current best score: 0.29823141446619317 &&& Best Weights 50 : (0.01909716266705186, 0.0886406818341952, 0.892262155498753)\n",
            "Iteration 100: Current best score: 0.298280169186453 &&& Best Weights 100 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 150: Current best score: 0.298280169186453 &&& Best Weights 150 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 4/7 [01:27<01:43, 34.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.298280169186453 &&& Best Weights 0 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 50: Current best score: 0.298280169186453 &&& Best Weights 50 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 100: Current best score: 0.298280169186453 &&& Best Weights 100 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 150: Current best score: 0.298280169186453 &&& Best Weights 150 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 5/7 [02:47<01:41, 50.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.298280169186453 &&& Best Weights 0 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 50: Current best score: 0.298280169186453 &&& Best Weights 50 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 100: Current best score: 0.298280169186453 &&& Best Weights 100 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 150: Current best score: 0.298280169186453 &&& Best Weights 150 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 6/7 [04:08<01:01, 61.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.298280169186453 &&& Best Weights 0 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 50: Current best score: 0.298280169186453 &&& Best Weights 50 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 100: Current best score: 0.298280169186453 &&& Best Weights 100 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n",
            "Iteration 150: Current best score: 0.298280169186453 &&& Best Weights 150 : (0.061434197609660846, 0.04425111941317697, 0.8943146829771622)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [05:27<00:00, 46.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. \n",
            "\n",
            "**Best Score** : 0.298280169186453\n",
            "**Best Answer CODE**: Toolformer의 Loss는 주어진 입력에 대한 출력과 실제 정답 사이의 차이를 측정하는 방법입니다. Loss 함수는 모델이 학습 중에 최소화하려는 값으로 사용됩니다. Toolformer의 Loss 함수는 다음과 같은 수식으로 나타낼 수 있습니다:\n",
            "\n",
            "\\[ \\text{Loss} = \\sum_{i=1}^{N} \\text{Loss}_i \\]\n",
            "\n",
            "여기서 \\( N \\)은 배치 크기를 나타내며, 각 샘플에 대한 손실을 나타내는 \\( \\text{Loss}_i \\)는 다음과 같이 정의됩니다:\n",
            "\n",
            "\\[ \\text{Loss}_i = \\frac{1}{M} \\sum_{j=1}^{M} \\text{L}(\\text{output}_{i,j}, \\text{target}_{i,j}) \\]\n",
            "\n",
            "여기서 \\( M \\)은 최소 손실 범위를 나타내며, \\( \\text{output}_{i,j} \\)는 모델의 출력이고, \\( \\text{target}_{i,j} \\)는 실제 정답입니다.\n",
            "\n",
            "이 답변은 주어진 정보를 기반으로 추론하여 제공되었습니다. \n",
            "\n",
            "\n",
            "**Best Answer PDF**: Toolformer의 Loss는 주어진 데이터셋에 대한 모델의 예측과 실제 정답 간의 차이를 측정하는 지표입니다. Loss는 보통 모델이 예측한 값과 실제 값 사이의 오차를 나타내는 함수를 통해 계산됩니다. 이러한 함수는 주로 평균 제곱 오차(Mean Squared Error)나 교차 엔트로피 손실(Cross-Entropy Loss) 등이 사용됩니다.\n",
            "\n",
            "Toolformer의 Loss 수식은 논문에서 명시되어 있지 않지만, 주로 사용되는 Loss 함수 중 하나를 적용하여 모델의 성능을 평가할 수 있습니다. Loss 함수는 모델이 학습하는 동안 역전파(backpropagation) 알고리즘을 통해 최적화되는데, 이를 통해 모델이 예측을 개선하고 손실을 최소화하도록 학습됩니다.\n",
            "\n",
            "이러한 정보는 논문에서 자세히 설명되어 있지 않기 때문에, Loss 함수의 구체적인 수식은 논문에 명시된 내용을 기반으로 추론하여 설명드리고 있습니다. \n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/flash_attention\n",
            "**Best Contex CODE**:\n",
            "\n",
            "```python\n",
            "[Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import Calculator\\nfrom prompts import calculator_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\nimport dateutil.parser as dparser\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nM = 16  # Min Loss Span To Consider\\nMAX_LEN = 1024  # Maximum calculator length', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/calculator.py'}), Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import Calculator\\nfrom prompts import calculator_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\nimport dateutil.parser as dparser\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nM = 16  # Min Loss Span To Consider\\nMAX_LEN = 1024  # Maximum calculator length', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/calculator.py'}), Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import Calculator\\nfrom prompts import calculator_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\nimport dateutil.parser as dparser\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nM = 16  # Min Loss Span To Consider\\nMAX_LEN = 1024  # Maximum calculator length', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/calculator.py'})]\n",
            "```\n",
            "**Best Contex PDF**:\n",
            "\n",
            "\n",
            "[Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='Model T EMPLAMA D ATESET\\nGPT-J 13.7 3.9\\nGPT-J + CC 12.9 2.9\\nToolformer (disabled) 12.7 5.9\\nToolformer 16.3 27.3\\nOPT (66B) 14.5 1.3\\nGPT-3 (175B) 15.5 0.8\\nTable 7: Results for the temporal datasets. Toolformer\\noutperforms all baselines, but does not make use of the\\ncalendar tool for T EMPLAMA.\\nFor both tasks, we use the same evaluation as for\\nthe original LAMA dataset.\\nResults shown in Table 7 illustrate that Tool-\\nformer outperforms all baselines for both TEM-\\nPLAMA andDATESET . However, closer inspec-\\ntion shows that improvements on TEMPLAMA\\ncan not be attributed to the calendar tool, which is\\nonly used for 0.2% of all examples, but mostly to\\nthe Wikipedia search and question answering tools,\\nwhich Toolformer calls the most. This makes sense\\ngiven that named entities in TEMPLAMA are often\\nso speciﬁc and rare that even knowing the exact\\ndate alone would be of little help. The best course\\nof action for this dataset – ﬁrst querying the calen-\\ndar API to get the current date, and then querying\\nthe question answering system with this date – is\\nnot only prohibited by our restriction of using at\\nmost one API call per example, but also hard to\\nlearn for Toolformer given that all API calls in its\\ntraining data are sampled independently.\\nForDATESET , on the other hand, the consider-\\nable improvement of Toolformer compared to other\\nmodels can be fully accredited to the calendar tool,\\nwhich it makes use of for 54.8% of all examples.\\n4.3 Language Modeling\\nIn addition to verifying improved performance on\\nvarious downstream tasks, we also want to ensure\\nthat language modeling performance of Toolformer\\ndoes not degrade through our ﬁnetuning with API\\ncalls. To this end, we evaluate our models on\\ntwo language modeling datasets: WikiText (Mer-\\nity et al., 2017) and a subset of 10,000 randomly\\nselected documents from CCNet (Wenzek et al.,\\n2020) that were not used during training. Perplex-\\nities of various models are shown in Table 8. As\\none would expect, ﬁnetuning on CCNet leads to\\nslightly improved performance on a different CC-\\nNet subset, but it slightly deteriorates performance\\non WikiText, presumably because the original pre-Model WikiText CCNet\\nGPT-J 9.9 10.6\\nGPT-J + CC 10.3 10.5\\nToolformer (disabled) 10.3 10.5\\nTable 8: Perplexities of different models on WikiText\\nand our validation subset of CCNet. Adding API calls\\ncomes without a cost in terms of perplexity for lan-\\nguage modeling without any API calls.\\ntraining data for GPT-J is more similar to Wiki-\\nText than our randomly selected subset of CCNet.\\nMost importantly, however, training on C∗(our\\ndataset annotated with API calls) does not lead to\\nan increase in perplexity compared to training on\\nCwhen API calls are disabled at inference time.8\\n4.4 Scaling Laws\\nWe investigate how the ability to ask external tools\\nfor help affects performance as we vary the size\\nof our LM. To this end, we apply our approach\\nnot just to GPT-J, but also to four smaller mod-\\nels from the GPT-2 family (Radford et al., 2019),\\nwith 124M, 355M, 775M and 1.6B parameters, re-\\nspectively. We do so using only a subset of three\\ntools: the question answering system, the calcula-\\ntor, and the Wikipedia search engine. Apart from\\nthis, we follow the experimental setup described in\\nSection 4.1.\\nFigure 4 shows that the ability to leverage the\\nprovided tools only emerges at around 775M pa-\\nrameters: smaller models achieve similar perfor-\\nmance both with and without tools. An exception\\nto this is the Wikipedia search engine used mostly\\nfor QA benchmarks; we hypothesize that this is\\nbecause the API is comparably easy to use. While\\nmodels become better at solving tasks without API\\ncalls as they grow in size, their ability to make good\\nuse of the provided API improves at the same time.\\nAs a consequence, there remains a large gap be-\\ntween predictions with and without API calls even\\nfor our biggest model.\\n5 Analysis\\nDecoding Strategy We investigate the effect of\\nour modiﬁed decoding strategy introduced in Sec-', metadata={'page': 7, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "---------------------- **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1/7 [00:00<00:00,  7.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping subdir /content/test_repo/configs due to error: Expected IDs to be a non-empty list, got 0 IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 2/7 [00:00<00:00,  7.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping subdir /content/test_repo/.git due to error: Expected IDs to be a non-empty list, got 0 IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 3/7 [00:00<00:00,  7.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping subdir /content/test_repo/customToolformer due to error: Expected IDs to be a non-empty list, got 0 IDs\n",
            "Iteration 0: Current best score: 0.362810556496564 &&& Best Weights 0 : (0.2356590447803738, 0.3952420385543589, 0.3690989166652673)\n",
            "Iteration 50: Current best score: 0.454956232543908 &&& Best Weights 50 : (0.052081988368480436, 0.0410460884226835, 0.906871923208836)\n",
            "Iteration 100: Current best score: 0.454956232543908 &&& Best Weights 100 : (0.052081988368480436, 0.0410460884226835, 0.906871923208836)\n",
            "Iteration 150: Current best score: 0.454956232543908 &&& Best Weights 150 : (0.052081988368480436, 0.0410460884226835, 0.906871923208836)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 4/7 [01:11<01:25, 28.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.4573482313929848 &&& Best Weights 0 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 50: Current best score: 0.4573482313929848 &&& Best Weights 50 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 100: Current best score: 0.4573482313929848 &&& Best Weights 100 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 150: Current best score: 0.4573482313929848 &&& Best Weights 150 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 5/7 [02:26<01:30, 45.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.4573482313929848 &&& Best Weights 0 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 50: Current best score: 0.4573482313929848 &&& Best Weights 50 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 100: Current best score: 0.4573482313929848 &&& Best Weights 100 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 150: Current best score: 0.4573482313929848 &&& Best Weights 150 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 6/7 [03:46<00:56, 56.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.4573482313929848 &&& Best Weights 0 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 50: Current best score: 0.4573482313929848 &&& Best Weights 50 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 100: Current best score: 0.4573482313929848 &&& Best Weights 100 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n",
            "Iteration 150: Current best score: 0.4573482313929848 &&& Best Weights 150 : (0.008551616023304232, 0.1232970923419235, 0.8681512916347722)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [05:01<00:00, 43.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? \n",
            "\n",
            "**Best Score** : 0.4573482313929848\n",
            "**Best Answer CODE**: Toolformer에서 사용되는 도구들은 다음과 같습니다:\n",
            "- torch\n",
            "- transformers\n",
            "- langchain_llmchain\n",
            "- llmchain_prompt\n",
            "- typing\n",
            "- base_api\n",
            "\n",
            "이 정보는 주어진 코드에서 가져온 것입니다. \n",
            "\n",
            "\n",
            "**Best Answer PDF**: Toolformer가 사용하는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 언급되었습니다. \n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/flash_attention\n",
            "**Best Contex CODE**:\n",
            "\n",
            "```python\n",
            "[Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import langchain_llmchain\\nfrom prompts import llmchain_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\n\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nMAX_LEN = 1024  # Maximum retrieval length\\nM = 16  # Min Loss Span To Consider', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/llmchain.py'}), Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import langchain_llmchain\\nfrom prompts import llmchain_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\n\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nMAX_LEN = 1024  # Maximum retrieval length\\nM = 16  # Min Loss Span To Consider', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/llmchain.py'}), Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import langchain_llmchain\\nfrom prompts import llmchain_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\n\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nMAX_LEN = 1024  # Maximum retrieval length\\nM = 16  # Min Loss Span To Consider', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/llmchain.py'})]\n",
            "```\n",
            "**Best Contex PDF**:\n",
            "\n",
            "\n",
            "[Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 위에가 잘 안되는 이유\n",
        "\n",
        "Weighted Sum 을 하나의 component 가 dominate 함. score 를 내기 더 쉬운 방향으로만 학습하려고 하지, 우리가 의도한 올바른 학습방향으로 학습하려고 하지 않음.\n",
        "\n",
        "- 해결방안 1 : 클러스터 자체를 바꿔야 함. context_pdf 와 context_code term 이 final_score 를 dominate 하므로, 3가지를 균형있게 밸런싱 할 수 있는 새로운 클러스터(객체) 가 필요.\n",
        "\n",
        "  - 혹은 클러스터를 더 잘게 쪼개보는 방법. (당연한것. 현재 모든 객체를 고려하지 못함. - `answer_pdf`, `answer_code` 객체가 없음.)\n",
        "\n",
        "- 해결방안 2 : 아니면 metric 을 바꿔야 함."
      ],
      "metadata": {
        "id": "s7_lcT9BVv-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(weight_combinations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzbmYyvLIIb",
        "outputId": "7faf8f81-eac3-42fe-c7d3-7d69d78f2a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUkNuTAsE5Z8",
        "outputId": "14ce3fb7-1d04-43d2-c5e5-b3bf372a8540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='class Toolformer(nn.Module):\\n    def __init__(\\n        self,\\n        dim,\\n        num_tokens,\\n        depth,\\n        dim_head=64,\\n        heads=8,\\n        ff_mult=4,\\n    ):\\n        super().__init__()\\n\\n        self.emb = nn.Embedding(num_tokens, dim)\\n        self.transformer = Transformer(dim, depth, heads, dim_head, ff_mult)\\n        self.to_logits = nn.Linear(dim, num_tokens)\\n\\n    def forward(self, x):\\n        x = self.emb(x)\\n        x = self.transformer(x)\\n        x = self.to_logits(x)\\n        return x', metadata={'content_type': 'functions_classes', 'language': 'python', 'source': '/content/test_repo/gptj_pytorch.py'}),\n",
              " Document(page_content='class Toolformer(nn.Module):\\n    def __init__(\\n        self,\\n        dim,\\n        num_tokens,\\n        depth,\\n        dim_head=64,\\n        heads=8,\\n        ff_mult=4,\\n    ):\\n        super().__init__()\\n\\n        self.emb = nn.Embedding(num_tokens, dim)\\n        self.transformer = Transformer(dim, depth, heads, dim_head, ff_mult)\\n        self.to_logits = nn.Linear(dim, num_tokens)\\n\\n    def forward(self, x):\\n        x = self.emb(x)\\n        x = self.transformer(x)\\n        x = self.to_logits(x)\\n        return x', metadata={'content_type': 'functions_classes', 'language': 'python', 'source': '/content/test_repo/gptj_pytorch.py'}),\n",
              " Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import langchain_llmchain\\nfrom prompts import llmchain_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\n\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nMAX_LEN = 1024  # Maximum retrieval length\\nM = 16  # Min Loss Span To Consider', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/llmchain.py'})]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oleh11DWBNht",
        "outputId": "b247c49d-5e70-4b55-b8b6-b6774ff5849f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Toolformer가 사용하는 도구에는 계산기, 질의응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. 이 정보는 논문 \"Toolformer: Language Models Can Teach Themselves to Use Tools\"에서 제공되었습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_combinations = generate_weight_combinations(1000)\n",
        "weight_combinations[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmPb_PQOII5M",
        "outputId": "a371e0aa-0f01-4271-9c18-00d4ffcb788b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.15870159635633874, 0.26677729606427003, 0.5745211075793912)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 3\n"
      ],
      "metadata": {
        "id": "sF25-pwPOwio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_quality_score_quintuple(question: str, context_code, context_pdf, answer_code, answer_pdf,\n",
        "                                   weight_qc=0.1, weight_qp=0.1, weight_qac=0.1, weight_qap=0.1, weight_cac=0.1,\n",
        "                                   weight_cap=0.1, weight_cpdf=0.1, weight_pap=0.1, weight_capdf=0.1, weight_cp=0.1):\n",
        "    # Embedding\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    context_code_embedding = model.encode(context_code, convert_to_tensor=True)\n",
        "    context_pdf_embedding = model.encode(context_pdf, convert_to_tensor=True)\n",
        "    answer_code_embedding = model.encode(answer_code, convert_to_tensor=True)\n",
        "    answer_pdf_embedding = model.encode(answer_pdf, convert_to_tensor=True)\n",
        "\n",
        "    # cosine simliarity\n",
        "    cos_sim_qc = util.cos_sim(question_embedding, context_code_embedding)\n",
        "    cos_sim_qp = util.cos_sim(question_embedding, context_pdf_embedding)\n",
        "    cos_sim_qac = util.cos_sim(question_embedding, answer_code_embedding)\n",
        "    cos_sim_qap = util.cos_sim(question_embedding, answer_pdf_embedding)\n",
        "    cos_sim_cac = util.cos_sim(context_code_embedding, answer_code_embedding)\n",
        "    cos_sim_cap = util.cos_sim(context_code_embedding, answer_pdf_embedding)\n",
        "    cos_sim_cpdf = util.cos_sim(context_code_embedding, context_pdf_embedding)\n",
        "    cos_sim_pap = util.cos_sim(context_pdf_embedding, answer_pdf_embedding)\n",
        "    cos_sim_capdf = util.cos_sim(context_code_embedding, context_pdf_embedding)\n",
        "    cos_sim_cp = util.cos_sim(context_code_embedding, context_pdf_embedding)\n",
        "\n",
        "    # weighted sum of score\n",
        "    normalized_score = (float(cos_sim_qc.item()) * weight_qc + float(cos_sim_qp.item()) * weight_qp +\n",
        "                        float(cos_sim_qac.item()) * weight_qac + float(cos_sim_qap.item()) * weight_qap +\n",
        "                        float(cos_sim_cac.item()) * weight_cac + float(cos_sim_cap.item()) * weight_cap +\n",
        "                        float(cos_sim_cpdf.item()) * weight_cpdf + float(cos_sim_pap.item()) * weight_pap +\n",
        "                        float(cos_sim_capdf.item()) * weight_capdf + float(cos_sim_cp.item()) * weight_cp)\n",
        "\n",
        "    return normalized_score"
      ],
      "metadata": {
        "id": "JOVvIclOQZca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_weight_combinations_10(iter):\n",
        "    combinations = []\n",
        "    for _ in range(iter):\n",
        "        weights = np.random.rand(10)\n",
        "        weights /= weights.sum()  # Normalize the weights so that their sum is 1\n",
        "        combinations.append(tuple(weights))\n",
        "    return combinations\n",
        "\n",
        "weight_combinations = generate_weight_combinations_10(3)\n",
        "for weights in weight_combinations:\n",
        "    print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX1MdHStSpzK",
        "outputId": "e4f65e91-9fa1-4898-d934-aa5565b1fc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.1492176761662531, 0.12558587951920738, 0.12138937726289858, 0.15165358259387174, 0.02300107715495243, 0.02215443035693413, 0.027779184781749264, 0.10544386298898391, 0.10132429970211483, 0.17245062947303463)\n",
            "(0.07067470904833198, 0.11781920969103751, 0.13208277390755996, 0.005360342802557969, 0.0656387865377058, 0.07502715008402899, 0.17304823682644624, 0.15256441797620823, 0.15572730158092848, 0.05205707154519494)\n",
            "(0.11820045043024718, 0.03125748285552181, 0.17833501118426026, 0.16037076044423199, 0.08653647978247064, 0.07310523938181737, 0.0958217004051037, 0.02141444296057042, 0.07074221781624905, 0.16421621473952758)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subdirs.append(\"/content/test_repo\")"
      ],
      "metadata": {
        "id": "TtmSDhI8as-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7w4MMfTna0W4",
        "outputId": "5bb9f129-5000-46ce-a619-db127410669b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test_repo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subdirs = [os.path.join(repo_path, d) for d in os.listdir(repo_path) if os.path.isdir(os.path.join(repo_path, d))]\n",
        "subdirs.append(\"/content/test_repo\") # 자기 자신 폴더도 확인되게끔 수정\n",
        "\n",
        "questions = [\"Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘.\",\n",
        "            \"Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어?\"]\n",
        "\n",
        "for question in questions:\n",
        "  best_score = 0.0\n",
        "  best_answer = (\"\")\n",
        "  best_subdir = \"\"\n",
        "  best_context_code = \"\"\n",
        "  best_context_pdf = \"\"\n",
        "\n",
        "  weight_combinations = generate_weight_combinations_10(200)\n",
        "  print(f\"\\n---------------------- **Question**: {question} ----------------------\\n\")\n",
        "\n",
        "  for i, weights in enumerate(tqdm(weight_combinations, miniters=int(round(len(weight_combinations)/100)))):\n",
        "    for subdir in subdirs:\n",
        "      # code load setup\n",
        "      loader = GenericLoader.from_filesystem(\n",
        "          subdir,\n",
        "          glob = \"**/*\",\n",
        "          suffixes= [\".py\"],\n",
        "          exclude = [\"**/non-utf8-encoding.py\"],\n",
        "          parser = LanguageParser(language = Language.PYTHON, parser_threshold = 200),\n",
        "      )\n",
        "      python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "          language = Language.PYTHON,\n",
        "          chunk_size = 4000,\n",
        "          chunk_overlap = 100,\n",
        "      )\n",
        "\n",
        "      # code load\n",
        "      documents_code = loader.load()\n",
        "      texts_code = python_splitter.split_documents(documents_code)\n",
        "\n",
        "      # 만약 .py 가 없는 빈 폴더면 error 가 나기 때문에 error handling\n",
        "      try:\n",
        "        db_code = Chroma.from_documents(texts_code,\n",
        "                                    OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                                    collection_metadata = {'hnsw:space': 'cosine'},\n",
        "                                        collection_name = \"code\")\n",
        "        retriever_code = db_code.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
        "\n",
        "        # prompt\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "            (\"user\", \"{input}\"),\n",
        "            (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "        ])\n",
        "        retrieval_chain_code = create_history_aware_retriever(llm, retriever_code, prompt)\n",
        "        # retrieval_chain_pdf = create_history_aware_retriever(llm, retriever_pdf, prompt)\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "            (\"user\", \"{input}\"),\n",
        "        ])\n",
        "        document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "        # result code\n",
        "        qa_code = create_retrieval_chain(retrieval_chain_code, document_chain)\n",
        "        result_code = qa_code.invoke({\"input\": question})\n",
        "        answer_code = result_code['answer']\n",
        "        context_code = result_code['context']\n",
        "\n",
        "      except ValueError as e:\n",
        "        pass\n",
        "        # print(f\"Skipping subdir {subdir} due to error: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "      # pdf load\n",
        "      pdf = PyPDFLoader(\"/content/2302.04761v1 (4).pdf\")\n",
        "      pages = pdf.load_and_split()\n",
        "\n",
        "      db_pdf = Chroma.from_documents(pages,\n",
        "                                  OpenAIEmbeddings(openai_api_key=api_key, disallowed_special=()),\n",
        "                                  collection_metadata = {'hnsw:space': 'cosine'},\n",
        "                                    collection_name = \"pdf\") # collection_name 을 설정해주지 않으면\n",
        "\n",
        "      retriever_pdf = db_pdf.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
        "\n",
        "      # prompt\n",
        "      prompt = ChatPromptTemplate.from_messages([\n",
        "          (\"placeholder\", \"{chat_history}\"),\n",
        "          (\"user\", \"{input}\"),\n",
        "          (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation.\"),\n",
        "      ])\n",
        "      # retrieval_chain_code = create_history_aware_retriever(llm, retriever_code, prompt)\n",
        "      retrieval_chain_pdf = create_history_aware_retriever(llm, retriever_pdf, prompt)\n",
        "\n",
        "      prompt = ChatPromptTemplate.from_messages([\n",
        "          (\"system\", \"Answer the user's question based on the below context : \\n\\n{context}. By each answer, should always give where the answer's source came from. If you can't find the answer, you should do the inference and give me the answer.\"),\n",
        "          (\"placeholder\", \"{chat_history}\"),\n",
        "          (\"user\", \"{input}\"),\n",
        "      ])\n",
        "      document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "      # result pdf\n",
        "      qa_pdf = create_retrieval_chain(retrieval_chain_pdf, document_chain)\n",
        "      result_pdf = qa_pdf.invoke({\"input\": question})\n",
        "      answer_pdf = result_pdf['answer']\n",
        "      context_pdf = result_pdf[\"context\"]\n",
        "\n",
        "      context_code_str = str(context_code)\n",
        "      context_pdf_str = str(context_pdf)\n",
        "\n",
        "      # CALCULATE the final score\n",
        "      final_score = answer_quality_score_quintuple(question, context_code_str, context_pdf_str, answer_code, answer_pdf, *weights)\n",
        "      if final_score > best_score:\n",
        "          best_score = final_score # final score update to better score\n",
        "          best_answer_code = (answer_code, final_score)\n",
        "          best_answer_pdf = (answer_pdf, final_score)\n",
        "          best_subdir = subdir\n",
        "          best_context_pdf = context_pdf\n",
        "          best_context_code = context_code\n",
        "          best_weights = weights\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print(f\"Iteration {i}: Current best score: {best_score} &&& Best Weights {i} : {best_weights}\")\n",
        "\n",
        "\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(f\"\\n -> **Question**: {question} \\n\")\n",
        "  print(f\"**Best Score** : {best_answer_code[1]}\")\n",
        "  print(f\"**Best Answer CODE**: {best_answer_code[0]} \\n\\n\")\n",
        "  print(f\"**Best Answer PDF**: {best_answer_pdf[0]} \\n\\n\")\n",
        "  print(f\"**Best Subdirectory**: {best_subdir}\")\n",
        "  print(\"**Best Contex CODE**:\\n\")\n",
        "  print(f\"```python\\n{best_context_code}\\n```\")  # Print context as a formatted code block\n",
        "  print(\"**Best Contex PDF**:\\n\")\n",
        "  print(f\"\\n{best_context_pdf}\\n\")  # Print context as a formatted code block\n",
        "  print(\"--------------------------------------------------------------------------\")\n",
        "  print(\"--------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnrsU5z0OyG8",
        "outputId": "7847f11d-1ab4-413b-947b-76c42dd65cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:52<2:55:11, 52.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.3628209783691579 &&& Best Weights 0 : (0.0852772530223539, 0.15608551493568135, 0.0022446145603125765, 0.13691004128762826, 0.0877927546339296, 0.05277234222440326, 0.08112802382357454, 0.1500090008945868, 0.14881835744910274, 0.09896209716842692)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [09:48<2:49:54, 53.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10: Current best score: 0.43022003265777364 &&& Best Weights 10 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [19:03<2:43:30, 54.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 20: Current best score: 0.43022003265777364 &&& Best Weights 20 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [27:57<2:34:37, 54.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 30: Current best score: 0.43022003265777364 &&& Best Weights 30 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [36:49<2:22:57, 53.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 40: Current best score: 0.43022003265777364 &&& Best Weights 40 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [45:46<2:12:51, 53.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 50: Current best score: 0.43022003265777364 &&& Best Weights 50 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [54:23<1:57:19, 50.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 60: Current best score: 0.43022003265777364 &&& Best Weights 60 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [1:02:10<1:43:02, 47.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 70: Current best score: 0.43022003265777364 &&& Best Weights 70 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [1:09:58<1:32:45, 46.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 80: Current best score: 0.43022003265777364 &&& Best Weights 80 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [1:17:46<1:26:26, 47.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 90: Current best score: 0.43022003265777364 &&& Best Weights 90 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [1:25:24<1:14:39, 45.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100: Current best score: 0.43022003265777364 &&& Best Weights 100 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [1:33:03<1:09:34, 46.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 110: Current best score: 0.43022003265777364 &&& Best Weights 110 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [1:40:51<1:00:42, 46.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 120: Current best score: 0.43022003265777364 &&& Best Weights 120 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [1:48:58<55:44, 48.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 130: Current best score: 0.43022003265777364 &&& Best Weights 130 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [1:56:44<44:46, 45.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 140: Current best score: 0.43022003265777364 &&& Best Weights 140 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [2:04:09<35:43, 43.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 150: Current best score: 0.43022003265777364 &&& Best Weights 150 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [2:11:39<29:29, 45.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 160: Current best score: 0.43022003265777364 &&& Best Weights 160 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [2:19:10<21:45, 45.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 170: Current best score: 0.43022003265777364 &&& Best Weights 170 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [2:27:00<14:36, 46.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 180: Current best score: 0.43022003265777364 &&& Best Weights 180 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [2:35:11<07:20, 48.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 190: Current best score: 0.43022003265777364 &&& Best Weights 190 : (0.11952944023749872, 0.06646392642573881, 0.1798993747710065, 0.10143256134366915, 0.0742174261464129, 0.0030760379730034246, 0.0661481786552112, 0.07338172903273636, 0.2086029765719843, 0.10724834884273865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [2:42:32<00:00, 48.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 의 Loss 는 어떻게 상정되는지 Loss 의 수식을 중심으로 알려줘. \n",
            "\n",
            "**Best Score** : 0.4450754576831272\n",
            "**Best Answer CODE**: Toolformer의 Loss는 주어진 입력에 대한 모델의 출력과 실제 정답 사이의 차이를 측정하는 방법입니다. Loss 함수는 모델이 학습 중에 최적화되는 방향을 제시하며, 모델이 예측을 개선할 수 있도록 도와줍니다.\n",
            "\n",
            "Toolformer의 Loss 수식은 다음과 같이 표현될 수 있습니다:\n",
            "```python\n",
            "loss = criterion(outputs, targets)\n",
            "```\n",
            "\n",
            "여기서 `outputs`는 모델의 예측값이고, `targets`는 실제 정답값입니다. Loss 함수는 이 두 값 사이의 차이를 계산하여 모델이 얼마나 잘 예측했는지를 측정합니다.\n",
            "\n",
            "이 답변은 제공된 코드에서 Loss 함수의 구체적인 수식이 언급되지 않았기 때문에 추론을 통해 답변을 제공하였습니다. \n",
            "\n",
            "\n",
            "**Best Answer PDF**: Toolformer의 Loss는 API 호출을 포함한 예제에 대해 아직 Feintuned되지 않았기 때문에 x의 중간에 삽입하면 흐름을 방해하고 사전 훈련 코퍼스의 패턴과 일치하지 않아 Perplexity를 해치게 됩니다. Loss의 수식에 대한 정보는 제공되지 않았습니다. \n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/flash_attention\n",
            "**Best Contex CODE**:\n",
            "\n",
            "```python\n",
            "[Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import Calculator\\nfrom prompts import calculator_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\nimport dateutil.parser as dparser\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nM = 16  # Min Loss Span To Consider\\nMAX_LEN = 1024  # Maximum calculator length', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/calculator.py'}), Document(page_content='import torch\\nfrom transformers import (\\n    PreTrainedTokenizerBase,\\n    PreTrainedModel,\\n)\\nfrom tools import Calculator\\nfrom prompts import calculator_prompt\\nfrom typing import List\\nfrom data_generation.base_api import APICallPostprocessing\\nimport dateutil.parser as dparser\\n\\n\\n# TODO: Per API?\\nMAX_BATCH_SIZE = 1  # My 3090 is weak 😔\\nN = 128  # SEQ Len\\nM = 16  # Min Loss Span To Consider\\nMAX_LEN = 1024  # Maximum calculator length', metadata={'language': 'python', 'source': '/content/test_repo/data_generation/calculator.py'})]\n",
            "```\n",
            "**Best Contex PDF**:\n",
            "\n",
            "\n",
            "[Document(page_content='positionibecauseMis not yet ﬁnetuned on any examples\\ncontaining API calls, so inserting it in the middle of xwould\\ninterrupt the ﬂow and not align with patterns in the pretraining\\ncorpus, thus hurting perplexity.', metadata={'page': 2, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content='positionibecauseMis not yet ﬁnetuned on any examples\\ncontaining API calls, so inserting it in the middle of xwould\\ninterrupt the ﬂow and not align with patterns in the pretraining\\ncorpus, thus hurting perplexity.', metadata={'page': 2, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "---------------------- **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? ----------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:33<1:51:07, 33.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Current best score: 0.42464327384402223 &&& Best Weights 0 : (0.03406964580725607, 0.014351151318948626, 0.1252980511351012, 0.14697928189522896, 0.0927036760996391, 0.1349566846841748, 0.15248524665537008, 0.15507093027016366, 0.0672705040183366, 0.07681482811578075)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [05:24<1:31:57, 29.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10: Current best score: 0.4913649220378753 &&& Best Weights 10 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [10:29<1:29:36, 30.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 20: Current best score: 0.4913649220378753 &&& Best Weights 20 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [15:23<1:25:24, 30.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 30: Current best score: 0.4913649220378753 &&& Best Weights 30 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [20:16<1:18:21, 29.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 40: Current best score: 0.4913649220378753 &&& Best Weights 40 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [24:50<1:06:58, 26.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 50: Current best score: 0.4913649220378753 &&& Best Weights 50 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [29:15<59:56, 25.87s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 60: Current best score: 0.4913649220378753 &&& Best Weights 60 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [33:43<57:11, 26.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 70: Current best score: 0.4913649220378753 &&& Best Weights 70 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [38:09<52:37, 26.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 80: Current best score: 0.4913649220378753 &&& Best Weights 80 : (0.06626464041019968, 0.05487596678063735, 0.15930476445801128, 0.21679310446220948, 0.06538430840858504, 0.043030673273792085, 0.05282459013459714, 0.1882733385371346, 0.10665824315400775, 0.04659037038082553)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [42:30<48:09, 26.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 90: Current best score: 0.536230932574046 &&& Best Weights 90 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [46:59<44:51, 27.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100: Current best score: 0.536230932574046 &&& Best Weights 100 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [51:23<39:36, 26.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 110: Current best score: 0.536230932574046 &&& Best Weights 110 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [55:56<35:24, 26.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 120: Current best score: 0.536230932574046 &&& Best Weights 120 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [1:00:22<30:54, 26.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 130: Current best score: 0.536230932574046 &&& Best Weights 130 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [1:04:47<26:02, 26.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 140: Current best score: 0.536230932574046 &&& Best Weights 140 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [1:09:25<22:45, 27.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 150: Current best score: 0.536230932574046 &&& Best Weights 150 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [1:13:47<16:53, 26.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 160: Current best score: 0.536230932574046 &&& Best Weights 160 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [1:18:18<12:34, 26.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 170: Current best score: 0.536230932574046 &&& Best Weights 170 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [1:22:48<08:34, 27.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 180: Current best score: 0.536230932574046 &&& Best Weights 180 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [1:27:11<03:57, 26.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 190: Current best score: 0.536230932574046 &&& Best Weights 190 : (0.012183247552104256, 0.10026529640555645, 0.18151324758119516, 0.17073438496545748, 0.10502537024077112, 0.01704885446973744, 0.06331769582366116, 0.15275527427484964, 0.07617036169436044, 0.1209862669923068)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [1:31:04<00:00, 27.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            " -> **Question**: Toolformer 에서 사용하고 있는 Tool 에는 어떤게 있어? \n",
            "\n",
            "**Best Score** : 0.536230932574046\n",
            "**Best Answer CODE**: Toolformer 클래스에서 사용되는 Tool은 nn.Embedding, Transformer, nn.Linear 입니다. (위 코드 참조) \n",
            "\n",
            "\n",
            "**Best Answer PDF**: Toolformer 모델이 사용하는 도구에는 계산기, 질문 응답 시스템, 검색 엔진, 번역 시스템 및 캘린더가 포함되어 있습니다. (Source: Toolformer: Language Models Can Teach Themselves to Use Tools) \n",
            "\n",
            "\n",
            "**Best Subdirectory**: /content/test_repo/data_generation\n",
            "**Best Contex CODE**:\n",
            "\n",
            "```python\n",
            "[Document(page_content='class Toolformer(nn.Module):\\n    def __init__(\\n        self,\\n        dim,\\n        num_tokens,\\n        depth,\\n        dim_head=64,\\n        heads=8,\\n        ff_mult=4,\\n    ):\\n        super().__init__()\\n\\n        self.emb = nn.Embedding(num_tokens, dim)\\n        self.transformer = Transformer(dim, depth, heads, dim_head, ff_mult)\\n        self.to_logits = nn.Linear(dim, num_tokens)\\n\\n    def forward(self, x):\\n        x = self.emb(x)\\n        x = self.transformer(x)\\n        x = self.to_logits(x)\\n        return x', metadata={'content_type': 'functions_classes', 'language': 'python', 'source': '/content/test_repo/gptj_pytorch.py'}), Document(page_content='class Toolformer(nn.Module):\\n    def __init__(\\n        self,\\n        dim,\\n        num_tokens,\\n        depth,\\n        dim_head=64,\\n        heads=8,\\n        ff_mult=4,\\n    ):\\n        super().__init__()\\n\\n        self.emb = nn.Embedding(num_tokens, dim)\\n        self.transformer = Transformer(dim, depth, heads, dim_head, ff_mult)\\n        self.to_logits = nn.Linear(dim, num_tokens)\\n\\n    def forward(self, x):\\n        x = self.emb(x)\\n        x = self.transformer(x)\\n        x = self.to_logits(x)\\n        return x', metadata={'content_type': 'functions_classes', 'language': 'python', 'source': '/content/test_repo/gptj_pytorch.py'})]\n",
            "```\n",
            "**Best Contex PDF**:\n",
            "\n",
            "\n",
            "[Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'}), Document(page_content=\"Toolformer: Language Models Can Teach Themselves to Use Tools\\nTimo Schick Jane Dwivedi-Yu Roberto Dessì†Roberta Raileanu\\nMaria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom\\nMeta AI Research†Universitat Pompeu Fabra\\nAbstract\\nLanguage models (LMs) exhibit remarkable\\nabilities to solve new tasks from just a few\\nexamples or textual instructions, especially at\\nscale. They also, paradoxically, struggle with\\nbasic functionality, such as arithmetic or fac-\\ntual lookup, where much simpler and smaller\\nmodels excel. In this paper, we show that\\nLMs can teach themselves to use external tools\\nvia simple APIs and achieve the best of both\\nworlds. We introduce Toolformer , a model\\ntrained to decide which APIs to call, when to\\ncall them, what arguments to pass, and how to\\nbest incorporate the results into future token\\nprediction. This is done in a self-supervised\\nway, requiring nothing more than a handful of\\ndemonstrations for each API. We incorporate\\na range of tools, including a calculator, a Q&A\\nsystem, a search engine, a translation system,\\nand a calendar. Toolformer achieves substan-\\ntially improved zero-shot performance across\\na variety of downstream tasks, often competi-\\ntive with much larger models, without sacriﬁc-\\ning its core language modeling abilities.\\n1 Introduction\\nLarge language models achieve impressive zero-\\nand few-shot results on a variety of natural lan-\\nguage processing tasks (Brown et al., 2020; Chowd-\\nhery et al., 2022, i.a.) and show several emergent\\ncapabilities (Wei et al., 2022). However, all of\\nthese models have several inherent limitations that\\ncan at best be partially addressed by further scal-\\ning. These limitations include an inability to access\\nup-to-date information on recent events (Komeili\\net al., 2022) and the related tendency to hallucinate\\nfacts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-\\nties in understanding low-resource languages (Lin\\net al., 2021), a lack of mathematical skills to per-\\nform precise calculations (Patel et al., 2021) and an\\nunawareness of the progression of time (Dhingra\\net al., 2022).\\nThe New England Journal of Medicine is a registered \\ntrademark of  [QA(“Who is the publisher of The New  \\nEngland Journal of Medicine?”) → Massachusetts  \\nMedical Society]  the MMS. \\nOut of 1400 participants, 400 (or [Calculator(400 / 1400)  \\n→ 0.29]  29%) passed the test. \\nThe name derives from “la tortuga”, the Spanish word for \\n[MT(“tortuga”) → turtle]  turtle. \\nThe Brown Act is California’s law  [WikiSearch(“Brown  \\nAct”) → The Ralph M. Brown Act is an act of the  \\nCalifornia State Legislature that guarantees the public's  \\nright to attend and participate in meetings of local  \\nlegislative bodies.]  that requires legislative bodies, like \\ncity councils, to hold their meetings open to the public. Figure 1: Exemplary predictions of Toolformer. The\\nmodel autonomously decides to call different APIs\\n(from top to bottom: a question answering system,\\na calculator, a machine translation system, and a\\nWikipedia search engine) to obtain information that is\\nuseful for completing a piece of text.\\nA simple way to overcome these limitations of\\ntoday’s language models is to give them the abil-\\nity to use external tools such as search engines,\\ncalculators, or calendars. However, existing ap-\\nproaches either rely on large amounts of human\\nannotations (Komeili et al., 2022; Thoppilan et al.,\\n2022) or limit tool use to task-speciﬁc settings only\\n(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-\\ning a more widespread adoption of tool use in LMs.\\nTherefore, we propose Toolformer , a model that\\nlearns to use tools in a novel way, which fulﬁlls the\\nfollowing desiderata:\\n•The use of tools should be learned in a\\nself-supervised way without requiring large\\namounts of human annotations . This is impor-arXiv:2302.04761v1  [cs.CL]  9 Feb 2023\", metadata={'page': 0, 'source': '/content/2302.04761v1 (4).pdf'})]\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vRkCrCV2X-e9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}