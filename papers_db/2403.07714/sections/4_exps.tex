\subsection{Experimental Setups}

% \subsection{Query Construction}
% \textcolor{red}{Discussion: Position of query construction in the paper.}
% % Curating a large number of real-world queries based on a large-scale tool set is a non-trival problems. To balance 

% In addition to the original queries in ToolBench, we further create queries aiming at improved reality and quality of benchmark. In ToolBench, queries are created from the bottom-up, i.e., LLMs will write questions based on the APIs they are given. In this way, although the feasibility of the queries is guaranteed, reality is sacrificed. This is because when it comes to more complex multi-step questions, LLMs may connect unrelated APIs to make up an unnatural query. For example, in the following query: 

%  \texttt{I'm working on a project and I need some data related to addresses in Brazil. Can you provide me with address details using the postal code 75094080? Also, I would like to know the health status of the SQUAKE API.}

% \noindent The first and the second subquery, asking for address details and API status are not related.

% To enhance the reality of the queries, we further create some queries with cluster APIs functionalities with specified scenarios. Specifically, we first extract some scenarios from the training set of the ToolBench dataset, by prompting \texttt{GPT-4}. Then, we encode all tools by their documentation using \texttt{E5-Mistral-7B-Instruct}~\cite{wang2022text, wang2023improving}, following EasyTool~\cite{yuan2024easytool}. We cluster these APIs with K-Means~\cite{MacQueen1967SomeMF}. Within each cluster, we summarise the functionality of this cluster with \texttt{GPT-3.5-Turbo}. At last, for each scenario, we retrieve the top 5 clusters of APIs by the cosine similarity between the scenarios and the cluster centres and then ask GPT-4 to write queries based on the scenarios and retrieved clusters. Based on the clustered APIs, the detailed functionality of the APIs is blurred, allowing more natural queries.







