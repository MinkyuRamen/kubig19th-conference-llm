{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "from semanticscholar import SemanticScholar\n",
    "\n",
    "import requests\n",
    "\n",
    "dotenv_path = '.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "ss_api_key = os.getenv(\"SS_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì „ëµ 1\n",
    "- ë…¼ë¬¸ì„ ì¸ìš©(citation)í•œ ë‹¤ë¥¸ ë…¼ë¬¸ë“¤ì˜ ì´ˆë¡ì—ì„œ í•œê³„ì ì„ ì–¸ê¸‰í•œ ê²ƒì´ ìˆëŠ”ì§€ ì°¾ì•„ë³´ê¸°\n",
    "- ë…¼ë¬¸ì„ ì°¸ì¡°(reference)í•œ ë‹¤ë¥¸ ë…¼ë¬¸ë“¤ì˜ ì´ˆë¡ì—ì„œ í•œê³„ì ì„ ì–¸ê¸‰í•œ ê²ƒì´ ìˆëŠ”ì§€ ì°¾ì•„ë³´ê¸°\n",
    "- ì°¾ê²Œ ëœë‹¤ë©´ ì–¸ê¸‰ì´ ëœ ê·¸ ë…¼ë¬¸ì´ ê°œì„ í•  ìˆ˜ ìˆëŠ” ì•„ì´ë””ì–´ì¼ ê²ƒì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_info_by_title(title, ss_api_key):\n",
    "    \"\"\"ë…¼ë¬¸ì˜ ì œëª©ìœ¼ë¡œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    # Define the API endpoint URL\n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/search?query={}&fields=paperId,title,abstract,authors,citations,fieldsOfStudy,influentialCitationCount,isOpenAccess,openAccessPdf,publicationDate,publicationTypes,references,venue'\n",
    "    \n",
    "    headers = {'x-api-key': ss_api_key}\n",
    "    response = requests.get(url.format(title), headers=headers).json()\n",
    "\n",
    "    if response.get('data'):\n",
    "        paper = response['data'][0]\n",
    "        return paper\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_citing_papers(paper_id, ss_api_key):\n",
    "    \"\"\"ì…ë ¥í•œ idì— í•´ë‹¹í•˜ëŠ” ë…¼ë¬¸ì„ ì¸ìš©í•œ ë…¼ë¬¸ë“¤ì˜ ì œëª©ê³¼ ì´ˆë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    url = f'https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations?fields=title,abstract'\n",
    "    \n",
    "    headers = {'x-api-key': ss_api_key}\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    \n",
    "    if response.get('data'):\n",
    "        return response['data']\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def get_referenced_papers(paper_id, ss_api_key):\n",
    "    url = f'https://api.semanticscholar.org/graph/v1/paper/{paper_id}/references?fields=title,abstract'\n",
    "    \n",
    "    headers = {'x-api-key': ss_api_key}\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    \n",
    "    if response.get('data'):\n",
    "        return response['data']\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def find_limitations_in_paper(texts):\n",
    "    \"\"\"í•œê³„ì ì´ë¼ê³  ì–¸ê¸‰ëœ ë¶€ë¶„ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    keywords = [\n",
    "        'limitation', 'limitations', 'drawback', 'shortcoming', 'constraint', 'weakness',\n",
    "        'future work', 'future direction', 'challenge', 'issue', 'problem', 'restriction',\n",
    "        'flaw', 'hurdle', 'barrier', 'difficulty', 'risk', 'pitfall', 'concern', 'obstacle',\n",
    "        'gap', 'disadvantage', 'incompleteness', 'improvement'\n",
    "    ]\n",
    "    limitations = []\n",
    "    \n",
    "    for text in texts:\n",
    "        abstract = text.get('abstract', '').lower()\n",
    "        if any(keyword in abstract for keyword in keywords):\n",
    "            limitations.append((text['title'], text['abstract']))\n",
    "    \n",
    "    return limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No limitations found in citing papers.\n",
      "\n",
      "No limitations found in referenced papers.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "title = \"Toolformer: Language Models Can Teach Themselves to Use Tools\"\n",
    "paper = get_paper_info_by_title(title, ss_api_key)\n",
    "\n",
    "if paper:\n",
    "    paper_id = paper['paperId']\n",
    "    citing_papers = get_citing_papers(paper_id, ss_api_key)\n",
    "    limitations_in_citations = find_limitations_in_paper(citing_papers)\n",
    "    \n",
    "    if limitations_in_citations:\n",
    "        print(\"\\nLimitations found in citing papers:\")\n",
    "        for title, limitations in limitations_in_citations:\n",
    "            print(f\"Title: {title}\")\n",
    "            for limitation in limitations:\n",
    "                print(f\" - {limitation}\")\n",
    "    else:\n",
    "        print(\"\\nNo limitations found in citing papers.\")\n",
    "    \n",
    "    # Get referenced papers and find limitations\n",
    "    referenced_papers = get_referenced_papers(paper_id, ss_api_key)\n",
    "    limitations_in_references = find_limitations_in_paper(referenced_papers)\n",
    "    \n",
    "    if limitations_in_references:\n",
    "        print(\"\\nLimitations found in referenced papers:\")\n",
    "        for title, limitations in limitations_in_references:\n",
    "            print(f\"Title: {title}\")\n",
    "            for limitation in limitations:\n",
    "                print(f\" - {limitation}\")\n",
    "    else:\n",
    "        print(\"\\nNo limitations found in referenced papers.\")\n",
    "else:\n",
    "    print(\"No paper found with the given title.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì „ëµ 2\n",
    "- ë…¼ë¬¸ì˜ ë‚´ìš©ì„ ì§ì ‘ ê°€ì ¸ì™€ì„œ ê±°ê¸°ì„œ í•œê³„ì  ë° í–¥í›„ ì—°êµ¬ ì–¸ê¸‰ ë¶€ë¶„ì„ ì°¾ì•„ë³´ê¸°\n",
    "- pdf ë‹¤ìš´ë¡œë“œ ë°©ì‹ë³´ë‹¤ëŠ” ì›¹ì—ì„œ ê¸ì–´ì˜¬ ìˆ˜ ìˆìœ¼ë©´ ì¢‹ê² ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    'limitation', 'limitations', 'drawback', 'shortcoming', 'constraint', 'weakness',\n",
    "    'future work', 'future direction', 'challenge', 'issue', 'problem', 'restriction',\n",
    "    'flaw', 'hurdle', 'barrier', 'difficulty', 'risk', 'pitfall', 'concern', 'obstacle',\n",
    "    'gap', 'disadvantage', 'incompleteness', 'improvement'\n",
    "]\n",
    "\n",
    "def get_arxiv_url(paper):\n",
    "    \"ë…¼ë¬¸ì˜ ar5iv ì£¼ì†Œë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜\"\n",
    "    external_ids = paper.get('openAccessPdf', {})\n",
    "    arxiv_id = external_ids.get('url')\n",
    "    if 'http' in arxiv_id:\n",
    "        arxiv_id = arxiv_id.split('/')[-1]\n",
    "        return f\"https://ar5iv.org/abs/{arxiv_id}\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def find_limitations_in_arxiv(url, sections:list=None):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    all_sections = soup.find_all('section')\n",
    "    \n",
    "    limitations = []\n",
    "    for section in all_sections:\n",
    "        section_title_tag = section.find('h2', class_='ltx_title_section')\n",
    "        if section_title_tag:\n",
    "            section_title = section_title_tag.get_text().strip().lower()\n",
    "            if sections and not any(s.lower() in section_title for s in sections):\n",
    "                print(section_title)\n",
    "                continue\n",
    "\n",
    "        paragraphs = section.find_all('p')\n",
    "        for paragraph in paragraphs:\n",
    "            text = paragraph.get_text().lower()\n",
    "            if any(keyword in text for keyword in keywords):\n",
    "                limitations.append(paragraph.get_text())\n",
    "    \n",
    "    if limitations:\n",
    "        return list(set(limitations))\n",
    "    else:\n",
    "        return \"No limitations found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toolformer: Language Models Can Teach Themselves to Use Tools\n",
      "Abstract: Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q\\&A system, two different search engines, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.\n",
      "arXiv URL: https://ar5iv.org/abs/2302.04761\n",
      "2 approach\n",
      "3 tools\n",
      "4 experiments\n",
      "5 analysis\n",
      "6 related work\n",
      "7 limitations\n",
      "8 conclusion\n",
      "Limitations found in the paper:\n",
      "- For Dateset, on the other hand, the considerable improvement of Toolformer compared to other models can be fully accredited to the calendar tool, which it makes use of for 54.8% of all examples.\n",
      "- Large language models achieve impressive zero- and few-shot results on a variety of natural language processing tasks (Brown etÂ al., 2020; Chowdhery etÂ al., 2022, i.a.) and show several emergent capabilities (Wei etÂ al., 2022). However, all of these models have several inherent limitations that can at best be partially addressed by further scaling. These limitations include an inability to access up-to-date information on recent events (Komeili etÂ al., 2022) and the related tendency to hallucinate facts (Maynez etÂ al., 2020; Ji etÂ al., 2022), difficulties in understanding low-resource languages (Lin etÂ al., 2021), a lack of mathematical skills to perform precise calculations (Patel etÂ al., 2021) and an unawareness of the progression of time (Dhingra etÂ al., 2022).\n",
      "- A simple way to overcome these limitations of todayâ€™s language models is to give them the ability to use external tools such as search engines, calculators, or calendars.\n",
      "However, existing approaches either rely on large amounts of human annotations (Komeili etÂ al., 2022; Thoppilan etÂ al., 2022) or limit tool use to task-specific settings only (e.g., Gao etÂ al., 2022; Parisi etÂ al., 2022), hindering a more widespread adoption of tool use in LMs.\n",
      "Therefore, we propose Toolformer, a model that learns to use tools in a novel way, which fulfills the following desiderata:\n",
      "- Results shown in TableÂ 7 illustrate that Toolformer outperforms all baselines for both TempLAMA and Dateset. However, closer inspection shows that improvements on TempLAMA can not be attributed to the calendar tool, which is only used for 0.2% of all examples, but mostly to the Wikipedia search and question answering tools, which Toolformer calls the most. This makes sense given that\n",
      "named entities in TempLama are often so specific and rare that even knowing the exact date alone would be of little help. The best course of action for this dataset â€“ first querying the calendar API to get the current date, and then querying the question answering system with this date â€“ is not only prohibited by our restriction of using at most one API call per example, but also hard to learn for Toolformer given that all API calls in its training data are sampled independently.\n",
      "- Results are shown in TableÂ 5. Once again, Toolformer clearly outperforms all other models based on GPT-J, this time mostly relying on the Wikipedia search API (99.3%) to find relevant information. However, Toolformer still lags behind the much larger GPT-3 (175B) model. This is likely due to both the simplicity of our search engine (in many cases, it returns results that are clearly not a good match for a given query) and the inability of Toolformer to interact with it, e.g., by reformulating its query if results are not helpful or by browsing through multiple of the top results. We believe that adding this functionality is an exciting direction for future work.\n",
      "- FigureÂ 4 shows that the ability to leverage the provided tools only emerges at around 775M parameters: smaller models achieve similar performance both with and without tools. An exception to this is the Wikipedia search engine used mostly for QA benchmarks; we hypothesize that this is because the API is comparably easy to use.\n",
      "While models become better at solving tasks without API calls as they grow in size, their ability to make good use of the provided API improves at the same time. As a consequence, there remains a large gap between predictions with and without API calls even for our biggest model.\n",
      "- We investigate the effect of our modified decoding strategy introduced in SectionÂ 4.2, where instead of always generating the most likely token, we generate the <API> token if it is one of the kğ‘˜k most likely tokens. TableÂ 9 shows performance on the T-REx subset of LAMA and on WebQS for different values of kğ‘˜k. As expected, increasing kğ‘˜k leads to the model doing API calls for more examples â€“ from 40.3% and 8.5% with k=1ğ‘˜1k=1 (i.e., regular greedy decoding) to 98.1% and 100% for k=10ğ‘˜10k=10. While for T-REx, there is already a clear improvement in performance with greedy decoding, on WebQS our model only starts to make a substantial number of API calls as we slightly increase kğ‘˜k. Interestingly, for k=1ğ‘˜1k=1 the model is calibrated to some extent: It decides to call APIs for examples that it would perform particularly badly on without making API calls. This can be seen from the fact that performance on examples where it decides not to make an API call (44.3 and 19.9) is higher than average performance if no API calls are made at all (34.9 and 18.9). However, this calibration is lost for higher values of kğ‘˜k.\n",
      "- OPT and GPT-3 perform surprisingly weak across all languages, mostly because they fail to provide an answer in English despite being instructed to do so. A potential reason for GPT-J not suffering from this problem is that it was trained on more multilingual data than both OPT and GPT-3, including the EuroParl corpusÂ (Koehn, 2005; Gao etÂ al., 2020). As an upper bound, we also evaluate GPT-J and GPT-3 on a variant of MLQA where both the context and the question are provided in English. In this setup, GPT-3 performs better than all other models, supporting our hypothesis that its subpar performance on MLQA is due to the multilingual aspect of the task.\n",
      "- Input: But what are the risks during production of nanomaterials? Some nanomaterials may give rise to various kinds of lung damage.\n",
      "Output: But what are the risks during production of nanomaterials? [WikiSearch(â€nanomaterial production risksâ€)] Some nanomaterials may give rise to various kinds of lung damage.\n",
      "- We evaluate all models on a variety of downstream tasks. In all cases, we consider a prompted zero-shot setup â€“ i.e., models are instructed to solve each task in natural language, but we do not provide any in-context examples. This is in contrast to prior work on tool use (e.g., Gao etÂ al., 2022; Parisi etÂ al., 2022), where models are provided with dataset-specific examples of how a tool can be used to solve a concrete task. We choose the more challenging zero-shot setup as we are interested in seeing whether Toolformer works in precisely those cases where a user does not specify in advance which tools should be used in which way for solving a specific problem.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "title = \"Toolformer: Language Models Can Teach Themselves to Use Tools\"\n",
    "paper = get_paper_info_by_title(title, ss_api_key)\n",
    "\n",
    "if paper:\n",
    "    abstract = paper.get('abstract', '')\n",
    "    print(f\"Title: {paper['title']}\")\n",
    "    print(f\"Abstract: {abstract}\")\n",
    "    \n",
    "    arxiv_url = get_arxiv_url(paper)\n",
    "    if arxiv_url:\n",
    "        print(f\"arXiv URL: {arxiv_url}\")\n",
    "        limitations = find_limitations_in_arxiv(arxiv_url, ['introduction'])\n",
    "        if isinstance(limitations, list):\n",
    "            print(\"Limitations found in the paper:\")\n",
    "            for limitation in limitations:\n",
    "                print(f\"- {limitation}\")\n",
    "        else:\n",
    "            print(limitations)\n",
    "    else:\n",
    "        print(\"No arXiv ID available for this paper.\")\n",
    "else:\n",
    "    print(\"No paper found with the given title.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(limitations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Toolformer: Language Models Can Teach Themselves to Use Tools'\n",
    "num = 20\n",
    "threshold = 0.6\n",
    "recommend = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
